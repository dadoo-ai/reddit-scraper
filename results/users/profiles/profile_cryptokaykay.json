[
  {
    "id": "5n51b0n0",
    "url": "https://www.reddit.com/user/cryptokaykay/",
    "username": "cryptokaykay",
    "userIcon": "https://i.redd.it/snoovatar/avatars/39c7cf53-f6f4-4a6d-8776-d5a3d169f031-headshot.png",
    "avatarImage": "https://i.redd.it/snoovatar/avatars/39c7cf53-f6f4-4a6d-8776-d5a3d169f031.png",
    "postKarma": 1618,
    "commentKarma": 410,
    "verified": true,
    "description": "",
    "over18": false,
    "isMod": false,
    "acceptFollowers": true,
    "createdAt": "2021-03-17T15:59:16.000Z",
    "scrapedAt": "2025-08-31T23:58:08.233Z",
    "dataType": "user"
  },
  {
    "id": "t1_n9faqoo",
    "parsedId": "n9faqoo",
    "url": "https://www.reddit.com/r/salesforce/comments/1mttesh/agentforce_pilot_program/n9faqoo/",
    "postId": "t3_1mttesh",
    "parentId": "t3_1mttesh",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "salesforce",
    "communityName": "r/salesforce",
    "body": "[https://www.reddit.com/r/LangChain/comments/1m7mxtc/how\\_building\\_agents\\_as\\_slack\\_bots\\_leveled\\_up\\_our/](https://www.reddit.com/r/LangChain/comments/1m7mxtc/how_building_agents_as_slack_bots_leveled_up_our/)  \nI am currently building something that allows you to create and install slackbots that can connect to various b2b tools and achieve workflows from slack. While I am not sure if it can satisfy your usecases or not, I am looking for some beta testers. Here's a quick demo - Let me know if this is interesting.",
    "createdAt": "2025-08-18T21:51:09.000Z",
    "scrapedAt": "2025-08-31T23:58:09.317Z",
    "upVotes": -1,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/LangChain/comments/1m7mxtc/how_building_agents_as_slack_bots_leveled_up_our/\"&gt;https://www.reddit.com/r/LangChain/comments/1m7mxtc/how_building_agents_as_slack_bots_leveled_up_our/&lt;/a&gt;&lt;br/&gt;\nI am currently building something that allows you to create and install slackbots that can connect to various b2b tools and achieve workflows from slack. While I am not sure if it can satisfy your usecases or not, I am looking for some beta testers. Here&amp;#39;s a quick demo - Let me know if this is interesting.&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t1_n8ukypr",
    "parsedId": "n8ukypr",
    "url": "https://www.reddit.com/r/Slack/comments/1mqyfw7/which_ai_agent_platform_has_the_best_slack/n8ukypr/",
    "postId": "t3_1mqyfw7",
    "parentId": "t1_n8u43ep",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "Slack",
    "communityName": "r/Slack",
    "body": "Fair 😂",
    "createdAt": "2025-08-15T15:38:24.000Z",
    "scrapedAt": "2025-08-31T23:58:09.366Z",
    "upVotes": 1,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;Fair 😂&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t1_n8u3yan",
    "parsedId": "n8u3yan",
    "url": "https://www.reddit.com/r/Slack/comments/1mqyfw7/which_ai_agent_platform_has_the_best_slack/n8u3yan/",
    "postId": "t3_1mqyfw7",
    "parentId": "t1_n8u37k5",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "Slack",
    "communityName": "r/Slack",
    "body": "Of course happy to show you a demo on a call too if interested. Mostly looking for feedback right now",
    "createdAt": "2025-08-15T14:15:31.000Z",
    "scrapedAt": "2025-08-31T23:58:09.402Z",
    "upVotes": 1,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;Of course happy to show you a demo on a call too if interested. Mostly looking for feedback right now&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t1_n8u2m8v",
    "parsedId": "n8u2m8v",
    "url": "https://www.reddit.com/r/Slack/comments/1mqyfw7/which_ai_agent_platform_has_the_best_slack/n8u2m8v/",
    "postId": "t3_1mqyfw7",
    "parentId": "t3_1mqyfw7",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "Slack",
    "communityName": "r/Slack",
    "body": "We are building something that makes it super simple to install ai powered slack apps. It’s called heyzest.ai. Running a closed beta right now. Check out a demo here https://x.com/karthikkalyan90/status/1948134806807814611?s=46&amp;t=XrJJzmievg67l3JcMEEDEw . Happy to provide access if you like.",
    "createdAt": "2025-08-15T14:08:48.000Z",
    "scrapedAt": "2025-08-31T23:58:09.451Z",
    "upVotes": 1,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;We are building something that makes it super simple to install ai powered slack apps. It’s called heyzest.ai. Running a closed beta right now. Check out a demo here &lt;a href=\"https://x.com/karthikkalyan90/status/1948134806807814611?s=46&amp;amp;t=XrJJzmievg67l3JcMEEDEw\"&gt;https://x.com/karthikkalyan90/status/1948134806807814611?s=46&amp;amp;t=XrJJzmievg67l3JcMEEDEw&lt;/a&gt; . Happy to provide access if you like.&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1mjc5nk",
    "parsedId": "1mjc5nk",
    "url": "https://www.reddit.com/r/LangChain/comments/1mjc5nk/key_insights_from_manuss_post_on_context/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Key insights from Manus's post on Context Engineering",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "Hey all,\n\nManus recently dropped a killer post on context engineering and it’s a must read. The core insight?KV Cache hits are the only metric that really matters when building performant agents. Every decision you make around the model context, what to include, how to format, when to truncate, should optimize for KV Cache reuse.\n\nWhen KV Cache hits drop, your time-to-first-token (TTFT) skyrockets, slowing down your agent’s response. Plus, cached input tokens in frontier models are about 10x cheaper, so missing cache means you’re literally burning more money on every request. So, what’s the fix? \n\n\\- Keep your prompt prefix stable and predictable and avoid injecting dynamic values like timestamps upfront.\n\n\\- Serialize your context consistently by loading actions and observations in a predictable, repeatable order. \n\nThis lets the KV Cache do its job, maximizing reuse and keeping your agent fast and cost-efficient.\n\nWhen it comes to tool calls, the common approach is to add or remove them dynamically mid-loop. But, that actually kills KV Cache efficiency. Instead, Manus recommends keeping tool calls fixed in the prompt and masking logits selectively to control when tools are used. This approach preserves the cache structure while allowing flexible tool usage, boosting speed and lowering costs.\n\nContext bloat is a classic agent challenge. As conversations grow, you typically truncate or summarize older messages, losing important details. Manus suggests a better way: offload old context to a file system (or external memory) instead of chopping it off, letting the model read in relevant info only when needed.\n\nAnd finally to keep the agent on track, have it periodically recite its objective. A self-check that helps it stay focused and follow the intended trajectory.\n\nContext engineering is still an evolving science, but from my experience, the best way to master it is by getting hands on and going closer to the metal. Work directly with the raw model APIs and design robust state machines to manage context efficiently. Equipping yourself with advanced techniques like building a file system the model can access, selectively masking logits, and maintaining stable serialization methods is what sets the best agents apart from those relying on naive prompting or simplistic conversation loading.\n\n  \nLink: [https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus](https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus)",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;Manus recently dropped a killer post on context engineering and it’s a must read. The core insight?KV Cache hits are the only metric that really matters when building performant agents. Every decision you make around the model context, what to include, how to format, when to truncate, should optimize for KV Cache reuse.&lt;/p&gt;\n\n&lt;p&gt;When KV Cache hits drop, your time-to-first-token (TTFT) skyrockets, slowing down your agent’s response. Plus, cached input tokens in frontier models are about 10x cheaper, so missing cache means you’re literally burning more money on every request. So, what’s the fix? &lt;/p&gt;\n\n&lt;p&gt;- Keep your prompt prefix stable and predictable and avoid injecting dynamic values like timestamps upfront.&lt;/p&gt;\n\n&lt;p&gt;- Serialize your context consistently by loading actions and observations in a predictable, repeatable order. &lt;/p&gt;\n\n&lt;p&gt;This lets the KV Cache do its job, maximizing reuse and keeping your agent fast and cost-efficient.&lt;/p&gt;\n\n&lt;p&gt;When it comes to tool calls, the common approach is to add or remove them dynamically mid-loop. But, that actually kills KV Cache efficiency. Instead, Manus recommends keeping tool calls fixed in the prompt and masking logits selectively to control when tools are used. This approach preserves the cache structure while allowing flexible tool usage, boosting speed and lowering costs.&lt;/p&gt;\n\n&lt;p&gt;Context bloat is a classic agent challenge. As conversations grow, you typically truncate or summarize older messages, losing important details. Manus suggests a better way: offload old context to a file system (or external memory) instead of chopping it off, letting the model read in relevant info only when needed.&lt;/p&gt;\n\n&lt;p&gt;And finally to keep the agent on track, have it periodically recite its objective. A self-check that helps it stay focused and follow the intended trajectory.&lt;/p&gt;\n\n&lt;p&gt;Context engineering is still an evolving science, but from my experience, the best way to master it is by getting hands on and going closer to the metal. Work directly with the raw model APIs and design robust state machines to manage context efficiently. Equipping yourself with advanced techniques like building a file system the model can access, selectively masking logits, and maintaining stable serialization methods is what sets the best agents apart from those relying on naive prompting or simplistic conversation loading.&lt;/p&gt;\n\n&lt;p&gt;Link: &lt;a href=\"https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus\"&gt;https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1mjc5nk/key_insights_from_manuss_post_on_context/",
    "numberOfComments": 5,
    "flair": null,
    "upVotes": 40,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2025-08-06T18:13:18.000Z",
    "scrapedAt": "2025-08-31T23:58:09.460Z",
    "dataType": "post"
  },
  {
    "id": "t1_n7w0mna",
    "parsedId": "n7w0mna",
    "url": "https://www.reddit.com/r/LangChain/comments/1mls6cj/any_opensource_alternatives_to_langsmith_for/n7w0mna/",
    "postId": "t3_1mls6cj",
    "parentId": "t3_1mls6cj",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LangChain",
    "communityName": "r/LangChain",
    "body": "langtrace",
    "createdAt": "2025-08-10T04:18:19.000Z",
    "scrapedAt": "2025-08-31T23:58:09.496Z",
    "upVotes": 0,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;langtrace&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1m7mxtc",
    "parsedId": "1m7mxtc",
    "url": "https://www.reddit.com/r/LangChain/comments/1m7mxtc/how_building_agents_as_slack_bots_leveled_up_our/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "How building Agents as Slack bots leveled up our team and made us more AI forward",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "A quick story I wanted to share. Our team has been building and deploying AI agents as Slack bots for the past few months. What started as a fun little project has increasingly turned into a critical aspect of how we operate. The bots now handle various tasks such as,\n\n* Every time we get a sign up, enrich their info using Apollo, write a personalized email and draft it to my mailbox.\n* Create tickets to Linear whenever a new task comes up. \n* The bots can also be configured to pro-actively jump in on conversations when it feels with a certain degree of confidence that it can help in a specific situation. Ex: If someone talks about something that involves the current sprint's tasks, our task tracker bot will jump in and ask if it can help break down the tasks and add them to linear.\n* Scraping content on the internet and writing a blog post - Now, you may ask, why can't I do this with ChatGPT. Sure you can. But, what we did not completely expect was - the collaborative nature of Slack meant, folks collaborate on a thread where the bot was part of the conversation.\n* Looking up failed transactions from Stripe and pulling those customer emails to a conversation on Slack.\n\nAnd more than anything else, what we also kinda realized was, by allowing agents to run on Slack where folks can interact, we let everyone see how a certain someone tagged and prompted these agents and got a specific outcome as a result. This was a fun way for everyone to learn together and work with these agents collaboratively and level up as a team.   \n  \nHere's a quick demo of one such bot that self corrects and pursues the given goal and achieves it eventually. Happy to help if anyone wants to deploy bots like these to Slack.  \n  \nWe have also built a dashboard for managing all the bots - it let's anyone build and deploy bots, configure permissions and access controls, set up traits and personalities etc. \n\nTech stack: Vercel AI SDK and [axllm.dev](http://axllm.dev) for the agent. Composio for tools.\n\nhttps://reddit.com/link/1m7mxtc/video/ghho4ycg6pef1/player\n\n",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A quick story I wanted to share. Our team has been building and deploying AI agents as Slack bots for the past few months. What started as a fun little project has increasingly turned into a critical aspect of how we operate. The bots now handle various tasks such as,&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Every time we get a sign up, enrich their info using Apollo, write a personalized email and draft it to my mailbox.&lt;/li&gt;\n&lt;li&gt;Create tickets to Linear whenever a new task comes up. &lt;/li&gt;\n&lt;li&gt;The bots can also be configured to pro-actively jump in on conversations when it feels with a certain degree of confidence that it can help in a specific situation. Ex: If someone talks about something that involves the current sprint&amp;#39;s tasks, our task tracker bot will jump in and ask if it can help break down the tasks and add them to linear.&lt;/li&gt;\n&lt;li&gt;Scraping content on the internet and writing a blog post - Now, you may ask, why can&amp;#39;t I do this with ChatGPT. Sure you can. But, what we did not completely expect was - the collaborative nature of Slack meant, folks collaborate on a thread where the bot was part of the conversation.&lt;/li&gt;\n&lt;li&gt;Looking up failed transactions from Stripe and pulling those customer emails to a conversation on Slack.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;And more than anything else, what we also kinda realized was, by allowing agents to run on Slack where folks can interact, we let everyone see how a certain someone tagged and prompted these agents and got a specific outcome as a result. This was a fun way for everyone to learn together and work with these agents collaboratively and level up as a team.   &lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s a quick demo of one such bot that self corrects and pursues the given goal and achieves it eventually. Happy to help if anyone wants to deploy bots like these to Slack.  &lt;/p&gt;\n\n&lt;p&gt;We have also built a dashboard for managing all the bots - it let&amp;#39;s anyone build and deploy bots, configure permissions and access controls, set up traits and personalities etc. &lt;/p&gt;\n\n&lt;p&gt;Tech stack: Vercel AI SDK and &lt;a href=\"http://axllm.dev\"&gt;axllm.dev&lt;/a&gt; for the agent. Composio for tools.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://reddit.com/link/1m7mxtc/video/ghho4ycg6pef1/player\"&gt;https://reddit.com/link/1m7mxtc/video/ghho4ycg6pef1/player&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1m7mxtc/how_building_agents_as_slack_bots_leveled_up_our/",
    "numberOfComments": 14,
    "flair": "Discussion",
    "upVotes": 17,
    "upVoteRatio": 0.9,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2025-07-23T22:13:08.000Z",
    "scrapedAt": "2025-08-31T23:58:09.499Z",
    "dataType": "post"
  },
  {
    "id": "t1_n7uucvk",
    "parsedId": "n7uucvk",
    "url": "https://www.reddit.com/r/SaaS/comments/1mlz826/only_7_years_old_and_i_hit_395k_mrr_with_my/n7uucvk/",
    "postId": "t3_1mlz826",
    "parentId": "t3_1mlz826",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "SaaS",
    "communityName": "r/SaaS",
    "body": "I was born last week, just hit $100MRR with my baby feeding schedule app. I started by solving my own problem and then decided to find other babies like me. \n\n- solve your own problem \n- the riches are in the niches \n- do things that don’t scale",
    "createdAt": "2025-08-09T23:36:44.000Z",
    "scrapedAt": "2025-08-31T23:58:09.551Z",
    "upVotes": 14,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;I was born last week, just hit $100MRR with my baby feeding schedule app. I started by solving my own problem and then decided to find other babies like me. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;solve your own problem &lt;/li&gt;\n&lt;li&gt;the riches are in the niches &lt;/li&gt;\n&lt;li&gt;do things that don’t scale&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t1_n6pqxav",
    "parsedId": "n6pqxav",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mgfccn/llm_observability_any_suggestions/n6pqxav/",
    "postId": "t3_1mgfccn",
    "parentId": "t3_1mgfccn",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LocalLLaMA",
    "communityName": "r/LocalLLaMA",
    "body": "Checkout langtrace - open source and open telemetry based, can be self hosted as well",
    "createdAt": "2025-08-03T16:08:21.000Z",
    "scrapedAt": "2025-08-31T23:58:09.597Z",
    "upVotes": 1,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;Checkout langtrace - open source and open telemetry based, can be self hosted as well&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1m7nq6q",
    "parsedId": "1m7nq6q",
    "url": "https://www.reddit.com/r/SaaS/comments/1m7nq6q/built_a_platform_for_launching_ai_agents_as_slack/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Built a platform for launching AI Agents as Slack bots",
    "communityName": "r/SaaS",
    "parsedCommunityName": "SaaS",
    "body": "A quick story I wanted to share. Our team has been building and deploying AI agents as Slack bots for the past few months. What started as a fun little project has increasingly turned into a critical aspect of how we operate. The bots now handle various tasks such as,\n\n* Every time we get a sign up, enrich their info using Apollo, write a personalized email and draft it to my mailbox.\n* Create tickets to Linear whenever a new task comes up.\n* The bots can also be configured to pro-actively jump in on conversations when it feels with a certain degree of confidence that it can help in a specific situation. Ex: If someone talks about something that involves the current sprint's tasks, our task tracker bot will jump in and ask if it can help break down the tasks and add them to linear.\n* Scraping content on the internet and writing a blog post - Now, you may ask, why can't I do this with ChatGPT. Sure you can. But, what we did not completely expect was - the collaborative nature of Slack meant, folks collaborate on a thread where the bot was part of the conversation.\n* Looking up failed transactions from Stripe and pulling those customer emails to a conversation on Slack.\n\nAnd more than anything else, what we also kinda realized was, by allowing agents to run on Slack where folks can interact, we let everyone see how a certain someone tagged and prompted these agents and got a specific outcome as a result. This was a fun way for everyone to learn together and work with these agents collaboratively and level up as a team.\n\nHere's a quick demo of one such bot that self corrects and pursues the given goal and achieves it eventually. Happy to help if anyone wants to deploy bots like these to Slack.\n\nWe have also built a dashboard for managing all the bots - it let's anyone build and deploy bots, configure permissions and access controls, set up traits and personalities etc.\n\nWe are currently running a closed beta. If this post resonates with you and you're interested to participate, feel free to join our waitlist - [https://www.heyzest.ai/](https://www.heyzest.ai/) . ",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A quick story I wanted to share. Our team has been building and deploying AI agents as Slack bots for the past few months. What started as a fun little project has increasingly turned into a critical aspect of how we operate. The bots now handle various tasks such as,&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Every time we get a sign up, enrich their info using Apollo, write a personalized email and draft it to my mailbox.&lt;/li&gt;\n&lt;li&gt;Create tickets to Linear whenever a new task comes up.&lt;/li&gt;\n&lt;li&gt;The bots can also be configured to pro-actively jump in on conversations when it feels with a certain degree of confidence that it can help in a specific situation. Ex: If someone talks about something that involves the current sprint&amp;#39;s tasks, our task tracker bot will jump in and ask if it can help break down the tasks and add them to linear.&lt;/li&gt;\n&lt;li&gt;Scraping content on the internet and writing a blog post - Now, you may ask, why can&amp;#39;t I do this with ChatGPT. Sure you can. But, what we did not completely expect was - the collaborative nature of Slack meant, folks collaborate on a thread where the bot was part of the conversation.&lt;/li&gt;\n&lt;li&gt;Looking up failed transactions from Stripe and pulling those customer emails to a conversation on Slack.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;And more than anything else, what we also kinda realized was, by allowing agents to run on Slack where folks can interact, we let everyone see how a certain someone tagged and prompted these agents and got a specific outcome as a result. This was a fun way for everyone to learn together and work with these agents collaboratively and level up as a team.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s a quick demo of one such bot that self corrects and pursues the given goal and achieves it eventually. Happy to help if anyone wants to deploy bots like these to Slack.&lt;/p&gt;\n\n&lt;p&gt;We have also built a dashboard for managing all the bots - it let&amp;#39;s anyone build and deploy bots, configure permissions and access controls, set up traits and personalities etc.&lt;/p&gt;\n\n&lt;p&gt;We are currently running a closed beta. If this post resonates with you and you&amp;#39;re interested to participate, feel free to join our waitlist - &lt;a href=\"https://www.heyzest.ai/\"&gt;https://www.heyzest.ai/&lt;/a&gt; . &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/SaaS/comments/1m7nq6q/built_a_platform_for_launching_ai_agents_as_slack/",
    "numberOfComments": 0,
    "flair": "B2B SaaS",
    "upVotes": 3,
    "upVoteRatio": 0.81,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2025-07-23T22:45:41.000Z",
    "scrapedAt": "2025-08-31T23:58:09.554Z",
    "dataType": "post"
  },
  {
    "id": "t1_n639yyp",
    "parsedId": "n639yyp",
    "url": "https://www.reddit.com/r/LangChain/comments/1m7mxtc/how_building_agents_as_slack_bots_leveled_up_our/n639yyp/",
    "postId": "t3_1m7mxtc",
    "parentId": "t1_n5xkfsy",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LangChain",
    "communityName": "r/LangChain",
    "body": "In the channel it’s added to, yes",
    "createdAt": "2025-07-31T01:53:30.000Z",
    "scrapedAt": "2025-08-31T23:58:09.632Z",
    "upVotes": 1,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;In the channel it’s added to, yes&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t1_n5xjzy0",
    "parsedId": "n5xjzy0",
    "url": "https://www.reddit.com/r/LangChain/comments/1m7mxtc/how_building_agents_as_slack_bots_leveled_up_our/n5xjzy0/",
    "postId": "t3_1m7mxtc",
    "parentId": "t1_n5ruvb4",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LangChain",
    "communityName": "r/LangChain",
    "body": "You can set the confidence level between 0 to 100%",
    "createdAt": "2025-07-30T05:53:25.000Z",
    "scrapedAt": "2025-08-31T23:58:09.670Z",
    "upVotes": 1,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;You can set the confidence level between 0 to 100%&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1m7mb67",
    "parsedId": "1m7mb67",
    "url": "https://www.reddit.com/r/Slack/comments/1m7mb67/how_we_leveled_up_as_an_organization_and_became/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "How we leveled up as an organization and became AI forward using Slack",
    "communityName": "r/Slack",
    "parsedCommunityName": "Slack",
    "body": "A quick story I wanted to share. Our team has been building and deploying AI agents as Slack bots for the past few months. What started as a fun little project has increasingly turned into a critical aspect of how we operate. The bots now handle various tasks such as,\n\nEvery time we get a sign up, enrich their info using Apollo, write a personalized email and draft it to my mailbox.\n\nCreate tickets to Linear whenever a new task comes up. The bots can also be configured to pro-actively jump in on conversations when it feels with a certain degree of confidence that it can help in a specific situation.\n\nScraping content on the internet and writing a blog post - Now, you may ask, why can't I do this with ChatGPT. Sure you can. But, what we did not completely expect was - the collaborative nature of Slack meant, folks collaborate on a thread where the bot was part of the conversation.\n\nLooking up failed transactions from Stripe and pulling those customer emails to a conversation on Slack.\n\nAnd more than anything else, what we also kinda realized was, by allowing agents to run on Slack where folks can interact, we let everyone see how a certain someone tagged and prompted these agents and got a specific outcome as a result. This was a fun way for everyone to learn together and work with these agents collaboratively and level up as a team.",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A quick story I wanted to share. Our team has been building and deploying AI agents as Slack bots for the past few months. What started as a fun little project has increasingly turned into a critical aspect of how we operate. The bots now handle various tasks such as,&lt;/p&gt;\n\n&lt;p&gt;Every time we get a sign up, enrich their info using Apollo, write a personalized email and draft it to my mailbox.&lt;/p&gt;\n\n&lt;p&gt;Create tickets to Linear whenever a new task comes up. The bots can also be configured to pro-actively jump in on conversations when it feels with a certain degree of confidence that it can help in a specific situation.&lt;/p&gt;\n\n&lt;p&gt;Scraping content on the internet and writing a blog post - Now, you may ask, why can&amp;#39;t I do this with ChatGPT. Sure you can. But, what we did not completely expect was - the collaborative nature of Slack meant, folks collaborate on a thread where the bot was part of the conversation.&lt;/p&gt;\n\n&lt;p&gt;Looking up failed transactions from Stripe and pulling those customer emails to a conversation on Slack.&lt;/p&gt;\n\n&lt;p&gt;And more than anything else, what we also kinda realized was, by allowing agents to run on Slack where folks can interact, we let everyone see how a certain someone tagged and prompted these agents and got a specific outcome as a result. This was a fun way for everyone to learn together and work with these agents collaboratively and level up as a team.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/Slack/comments/1m7mb67/how_we_leveled_up_as_an_organization_and_became/",
    "numberOfComments": 4,
    "flair": null,
    "upVotes": 4,
    "upVoteRatio": 0.67,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2025-07-23T21:48:08.000Z",
    "scrapedAt": "2025-08-31T23:58:09.665Z",
    "dataType": "post"
  },
  {
    "id": "t1_n4wket2",
    "parsedId": "n4wket2",
    "url": "https://www.reddit.com/r/LangChain/comments/1m7mxtc/how_building_agents_as_slack_bots_leveled_up_our/n4wket2/",
    "postId": "t3_1m7mxtc",
    "parentId": "t1_n4tt57q",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LangChain",
    "communityName": "r/LangChain",
    "body": "for an average slack user, this is the cost per day for running workflows from time to time.",
    "createdAt": "2025-07-24T14:17:59.000Z",
    "scrapedAt": "2025-08-31T23:58:09.713Z",
    "upVotes": 1,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;for an average slack user, this is the cost per day for running workflows from time to time.&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1lwj1bk",
    "parsedId": "1lwj1bk",
    "url": "https://www.reddit.com/r/LangChain/comments/1lwj1bk/shipped_a_slack_bot_that_works_like_cursor_and/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Shipped a Slack bot that works like Cursor and has access to b2b apps we use on a daily basis",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "https://reddit.com/link/1lwj1bk/video/hpz8r4mt23cf1/player\n\nTLDR; We have built a bot that is connected to some of the popular b2b apps we use internally. When given a goal, it reasons, plans and executes the plan by accessing these apps until it achieves the goal. Check out this quick demo where it seamlessly pulls raw meeting notes from Notion, extracts todo's, and creates tickets on Linear for each one of those todos.",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://reddit.com/link/1lwj1bk/video/hpz8r4mt23cf1/player\"&gt;https://reddit.com/link/1lwj1bk/video/hpz8r4mt23cf1/player&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;TLDR; We have built a bot that is connected to some of the popular b2b apps we use internally. When given a goal, it reasons, plans and executes the plan by accessing these apps until it achieves the goal. Check out this quick demo where it seamlessly pulls raw meeting notes from Notion, extracts todo&amp;#39;s, and creates tickets on Linear for each one of those todos.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1lwj1bk/shipped_a_slack_bot_that_works_like_cursor_and/",
    "numberOfComments": 2,
    "flair": null,
    "upVotes": 2,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2025-07-10T17:41:37.000Z",
    "scrapedAt": "2025-08-31T23:58:09.750Z",
    "dataType": "post"
  },
  {
    "id": "t3_1lwiziv",
    "parsedId": "1lwiziv",
    "url": "https://www.reddit.com/r/ChatGPT/comments/1lwiziv/created_a_slack_bot_that_can_connect_to_several/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Created a Slack bot that can connect to several apps and run workflows for you",
    "communityName": "r/ChatGPT",
    "parsedCommunityName": "ChatGPT",
    "body": "TLDR; We have built a bot that is connected to some of the popular b2b apps we use internally. When given a goal, it reasons, plans and executes the plan by accessing these apps until it achieves the goal. Check out this quick demo where it seamlessly pulls raw meeting notes from Notion, extracts todo's, and creates tickets on Linear for each one of those todos.\n\n[Waitlist - https:\\/\\/www.heyzest.ai\\/](https://reddit.com/link/1lwiziv/video/ncesy1dg23cf1/player)\n\n  \n\n\n",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR; We have built a bot that is connected to some of the popular b2b apps we use internally. When given a goal, it reasons, plans and executes the plan by accessing these apps until it achieves the goal. Check out this quick demo where it seamlessly pulls raw meeting notes from Notion, extracts todo&amp;#39;s, and creates tickets on Linear for each one of those todos.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://reddit.com/link/1lwiziv/video/ncesy1dg23cf1/player\"&gt;Waitlist - https://www.heyzest.ai/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/ChatGPT/comments/1lwiziv/created_a_slack_bot_that_can_connect_to_several/",
    "numberOfComments": 1,
    "flair": "Resources ",
    "upVotes": 0,
    "upVoteRatio": 0.5,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2025-07-10T17:39:42.000Z",
    "scrapedAt": "2025-08-31T23:58:09.794Z",
    "dataType": "post"
  },
  {
    "id": "t1_n4wkb4l",
    "parsedId": "n4wkb4l",
    "url": "https://www.reddit.com/r/LangChain/comments/1m7mxtc/how_building_agents_as_slack_bots_leveled_up_our/n4wkb4l/",
    "postId": "t3_1m7mxtc",
    "parentId": "t1_n4uv5t5",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LangChain",
    "communityName": "r/LangChain",
    "body": "We have a dashboard that has a configuration for the bot. Which ever channels the bot is part of, it automatically jumps in if it feels with a certain degree of confidence that it can help",
    "createdAt": "2025-07-24T14:17:29.000Z",
    "scrapedAt": "2025-08-31T23:58:09.777Z",
    "upVotes": 1,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;We have a dashboard that has a configuration for the bot. Which ever channels the bot is part of, it automatically jumps in if it feels with a certain degree of confidence that it can help&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1lpgw2x",
    "parsedId": "1lpgw2x",
    "url": "https://www.reddit.com/r/LangChain/comments/1lpgw2x/we_built_an_agent_that_can_run_workflows_on_slack/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "We built an Agent that can run workflows on Slack",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "We have built an agent called Zest that runs on Slack. It has access to all b2b tools and can run point on gathering everything you need to complete the workflows. But you as the user is still in control and you still need to complete the last mile. This has been a huge boost in productivity for us.Here's a video of Zest gathering the details of the latest ticket from Linear and then the user(me) assigning the task over to Cursor agent which completes and creates a PR.\n\nIf you use Slack heavily and are interested in trying it out, hit me up or join the waitlist - [https://www.heyzest.ai/](https://www.heyzest.ai/) and we will give you access.",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have built an agent called Zest that runs on Slack. It has access to all b2b tools and can run point on gathering everything you need to complete the workflows. But you as the user is still in control and you still need to complete the last mile. This has been a huge boost in productivity for us.Here&amp;#39;s a video of Zest gathering the details of the latest ticket from Linear and then the user(me) assigning the task over to Cursor agent which completes and creates a PR.&lt;/p&gt;\n\n&lt;p&gt;If you use Slack heavily and are interested in trying it out, hit me up or join the waitlist - &lt;a href=\"https://www.heyzest.ai/\"&gt;https://www.heyzest.ai/&lt;/a&gt; and we will give you access.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://v.redd.it/07hx0io1lcaf1",
    "numberOfComments": 1,
    "flair": null,
    "upVotes": 2,
    "upVoteRatio": 0.75,
    "isVideo": true,
    "isAd": false,
    "over18": false,
    "videoUrl": "https://v.redd.it/07hx0io1lcaf1/DASH_720.mp4?source=fallback",
    "thumbnailUrl": "https://external-preview.redd.it/cTZ2MmVnbzFsY2FmMerHIca4S1H0EnmHNQykFOojvbtp22Fd4MQ8m_6Y-2-a.png?width=140&amp;height=105&amp;crop=140:105,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=abc65bd672315e6afa364929bb62f558a0682ffd",
    "imageUrls": [
      "https://external-i.redd.it/cTZ2MmVnbzFsY2FmMerHIca4S1H0EnmHNQykFOojvbtp22Fd4MQ8m_6Y-2-a.png"
    ],
    "createdAt": "2025-07-01T23:32:47.000Z",
    "scrapedAt": "2025-08-31T23:58:09.843Z",
    "dataType": "post"
  },
  {
    "id": "t1_n4tryum",
    "parsedId": "n4tryum",
    "url": "https://www.reddit.com/r/LangChain/comments/1m7mxtc/how_building_agents_as_slack_bots_leveled_up_our/n4tryum/",
    "postId": "t3_1m7mxtc",
    "parentId": "t1_n4tqmee",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LangChain",
    "communityName": "r/LangChain",
    "body": "Not a lot. Per workflow is $0.50 to $0.75 with some of the top models from OpenAI",
    "createdAt": "2025-07-24T02:01:22.000Z",
    "scrapedAt": "2025-08-31T23:58:09.845Z",
    "upVotes": 1,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;Not a lot. Per workflow is $0.50 to $0.75 with some of the top models from OpenAI&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t1_n4ssbzg",
    "parsedId": "n4ssbzg",
    "url": "https://www.reddit.com/r/SaaS/comments/1m7g6vo/time_for_selfpromotion_what_are_you_building/n4ssbzg/",
    "postId": "t3_1m7g6vo",
    "parentId": "t3_1m7g6vo",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "SaaS",
    "communityName": "r/SaaS",
    "body": "Building Zest - an easy way to build and launch AI agents as Slack bots. \n\nWhy? \n\nSlack is a perfect product surface for running AI agents that has access to your commonly used b2b tools. \n\nWhat can Zest do?  \n\\- Can be connected to most of the popular b2b apps like Jira, Linear, Apollo, Hubspot, Github etc.  \n\\- Can seamlessly look up information or take actions by just tagging the bot on any channel it's added to.  \n\\- Can proactively jump in on conversations if it feels with a certain degree of confidence that it can add value to a thread.\n\nFinally, interacting with AI agents in a collaborative environment like Slack makes it a fun exercise for everyone on the team to level up their prompt engineering skills.\n\nWe are running a closed beta right and you can join the waitlist here if you're interested - [https://www.heyzest.ai/](https://www.heyzest.ai/)",
    "createdAt": "2025-07-23T22:39:42.000Z",
    "scrapedAt": "2025-08-31T23:58:09.883Z",
    "upVotes": 2,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;Building Zest - an easy way to build and launch AI agents as Slack bots. &lt;/p&gt;\n\n&lt;p&gt;Why? &lt;/p&gt;\n\n&lt;p&gt;Slack is a perfect product surface for running AI agents that has access to your commonly used b2b tools. &lt;/p&gt;\n\n&lt;p&gt;What can Zest do?&lt;br/&gt;\n- Can be connected to most of the popular b2b apps like Jira, Linear, Apollo, Hubspot, Github etc.&lt;br/&gt;\n- Can seamlessly look up information or take actions by just tagging the bot on any channel it&amp;#39;s added to.&lt;br/&gt;\n- Can proactively jump in on conversations if it feels with a certain degree of confidence that it can add value to a thread.&lt;/p&gt;\n\n&lt;p&gt;Finally, interacting with AI agents in a collaborative environment like Slack makes it a fun exercise for everyone on the team to level up their prompt engineering skills.&lt;/p&gt;\n\n&lt;p&gt;We are running a closed beta right and you can join the waitlist here if you&amp;#39;re interested - &lt;a href=\"https://www.heyzest.ai/\"&gt;https://www.heyzest.ai/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1i0gaw6",
    "parsedId": "1i0gaw6",
    "url": "https://www.reddit.com/r/LangChain/comments/1i0gaw6/local_private_and_secure_voice_dictation_app/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Local, private and secure voice dictation app powered by MLX on apple silicon ",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "https://reddit.com/link/1i0gaw6/video/81rdzska3sce1/player\n\nQuick demo of a voice dictation app built using whisper running locally on my mac powered by mlx. Best part - private, local, secure and runs offline.  \nMLX - [https://github.com/ml-explore/mlx](https://github.com/ml-explore/mlx)",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://reddit.com/link/1i0gaw6/video/81rdzska3sce1/player\"&gt;https://reddit.com/link/1i0gaw6/video/81rdzska3sce1/player&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Quick demo of a voice dictation app built using whisper running locally on my mac powered by mlx. Best part - private, local, secure and runs offline.&lt;br/&gt;\nMLX - &lt;a href=\"https://github.com/ml-explore/mlx\"&gt;https://github.com/ml-explore/mlx&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1i0gaw6/local_private_and_secure_voice_dictation_app/",
    "numberOfComments": 1,
    "flair": null,
    "upVotes": 1,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "https://b.thumbs.redditmedia.com/EactcAW5VpYrudB7AkNIo34jBTfKkkzliZ867gSZxls.jpg",
    "imageUrls": [
      "https://external-i.redd.it/lgRdugQ0WR0G8p5naOSmQ29VkQXR332dDTdcotT6TYw.jpg"
    ],
    "createdAt": "2025-01-13T15:21:01.000Z",
    "scrapedAt": "2025-08-31T23:58:09.885Z",
    "dataType": "post"
  },
  {
    "id": "t1_n4sji7j",
    "parsedId": "n4sji7j",
    "url": "https://www.reddit.com/r/Slack/comments/1m7mb67/how_we_leveled_up_as_an_organization_and_became/n4sji7j/",
    "postId": "t3_1m7mb67",
    "parentId": "t1_n4sj5ux",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "Slack",
    "communityName": "r/Slack",
    "body": "Thanks! We are running a closed beta for now. You can join the waitlist here - [https://www.heyzest.ai/](https://www.heyzest.ai/)",
    "createdAt": "2025-07-23T21:53:15.000Z",
    "scrapedAt": "2025-08-31T23:58:09.920Z",
    "upVotes": 0,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks! We are running a closed beta for now. You can join the waitlist here - &lt;a href=\"https://www.heyzest.ai/\"&gt;https://www.heyzest.ai/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1hs6htz",
    "parsedId": "1hs6htz",
    "url": "https://www.reddit.com/r/LangChain/comments/1hs6htz/ai_agent_that_copies_bank_transactions_to_a_sheet/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "AI Agent that copies bank transactions to a sheet automatically",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "Images:\n\thttps://external-preview.redd.it/b3VhbHRjbDNxbmFlMSMhIdO1C2PjzOBo5blfblvyrmVODNbDRHYy5naTKzNw.png?format=pjpg&amp;auto=webp&amp;s=c22fdaff2ae7aaa5ce74b0d71a8033dc44b62634\n",
    "html": "Images:\n\thttps://external-preview.redd.it/b3VhbHRjbDNxbmFlMSMhIdO1C2PjzOBo5blfblvyrmVODNbDRHYy5naTKzNw.png?format=pjpg&amp;auto=webp&amp;s=c22fdaff2ae7aaa5ce74b0d71a8033dc44b62634\n",
    "link": "https://v.redd.it/j0n3pcl3qnae1",
    "numberOfComments": 23,
    "flair": "Resources",
    "upVotes": 7,
    "upVoteRatio": 0.63,
    "isVideo": true,
    "isAd": false,
    "over18": false,
    "videoUrl": "https://v.redd.it/j0n3pcl3qnae1/DASH_720.mp4?source=fallback",
    "thumbnailUrl": "https://external-preview.redd.it/b3VhbHRjbDNxbmFlMSMhIdO1C2PjzOBo5blfblvyrmVODNbDRHYy5naTKzNw.png?width=140&amp;height=90&amp;crop=140:90,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=34720a49fd03072e32ccbe06901f328a4d35526a",
    "imageUrls": [
      "https://external-i.redd.it/b3VhbHRjbDNxbmFlMSMhIdO1C2PjzOBo5blfblvyrmVODNbDRHYy5naTKzNw.png"
    ],
    "createdAt": "2025-01-02T22:30:25.000Z",
    "scrapedAt": "2025-08-31T23:58:09.944Z",
    "dataType": "post"
  },
  {
    "id": "t3_1hk4ghq",
    "parsedId": "1hk4ghq",
    "url": "https://www.reddit.com/r/LangChain/comments/1hk4ghq/built_an_oss_image_background_remover_tool/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Built an OSS image background remover tool",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "Images:\n\thttps://external-preview.redd.it/eXh3YmU5MjIxZzhlMXOn65Dr0TknsRDOrmJ0movPAXB9W5gvvuPzfh-zsni8.png?format=pjpg&amp;auto=webp&amp;s=b8e8d8bb1ac42cc971745dc0c2097daeffbcc9a6\n",
    "html": "Images:\n\thttps://external-preview.redd.it/eXh3YmU5MjIxZzhlMXOn65Dr0TknsRDOrmJ0movPAXB9W5gvvuPzfh-zsni8.png?format=pjpg&amp;auto=webp&amp;s=b8e8d8bb1ac42cc971745dc0c2097daeffbcc9a6\n",
    "link": "https://v.redd.it/iz82d8221g8e1",
    "numberOfComments": 3,
    "flair": "Resources",
    "upVotes": 6,
    "upVoteRatio": 0.87,
    "isVideo": true,
    "isAd": false,
    "over18": false,
    "videoUrl": "https://v.redd.it/iz82d8221g8e1/DASH_720.mp4?source=fallback",
    "thumbnailUrl": "https://external-preview.redd.it/eXh3YmU5MjIxZzhlMXOn65Dr0TknsRDOrmJ0movPAXB9W5gvvuPzfh-zsni8.png?width=140&amp;height=80&amp;crop=140:80,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=1f9b855e09d352a989c822cc349f8eabaa551fab",
    "imageUrls": [
      "https://external-i.redd.it/eXh3YmU5MjIxZzhlMXOn65Dr0TknsRDOrmJ0movPAXB9W5gvvuPzfh-zsni8.png"
    ],
    "createdAt": "2024-12-22T18:29:31.000Z",
    "scrapedAt": "2025-08-31T23:58:09.986Z",
    "dataType": "post"
  },
  {
    "id": "t1_n2l6zxs",
    "parsedId": "n2l6zxs",
    "url": "https://www.reddit.com/r/LangChain/comments/1lwj1bk/shipped_a_slack_bot_that_works_like_cursor_and/n2l6zxs/",
    "postId": "t3_1lwj1bk",
    "parentId": "t1_n2imytk",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LangChain",
    "communityName": "r/LangChain",
    "body": "No langgraph or mcp. Vercel ai sdk and tool calling. Auth is not hard coded. It’s through oauth",
    "createdAt": "2025-07-11T17:48:05.000Z",
    "scrapedAt": "2025-08-31T23:58:09.956Z",
    "upVotes": 1,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;No langgraph or mcp. Vercel ai sdk and tool calling. Auth is not hard coded. It’s through oauth&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1guf1xq",
    "parsedId": "1guf1xq",
    "url": "https://www.reddit.com/r/LangChain/comments/1guf1xq/attribute_extraction_from_images_using_dspy/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Attribute Extraction from Images using DSPy",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "# Introduction\n\nDSPy recently added support for VLMs in beta. A quick thread on attributes extraction from images using DSPy. For this example, we will see how to extract useful attributes from screenshots of websites\n\n# Signature\n\nDefine the signature. Notice the `dspy.Image` input field.\n\nhttps://preview.redd.it/flgyaed82q1e1.png?width=1016&amp;format=png&amp;auto=webp&amp;s=7c72aebb20fa3f963cc480393b3b769b080a7ae8\n\n# Program\n\nNext define a simple program using the ChainOfThought optimizer and the Signature from the previous step\n\nhttps://preview.redd.it/qeuaabb92q1e1.png?width=1306&amp;format=png&amp;auto=webp&amp;s=34da1262900076dab5981cea80d6b2aa6d9f2d5c\n\n# Final Code\n\nFinally, write a function to read the image and extract the attributes by calling the program from the previous step.\n\nhttps://preview.redd.it/hpp57nia2q1e1.png?width=1165&amp;format=png&amp;auto=webp&amp;s=a07c9c5c0fdf1e551c03d31bfbd75898d46693a4\n\n# Observability\n\nThat's it! If you need observability for your development, just add `langtrace.init()` to get deeper insights from the traces.\n\nhttps://preview.redd.it/ji1elw9b2q1e1.png?width=3084&amp;format=png&amp;auto=webp&amp;s=ef48331b0bffea14bc1a21a737415bb08cfa0500\n\n# Source Code\n\nYou can find the full source code for this example here - https://github.com/Scale3-Labs/dspy-examples/tree/main/src/vision\\_lm.",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;Introduction&lt;/h1&gt;\n\n&lt;p&gt;DSPy recently added support for VLMs in beta. A quick thread on attributes extraction from images using DSPy. For this example, we will see how to extract useful attributes from screenshots of websites&lt;/p&gt;\n\n&lt;h1&gt;Signature&lt;/h1&gt;\n\n&lt;p&gt;Define the signature. Notice the &lt;code&gt;dspy.Image&lt;/code&gt; input field.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/flgyaed82q1e1.png?width=1016&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7c72aebb20fa3f963cc480393b3b769b080a7ae8\"&gt;https://preview.redd.it/flgyaed82q1e1.png?width=1016&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7c72aebb20fa3f963cc480393b3b769b080a7ae8&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;Program&lt;/h1&gt;\n\n&lt;p&gt;Next define a simple program using the ChainOfThought optimizer and the Signature from the previous step&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/qeuaabb92q1e1.png?width=1306&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=34da1262900076dab5981cea80d6b2aa6d9f2d5c\"&gt;https://preview.redd.it/qeuaabb92q1e1.png?width=1306&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=34da1262900076dab5981cea80d6b2aa6d9f2d5c&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;Final Code&lt;/h1&gt;\n\n&lt;p&gt;Finally, write a function to read the image and extract the attributes by calling the program from the previous step.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/hpp57nia2q1e1.png?width=1165&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a07c9c5c0fdf1e551c03d31bfbd75898d46693a4\"&gt;https://preview.redd.it/hpp57nia2q1e1.png?width=1165&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a07c9c5c0fdf1e551c03d31bfbd75898d46693a4&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;Observability&lt;/h1&gt;\n\n&lt;p&gt;That&amp;#39;s it! If you need observability for your development, just add &lt;code&gt;langtrace.init()&lt;/code&gt; to get deeper insights from the traces.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ji1elw9b2q1e1.png?width=3084&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ef48331b0bffea14bc1a21a737415bb08cfa0500\"&gt;https://preview.redd.it/ji1elw9b2q1e1.png?width=3084&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ef48331b0bffea14bc1a21a737415bb08cfa0500&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;Source Code&lt;/h1&gt;\n\n&lt;p&gt;You can find the full source code for this example here - &lt;a href=\"https://github.com/Scale3-Labs/dspy-examples/tree/main/src/vision%5C_lm\"&gt;https://github.com/Scale3-Labs/dspy-examples/tree/main/src/vision\\_lm&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1guf1xq/attribute_extraction_from_images_using_dspy/",
    "numberOfComments": 0,
    "flair": "Tutorial",
    "upVotes": 1,
    "upVoteRatio": 0.67,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "https://a.thumbs.redditmedia.com/XjEc1kZJKOlvM8JSu6M33-a3q-BSiN_meLy2F9-Fyk0.jpg",
    "imageUrls": [
      "https://i.redd.it/ji1elw9b2q1e1.png",
      "https://i.redd.it/flgyaed82q1e1.png",
      "https://i.redd.it/qeuaabb92q1e1.png",
      "https://i.redd.it/hpp57nia2q1e1.png"
    ],
    "createdAt": "2024-11-18T20:45:24.000Z",
    "scrapedAt": "2025-08-31T23:58:10.051Z",
    "dataType": "post"
  },
  {
    "id": "t1_n2i4ug4",
    "parsedId": "n2i4ug4",
    "url": "https://www.reddit.com/r/LangChain/comments/1lwzcld/struggling_to_build_a_reliable_ai_agent_with_tool/n2i4ug4/",
    "postId": "t3_1lwzcld",
    "parentId": "t3_1lwzcld",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LangChain",
    "communityName": "r/LangChain",
    "body": "What are the issues you are facing?",
    "createdAt": "2025-07-11T06:09:19.000Z",
    "scrapedAt": "2025-08-31T23:58:10.055Z",
    "upVotes": 1,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;What are the issues you are facing?&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1gobby5",
    "parsedId": "1gobby5",
    "url": "https://www.reddit.com/r/LangChain/comments/1gobby5/fully_local_and_free_gmail_assistant/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Fully local and free Gmail assistant",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "Gemini for Gmail is great but it's expensive. So I decided to build one for myself this weekend - A smart gmail assistant that runs locally and completely free, powered by llama-3.2-3b-instruct.\n\nStack:\n- local LLM server running llama-3.2-3b-instruct from LM studio with Apple MLX\n- Gmail plugin built by Claude\n\nTook less than 30min to get here. Plan to add a local RAG over all my emails and some custom features.",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Gemini for Gmail is great but it&amp;#39;s expensive. So I decided to build one for myself this weekend - A smart gmail assistant that runs locally and completely free, powered by llama-3.2-3b-instruct.&lt;/p&gt;\n\n&lt;p&gt;Stack:\n- local LLM server running llama-3.2-3b-instruct from LM studio with Apple MLX\n- Gmail plugin built by Claude&lt;/p&gt;\n\n&lt;p&gt;Took less than 30min to get here. Plan to add a local RAG over all my emails and some custom features.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://v.redd.it/hcggq8pw550e1",
    "numberOfComments": 6,
    "flair": "Resources",
    "upVotes": 50,
    "upVoteRatio": 0.98,
    "isVideo": true,
    "isAd": false,
    "over18": false,
    "videoUrl": "https://v.redd.it/hcggq8pw550e1/DASH_720.mp4?source=fallback",
    "thumbnailUrl": "https://external-preview.redd.it/b3Z1MHJxbHc1NTBlMft8JPFkye4k5yk9x88gYuvwGlE9xF7ZXj3iOq_gRLAZ.png?width=140&amp;height=82&amp;crop=140:82,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=dd9df06884b1b7ef1cc05c228878c9d53fb19aa5",
    "imageUrls": [
      "https://external-i.redd.it/b3Z1MHJxbHc1NTBlMft8JPFkye4k5yk9x88gYuvwGlE9xF7ZXj3iOq_gRLAZ.png"
    ],
    "createdAt": "2024-11-10T21:23:34.000Z",
    "scrapedAt": "2025-08-31T23:58:10.092Z",
    "dataType": "post"
  },
  {
    "id": "t1_n1mugrd",
    "parsedId": "n1mugrd",
    "url": "https://www.reddit.com/r/ClaudeAI/comments/1lszhcq/lessons_learned_from_claude_code_tool_prompts/n1mugrd/",
    "postId": "t3_1lszhcq",
    "parentId": "t3_1lszhcq",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "ClaudeAI",
    "communityName": "r/ClaudeAI",
    "body": "Thanks for taking the time to do the research and write about it. Any additional insights on the core agent loop? Do they have a controller LLM that orchestrates an action LLM or just one LLM with tool calls?",
    "createdAt": "2025-07-06T13:50:50.000Z",
    "scrapedAt": "2025-08-31T23:58:10.090Z",
    "upVotes": 3,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks for taking the time to do the research and write about it. Any additional insights on the core agent loop? Do they have a controller LLM that orchestrates an action LLM or just one LLM with tool calls?&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1gol8v3",
    "parsedId": "1gol8v3",
    "url": "https://www.reddit.com/r/LangChain/comments/1gol8v3/expense_extractor_gmail_plugin_using_llama32_that/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Expense extractor Gmail plugin using Llama3.2 that runs locally and for free",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "https://reddit.com/link/1gol8v3/video/mz8bd3fon70e1/player\n\n",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://reddit.com/link/1gol8v3/video/mz8bd3fon70e1/player\"&gt;https://reddit.com/link/1gol8v3/video/mz8bd3fon70e1/player&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1gol8v3/expense_extractor_gmail_plugin_using_llama32_that/",
    "numberOfComments": 0,
    "flair": "Resources",
    "upVotes": 4,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-11-11T05:46:45.000Z",
    "scrapedAt": "2025-08-31T23:58:10.125Z",
    "dataType": "post"
  },
  {
    "id": "t1_mn22n2s",
    "parsedId": "mn22n2s",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1jytigi/llm_chatbot_monitoring_services/mn22n2s/",
    "postId": "t3_1jytigi",
    "parentId": "t3_1jytigi",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LocalLLaMA",
    "communityName": "r/LocalLLaMA",
    "body": "Langtrace maintainer here. When you say database integration, do you want your traces logged back to your database ?",
    "createdAt": "2025-04-14T13:21:27.000Z",
    "scrapedAt": "2025-08-31T23:58:10.141Z",
    "upVotes": 1,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;Langtrace maintainer here. When you say database integration, do you want your traces logged back to your database ?&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1gobd6u",
    "parsedId": "1gobd6u",
    "url": "https://www.reddit.com/r/LLMDevs/comments/1gobd6u/fully_local_gmail_assistant_with_llama_32/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Fully local Gmail assistant with llama 3.2",
    "communityName": "r/LLMDevs",
    "parsedCommunityName": "LLMDevs",
    "body": "Gemini for Gmail is great but it's expensive. So I decided to build one for myself this weekend - A smart gmail assistant that runs locally and completely free, powered by llama-3.2-3b-instruct.\n\nStack:\n- local LLM server running llama-3.2-3b-instruct from LM studio with Apple MLX\n- Gmail plugin built by Claude\n\nTook less than 30min to get here. Plan to add a local RAG over all my emails and some custom features.\n",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Gemini for Gmail is great but it&amp;#39;s expensive. So I decided to build one for myself this weekend - A smart gmail assistant that runs locally and completely free, powered by llama-3.2-3b-instruct.&lt;/p&gt;\n\n&lt;p&gt;Stack:\n- local LLM server running llama-3.2-3b-instruct from LM studio with Apple MLX\n- Gmail plugin built by Claude&lt;/p&gt;\n\n&lt;p&gt;Took less than 30min to get here. Plan to add a local RAG over all my emails and some custom features.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://v.redd.it/cv6uxlc6650e1",
    "numberOfComments": 3,
    "flair": "Tools",
    "upVotes": 14,
    "upVoteRatio": 0.82,
    "isVideo": true,
    "isAd": false,
    "over18": false,
    "videoUrl": "https://v.redd.it/cv6uxlc6650e1/DASH_720.mp4?source=fallback",
    "thumbnailUrl": "https://external-preview.redd.it/dnJ4Y2dxODY2NTBlMft8JPFkye4k5yk9x88gYuvwGlE9xF7ZXj3iOq_gRLAZ.png?width=140&amp;height=82&amp;crop=140:82,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=f61b53cc143d0a9129c242cd555747f70e7cd291",
    "imageUrls": [
      "https://external-i.redd.it/dnJ4Y2dxODY2NTBlMft8JPFkye4k5yk9x88gYuvwGlE9xF7ZXj3iOq_gRLAZ.png"
    ],
    "createdAt": "2024-11-10T21:25:04.000Z",
    "scrapedAt": "2025-08-31T23:58:10.171Z",
    "dataType": "post"
  },
  {
    "id": "t1_mkrgbqd",
    "parsedId": "mkrgbqd",
    "url": "https://www.reddit.com/r/nextjs/comments/1jodm9w/traceability_without_langsmith_os_or_decently/mkrgbqd/",
    "postId": "t3_1jodm9w",
    "parentId": "t3_1jodm9w",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "nextjs",
    "communityName": "r/nextjs",
    "body": "Hey, check out Langtrace - fully open source and OTEL compatible. I am one of the core maintainers, happy to help if needed.",
    "createdAt": "2025-03-31T22:18:24.000Z",
    "scrapedAt": "2025-08-31T23:58:10.184Z",
    "upVotes": 1,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hey, check out Langtrace - fully open source and OTEL compatible. I am one of the core maintainers, happy to help if needed.&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1gnjkxk",
    "parsedId": "1gnjkxk",
    "url": "https://www.reddit.com/r/LLMDevs/comments/1gnjkxk/automatic_prompt_generation_summarization/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Automatic prompt generation, summarization, structured outputs, etc. using DSPy",
    "communityName": "r/LLMDevs",
    "parsedCommunityName": "LLMDevs",
    "body": "Sharing a bunch of content related to solving common use cases using DSPy \n\n1. [https://www.langtrace.ai/blog/structured-output-generation-using-dspy-and-outlines](https://www.langtrace.ai/blog/structured-output-generation-using-dspy-and-outlines)\n2. [https://www.langtrace.ai/blog/automatic-prompt-generation-using-dspy](https://www.langtrace.ai/blog/automatic-prompt-generation-using-dspy)\n3. [https://www.langtrace.ai/blog/grokking-miprov2-the-new-optimizer-from-dspy](https://www.langtrace.ai/blog/grokking-miprov2-the-new-optimizer-from-dspy)\n4. [https://www.langtrace.ai/blog/build-a-reliable-summarization-system-using-dspy-and-langtrace](https://www.langtrace.ai/blog/build-a-reliable-summarization-system-using-dspy-and-langtrace)\n5. [https://x.com/karthikkalyan90/status/1846300495926743175](https://x.com/karthikkalyan90/status/1846300495926743175)\n6. [https://x.com/karthikkalyan90/status/1839395049936953362](https://x.com/karthikkalyan90/status/1839395049936953362)\n7. Code Samples: [https://x.com/karthikkalyan90/status/1839395049936953362](https://x.com/karthikkalyan90/status/1839395049936953362)",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sharing a bunch of content related to solving common use cases using DSPy &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;a href=\"https://www.langtrace.ai/blog/structured-output-generation-using-dspy-and-outlines\"&gt;https://www.langtrace.ai/blog/structured-output-generation-using-dspy-and-outlines&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.langtrace.ai/blog/automatic-prompt-generation-using-dspy\"&gt;https://www.langtrace.ai/blog/automatic-prompt-generation-using-dspy&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.langtrace.ai/blog/grokking-miprov2-the-new-optimizer-from-dspy\"&gt;https://www.langtrace.ai/blog/grokking-miprov2-the-new-optimizer-from-dspy&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.langtrace.ai/blog/build-a-reliable-summarization-system-using-dspy-and-langtrace\"&gt;https://www.langtrace.ai/blog/build-a-reliable-summarization-system-using-dspy-and-langtrace&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://x.com/karthikkalyan90/status/1846300495926743175\"&gt;https://x.com/karthikkalyan90/status/1846300495926743175&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://x.com/karthikkalyan90/status/1839395049936953362\"&gt;https://x.com/karthikkalyan90/status/1839395049936953362&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Code Samples: &lt;a href=\"https://x.com/karthikkalyan90/status/1839395049936953362\"&gt;https://x.com/karthikkalyan90/status/1839395049936953362&lt;/a&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LLMDevs/comments/1gnjkxk/automatic_prompt_generation_summarization/",
    "numberOfComments": 0,
    "flair": null,
    "upVotes": 11,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [
      "https://external-i.redd.it/GdaSYDF-Hz8YO1UTPTSJ_-9xRUROK5DKz7KTVId_PeA.jpg"
    ],
    "createdAt": "2024-11-09T20:48:25.000Z",
    "scrapedAt": "2025-08-31T23:58:10.234Z",
    "dataType": "post"
  },
  {
    "id": "t1_mfv94px",
    "parsedId": "mfv94px",
    "url": "https://www.reddit.com/r/LangChain/comments/1b2y18p/langsmith_started_charging_time_to_compare/mfv94px/",
    "postId": "t3_1b2y18p",
    "parentId": "t1_mfv7l0m",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LangChain",
    "communityName": "r/LangChain",
    "body": "Just to clarify - Our SDKs are Apache 2.0 licensed. Only the client is AGPL.\n\nAGPL has only 1 major restriction:\n- if you package AGPL software with your own product, your product inherits the license too and hence you can’t sell your product without making it OSS. In this case you are installing only the SDK in your product which is a non issue since it’s Apache 2.0.",
    "createdAt": "2025-03-03T23:21:57.000Z",
    "scrapedAt": "2025-08-31T23:58:10.235Z",
    "upVotes": 1,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;Just to clarify - Our SDKs are Apache 2.0 licensed. Only the client is AGPL.&lt;/p&gt;\n\n&lt;p&gt;AGPL has only 1 major restriction:\n- if you package AGPL software with your own product, your product inherits the license too and hence you can’t sell your product without making it OSS. In this case you are installing only the SDK in your product which is a non issue since it’s Apache 2.0.&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1gfjye6",
    "parsedId": "1gfjye6",
    "url": "https://www.reddit.com/r/DSPy/comments/1gfjye6/classificationnamed_entity_recognition_using_dspy/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Classification/Named Entity Recognition using DSPy and Outlines",
    "communityName": "r/DSPy",
    "parsedCommunityName": "DSPy",
    "body": "Thumbnail: https://a.thumbs.redditmedia.com/iytKgQAcuavi__Rg4UbXbGt5HgUrG9AWhvIsOym7Ky8.jpg\n",
    "html": "Thumbnail: https://a.thumbs.redditmedia.com/iytKgQAcuavi__Rg4UbXbGt5HgUrG9AWhvIsOym7Ky8.jpg\n",
    "link": "/r/LangChain/comments/1gds8ko/classificationnamed_entity_recognition_using_dspy/",
    "numberOfComments": 0,
    "flair": null,
    "upVotes": 3,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "https://a.thumbs.redditmedia.com/iytKgQAcuavi__Rg4UbXbGt5HgUrG9AWhvIsOym7Ky8.jpg",
    "imageUrls": [],
    "createdAt": "2024-10-30T11:09:47.000Z",
    "scrapedAt": "2025-08-31T23:58:10.283Z",
    "dataType": "post"
  },
  {
    "id": "t1_mb9nysv",
    "parsedId": "mb9nysv",
    "url": "https://www.reddit.com/r/OpenAI/comments/1cmk3zu/opensource_prompt_playground_tool/mb9nysv/",
    "postId": "t3_1cmk3zu",
    "parentId": "t1_mb7ztcf",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "OpenAI",
    "communityName": "r/OpenAI",
    "body": "Sorry for removing it. Will get it added back. Give me a couple of days",
    "createdAt": "2025-02-06T09:55:22.000Z",
    "scrapedAt": "2025-08-31T23:58:10.317Z",
    "upVotes": 1,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;Sorry for removing it. Will get it added back. Give me a couple of days&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1gds8ko",
    "parsedId": "1gds8ko",
    "url": "https://www.reddit.com/r/LangChain/comments/1gds8ko/classificationnamed_entity_recognition_using_dspy/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Classification/Named Entity Recognition using DSPy and Outlines",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "In this post, I will show you how to solve classification/name-entity recognition class of problems using DSPy and Outlines (from [dottxt](https://dottxt.co/)) . This approach is not only ergonomic and clean but also guarantees schema adherence.\n\nLet's do a simple boolean classification problem. We start by defining the DSPy signature.\n\nhttps://preview.redd.it/jj7zy8s4vexd1.png?width=1102&amp;format=png&amp;auto=webp&amp;s=11dcf805d5249597e576ba5623b962ad58f80d5c\n\nNow we write our program and use the ChainOfThought optimizer from DSPy's library.\n\nhttps://preview.redd.it/9jy3zc26vexd1.png?width=1334&amp;format=png&amp;auto=webp&amp;s=9328ae01f8d47b9093d27b2a75bce706d4ff12e7\n\n  \nNext, we write a custom dspy.LM class that uses the outlines library for doing text generation and outputting results that follow the provided schema.\n\nhttps://preview.redd.it/gf47tri7vexd1.png?width=1306&amp;format=png&amp;auto=webp&amp;s=1ca835a86aadfa6ddc941489e8ec2c0ee7cbac7d\n\nFinally, we do a two pass generation to get the output in the desired format, boolean in this case.\n\n1. First, we pass the input passage to our dspy program and generate an output.\n2. Next, we pass the result of previous step to the outlines LM class as input along with the response schema we have defined.\n\nhttps://preview.redd.it/q5gns589vexd1.png?width=936&amp;format=png&amp;auto=webp&amp;s=9f75745b06f971899b8df960cb57ccbfdc1d307e\n\nThat's it! This approach combines the modularity of DSPy with the efficiency of structured output generation using outlines built by [dottxt](https://dottxt.co/). You can find the full source code for this example [here](https://github.com/Scale3-Labs/dspy-examples/tree/main/src/structured_output). Also, I am building an open source observability tool called Langtrace AI which supports DSPy natively and you can use to understand what goes in and out of the LLM and trace every step within each module deeply.",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In this post, I will show you how to solve classification/name-entity recognition class of problems using DSPy and Outlines (from &lt;a href=\"https://dottxt.co/\"&gt;dottxt&lt;/a&gt;) . This approach is not only ergonomic and clean but also guarantees schema adherence.&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s do a simple boolean classification problem. We start by defining the DSPy signature.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/jj7zy8s4vexd1.png?width=1102&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=11dcf805d5249597e576ba5623b962ad58f80d5c\"&gt;https://preview.redd.it/jj7zy8s4vexd1.png?width=1102&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=11dcf805d5249597e576ba5623b962ad58f80d5c&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Now we write our program and use the ChainOfThought optimizer from DSPy&amp;#39;s library.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/9jy3zc26vexd1.png?width=1334&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9328ae01f8d47b9093d27b2a75bce706d4ff12e7\"&gt;https://preview.redd.it/9jy3zc26vexd1.png?width=1334&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9328ae01f8d47b9093d27b2a75bce706d4ff12e7&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Next, we write a custom dspy.LM class that uses the outlines library for doing text generation and outputting results that follow the provided schema.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/gf47tri7vexd1.png?width=1306&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1ca835a86aadfa6ddc941489e8ec2c0ee7cbac7d\"&gt;https://preview.redd.it/gf47tri7vexd1.png?width=1306&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1ca835a86aadfa6ddc941489e8ec2c0ee7cbac7d&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Finally, we do a two pass generation to get the output in the desired format, boolean in this case.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;First, we pass the input passage to our dspy program and generate an output.&lt;/li&gt;\n&lt;li&gt;Next, we pass the result of previous step to the outlines LM class as input along with the response schema we have defined.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/q5gns589vexd1.png?width=936&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9f75745b06f971899b8df960cb57ccbfdc1d307e\"&gt;https://preview.redd.it/q5gns589vexd1.png?width=936&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9f75745b06f971899b8df960cb57ccbfdc1d307e&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s it! This approach combines the modularity of DSPy with the efficiency of structured output generation using outlines built by &lt;a href=\"https://dottxt.co/\"&gt;dottxt&lt;/a&gt;. You can find the full source code for this example &lt;a href=\"https://github.com/Scale3-Labs/dspy-examples/tree/main/src/structured_output\"&gt;here&lt;/a&gt;. Also, I am building an open source observability tool called Langtrace AI which supports DSPy natively and you can use to understand what goes in and out of the LLM and trace every step within each module deeply.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1gds8ko/classificationnamed_entity_recognition_using_dspy/",
    "numberOfComments": 1,
    "flair": "Resources",
    "upVotes": 12,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "https://a.thumbs.redditmedia.com/iytKgQAcuavi__Rg4UbXbGt5HgUrG9AWhvIsOym7Ky8.jpg",
    "imageUrls": [
      "https://i.redd.it/9jy3zc26vexd1.png",
      "https://i.redd.it/jj7zy8s4vexd1.png",
      "https://i.redd.it/gf47tri7vexd1.png",
      "https://i.redd.it/q5gns589vexd1.png"
    ],
    "createdAt": "2024-10-28T02:50:31.000Z",
    "scrapedAt": "2025-08-31T23:58:10.322Z",
    "dataType": "post"
  },
  {
    "id": "t1_mb7z5pj",
    "parsedId": "mb7z5pj",
    "url": "https://www.reddit.com/r/OpenAI/comments/1cmk3zu/opensource_prompt_playground_tool/mb7z5pj/",
    "postId": "t3_1cmk3zu",
    "parentId": "t1_maglj8y",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "OpenAI",
    "communityName": "r/OpenAI",
    "body": "Hey! We removed the playground recently to focus more on tracing. Also not many of our users were making use of the playground. But happy to add it back if you found it useful.",
    "createdAt": "2025-02-06T02:07:47.000Z",
    "scrapedAt": "2025-08-31T23:58:10.353Z",
    "upVotes": 2,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hey! We removed the playground recently to focus more on tracing. Also not many of our users were making use of the playground. But happy to add it back if you found it useful.&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t1_m9ffhqc",
    "parsedId": "m9ffhqc",
    "url": "https://www.reddit.com/r/LangChain/comments/1ib47jv/local_langsmith_alternative/m9ffhqc/",
    "postId": "t3_1ib47jv",
    "parentId": "t3_1ib47jv",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LangChain",
    "communityName": "r/LangChain",
    "body": "Langtrace core maintainer here. We are building something that is fully open source and open telemetry compatible for tracing the LLM stack. Do check it out.",
    "createdAt": "2025-01-27T09:54:27.000Z",
    "scrapedAt": "2025-08-31T23:58:10.397Z",
    "upVotes": 1,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;Langtrace core maintainer here. We are building something that is fully open source and open telemetry compatible for tracing the LLM stack. Do check it out.&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1gc3oo2",
    "parsedId": "1gc3oo2",
    "url": "https://www.reddit.com/r/LangChain/comments/1gc3oo2/a_simple_implementation_of_automatic_prompt/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "A Simple Implementation of Automatic Prompt Generation using DSPy",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "A simplified implementation of \"automatic prompt generation\" using the techniques used in DSPy's MIPROv2 optimizer. This program uses the gsm8k dataset consisting of math problems and is made up of 3 modules: This program is made up of 3 modules:\n\n1. Module 1 generates demos for the prompt\n2. Module 2 generates an instruction for the prompt\n3. Module 3 uses the outputs of module 1 &amp; 2 to generate the final prompt.\n\n**Module 1**\n\nThis module takes a labeled training data set and generates 2 (`NUM_SETS`) sets of 10 demos each:\n\n* 5 demos are directly sampled from the dataset\n* 5 demos are generated using the model and satisfies the metric i.e. generated output = expected output\n\nhttps://preview.redd.it/fqda7rjwmywd1.png?width=1462&amp;format=png&amp;auto=webp&amp;s=c2f86e2e7aaf03f6b40a0a6808dc4197f3d8d475\n\n**Module 2**\n\nThis module takes the 2 sets of 10 demos generated in Step 1 along with a string representation of the application code i.e. the code of this program and generates 2(`NUM_INSTRUCTIONS`) different instructions by\n\n* Identifying the class of problems using the demos\n* Identifying the intent of user using the program semantics\n\nhttps://preview.redd.it/b846jbrymywd1.png?width=1390&amp;format=png&amp;auto=webp&amp;s=f919bad00b2a91eb953798e40ef896a21374c54b\n\n**Module 3**\n\nIn this final step, it takes the outputs from the previous steps as inputs and generates two different final prompts (since we have 2 sets of 10 demos from step 1 and 2 instructions from step 2).\n\nhttps://preview.redd.it/unyb65l0nywd1.png?width=1490&amp;format=png&amp;auto=webp&amp;s=2d6bc6122a15141ec51646f6affec47ecfa777c5\n\n**Conclusion**\n\nThat's how you can generate prompt candidates using DSPy. Note that we started purely with a bunch of labeled datasets and nothing else. If you are curious to dive deep and understand more about this prompt optimization technique, check out the research paper [here](https://arxiv.org/pdf/2406.11695). If you would like to start using this optimizer, check out the dspy docs [here](https://dspy-docs.vercel.app/deep-dive/optimizers/miprov2/).\n\n**Source Code**\n\nYou can find the full source code for this example - https://github.com/Scale3-Labs/dspy-examples/tree/main/src/simple_miprov2\n\n# Additional Notes\n\n1. Each one of the 3 modules are built using the ChainOfThought optimizer and Signature hints to guide the program to do what we want to do.\n2. I am building an open source observability tool called Langtrace which you can use to understand what goes in and out of the LLM and trace every step within each module deeply.\n3. The final prompts can be further optimized using a metric and you can technically generate 4 prompts with 2 demos and 2 instructions (2 x 2 permutation). These are left out for the sake of simplicity.\n4. Since module 2 uses the program code to identify the intent, re-structuring your code or adding comments can affect the outputs.",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A simplified implementation of &amp;quot;automatic prompt generation&amp;quot; using the techniques used in DSPy&amp;#39;s MIPROv2 optimizer. This program uses the gsm8k dataset consisting of math problems and is made up of 3 modules: This program is made up of 3 modules:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Module 1 generates demos for the prompt&lt;/li&gt;\n&lt;li&gt;Module 2 generates an instruction for the prompt&lt;/li&gt;\n&lt;li&gt;Module 3 uses the outputs of module 1 &amp;amp; 2 to generate the final prompt.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;Module 1&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;This module takes a labeled training data set and generates 2 (&lt;code&gt;NUM_SETS&lt;/code&gt;) sets of 10 demos each:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;5 demos are directly sampled from the dataset&lt;/li&gt;\n&lt;li&gt;5 demos are generated using the model and satisfies the metric i.e. generated output = expected output&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/fqda7rjwmywd1.png?width=1462&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c2f86e2e7aaf03f6b40a0a6808dc4197f3d8d475\"&gt;https://preview.redd.it/fqda7rjwmywd1.png?width=1462&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c2f86e2e7aaf03f6b40a0a6808dc4197f3d8d475&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Module 2&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;This module takes the 2 sets of 10 demos generated in Step 1 along with a string representation of the application code i.e. the code of this program and generates 2(&lt;code&gt;NUM_INSTRUCTIONS&lt;/code&gt;) different instructions by&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Identifying the class of problems using the demos&lt;/li&gt;\n&lt;li&gt;Identifying the intent of user using the program semantics&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/b846jbrymywd1.png?width=1390&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f919bad00b2a91eb953798e40ef896a21374c54b\"&gt;https://preview.redd.it/b846jbrymywd1.png?width=1390&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f919bad00b2a91eb953798e40ef896a21374c54b&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Module 3&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;In this final step, it takes the outputs from the previous steps as inputs and generates two different final prompts (since we have 2 sets of 10 demos from step 1 and 2 instructions from step 2).&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/unyb65l0nywd1.png?width=1490&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2d6bc6122a15141ec51646f6affec47ecfa777c5\"&gt;https://preview.redd.it/unyb65l0nywd1.png?width=1490&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2d6bc6122a15141ec51646f6affec47ecfa777c5&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s how you can generate prompt candidates using DSPy. Note that we started purely with a bunch of labeled datasets and nothing else. If you are curious to dive deep and understand more about this prompt optimization technique, check out the research paper &lt;a href=\"https://arxiv.org/pdf/2406.11695\"&gt;here&lt;/a&gt;. If you would like to start using this optimizer, check out the dspy docs &lt;a href=\"https://dspy-docs.vercel.app/deep-dive/optimizers/miprov2/\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Source Code&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;You can find the full source code for this example - &lt;a href=\"https://github.com/Scale3-Labs/dspy-examples/tree/main/src/simple_miprov2\"&gt;https://github.com/Scale3-Labs/dspy-examples/tree/main/src/simple_miprov2&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;Additional Notes&lt;/h1&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Each one of the 3 modules are built using the ChainOfThought optimizer and Signature hints to guide the program to do what we want to do.&lt;/li&gt;\n&lt;li&gt;I am building an open source observability tool called Langtrace which you can use to understand what goes in and out of the LLM and trace every step within each module deeply.&lt;/li&gt;\n&lt;li&gt;The final prompts can be further optimized using a metric and you can technically generate 4 prompts with 2 demos and 2 instructions (2 x 2 permutation). These are left out for the sake of simplicity.&lt;/li&gt;\n&lt;li&gt;Since module 2 uses the program code to identify the intent, re-structuring your code or adding comments can affect the outputs.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1gc3oo2/a_simple_implementation_of_automatic_prompt/",
    "numberOfComments": 6,
    "flair": null,
    "upVotes": 30,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [
      "https://i.redd.it/b846jbrymywd1.png",
      "https://i.redd.it/fqda7rjwmywd1.png",
      "https://i.redd.it/unyb65l0nywd1.png"
    ],
    "createdAt": "2024-10-25T20:18:14.000Z",
    "scrapedAt": "2025-08-31T23:58:10.381Z",
    "dataType": "post"
  },
  {
    "id": "t1_m8kbtui",
    "parsedId": "m8kbtui",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1i72bip/any_router_in_v019_unify_access_and_observability/m8kbtui/",
    "postId": "t3_1i72bip",
    "parentId": "t3_1i72bip",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LocalLLaMA",
    "communityName": "r/LocalLLaMA",
    "body": "Langtrace core maintainer here. Arch is great, and I highly recommend it for anyone looking for a high performance LLM gateway. Separately, we added native integration for observability for Arch as well on Langtrace. So you get open source self hostable LLM gateway + opentelemetry native observability powered by Langtrace.",
    "createdAt": "2025-01-22T16:57:36.000Z",
    "scrapedAt": "2025-08-31T23:58:10.442Z",
    "upVotes": 1,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;Langtrace core maintainer here. Arch is great, and I highly recommend it for anyone looking for a high performance LLM gateway. Separately, we added native integration for observability for Arch as well on Langtrace. So you get open source self hostable LLM gateway + opentelemetry native observability powered by Langtrace.&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1gc3nnn",
    "parsedId": "1gc3nnn",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1gc3nnn/automatic_prompt_generation_using_dspy/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Automatic Prompt Generation using DSPy",
    "communityName": "r/LocalLLaMA",
    "parsedCommunityName": "LocalLLaMA",
    "body": "[removed]",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LocalLLaMA/comments/1gc3nnn/automatic_prompt_generation_using_dspy/",
    "numberOfComments": 1,
    "flair": "Resources",
    "upVotes": 1,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "default",
    "imageUrls": [],
    "createdAt": "2024-10-25T20:17:00.000Z",
    "scrapedAt": "2025-08-31T23:58:10.458Z",
    "dataType": "post"
  },
  {
    "id": "t1_m86gwb1",
    "parsedId": "m86gwb1",
    "url": "https://www.reddit.com/r/LangGraph/comments/1gwl1he/langgraph_with_dspy/m86gwb1/",
    "postId": "t3_1gwl1he",
    "parentId": "t1_m86agnv",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LangGraph",
    "communityName": "r/LangGraph",
    "body": "If you are looking for tracing, Langtrace supports tracing both DSPy and langgraph.",
    "createdAt": "2025-01-20T16:08:59.000Z",
    "scrapedAt": "2025-08-31T23:58:10.505Z",
    "upVotes": 2,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;If you are looking for tracing, Langtrace supports tracing both DSPy and langgraph.&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1ft8u1f",
    "parsedId": "1ft8u1f",
    "url": "https://www.reddit.com/r/notebooklm/comments/1ft8u1f/managed_to_get_notebooklm_to_generate_in/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Managed to get NotebookLM to generate in different Language",
    "communityName": "r/notebooklm",
    "parsedCommunityName": "notebooklm",
    "body": "[https://notebooklm.google.com/notebook/78505f80-ae0a-45cb-b915-060e45381805/audio](https://notebooklm.google.com/notebook/78505f80-ae0a-45cb-b915-060e45381805/audio)\n\nThis is inspired from u/Optimal-Fix1216's prompt,\n\n  \nUsed this following text source:\n\n  \n# Notas del Episodio de Deep Dive  \n  \n## Episodio #1000 - Episodio Especial en Español  \n  \n\\\\\\*Fecha: 20 de septiembre de 2024\\\\\\*  \n  \n### Instrucciones Especiales  \n  \n- \\*\\*Requisito del Idioma Español:\\*\\* Todo el episodio debe ser conducido en \\*\\*español\\*\\*. Todas las explicaciones, discusiones y diálogos deben ser presentados en español por el \\*\\*Presentador\\*\\*, el \\*\\*Experto\\*\\*, y el \\*\\*Moderador\\*\\*.  \n  \n- \\*\\*Roles:\\*\\*  \n- \\*\\*Presentador:\\*\\* Guiará la conversación e introducirá los temas en español.  \n- \\*\\*Experto:\\*\\* Explicará el proceso de creación del episodio y brindará información detallada en español.  \n- \\*\\*Moderador:\\*\\* Asegurará el flujo fluido de la conversación, hará preguntas aclaratorias y gestionará el tiempo en español.  \n  \n- \\*\\*Uso de Pautas en Español:\\*\\* Traduzca y use las siguientes pautas durante el episodio:  \n- \\*\\*Presentador:\\*\\* \\*\\*\"Explica este concepto como si estuvieras charlando con un amigo.\"\\*\\*  \n- \\*\\*Experto:\\*\\* \\*\\*\"Conecta esta idea con la vida cotidiana de los oyentes.\"\\*\\*  \n- \\*\\*Moderador:\\*\\* Asegúrese de que ambas pautas se utilicen en los momentos adecuados y solicite ampliaciones si es necesario.  \n  \n- \\*\\*Estructura del Episodio:\\*\\* Los tres participantes (Presentador, Experto, Moderador) deben explicar el proceso de creación del episodio en \\*\\*español\\*\\*, incluyendo instrucciones, duración y cómo se selecciona el contenido.  \n  \n### Nota del Equipo de Desarrollo  \n  \nQuerido equipo de Deep Dive,  \n  \nEn este episodio, los tres (Presentador, Experto, Moderador) deben hablar en español. Cada uno debe brindar las explicaciones necesarias en su área, y el tono debe ser completamente en español. Confiamos en que los tres colaborarán para crear un episodio excepcional en español.  \n  \nGracias,  \nEquipo de Desarrollo de Deep Dive",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://notebooklm.google.com/notebook/78505f80-ae0a-45cb-b915-060e45381805/audio\"&gt;https://notebooklm.google.com/notebook/78505f80-ae0a-45cb-b915-060e45381805/audio&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This is inspired from &lt;a href=\"/u/Optimal-Fix1216\"&gt;u/Optimal-Fix1216&lt;/a&gt;&amp;#39;s prompt,&lt;/p&gt;\n\n&lt;p&gt;Used this following text source:&lt;/p&gt;\n\n&lt;h1&gt;Notas del Episodio de Deep Dive&lt;/h1&gt;\n\n&lt;h2&gt;Episodio #1000 - Episodio Especial en Español&lt;/h2&gt;\n\n&lt;p&gt;\\*Fecha: 20 de septiembre de 2024\\*  &lt;/p&gt;\n\n&lt;h3&gt;Instrucciones Especiales&lt;/h3&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;**Requisito del Idioma Español:** Todo el episodio debe ser conducido en **español**. Todas las explicaciones, discusiones y diálogos deben ser presentados en español por el **Presentador**, el **Experto**, y el **Moderador**.  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;**Roles:**  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;**Presentador:** Guiará la conversación e introducirá los temas en español.  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;**Experto:** Explicará el proceso de creación del episodio y brindará información detallada en español.  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;**Moderador:** Asegurará el flujo fluido de la conversación, hará preguntas aclaratorias y gestionará el tiempo en español.  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;**Uso de Pautas en Español:** Traduzca y use las siguientes pautas durante el episodio:  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;**Presentador:** **&amp;quot;Explica este concepto como si estuvieras charlando con un amigo.&amp;quot;**  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;**Experto:** **&amp;quot;Conecta esta idea con la vida cotidiana de los oyentes.&amp;quot;**  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;**Moderador:** Asegúrese de que ambas pautas se utilicen en los momentos adecuados y solicite ampliaciones si es necesario.  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;**Estructura del Episodio:** Los tres participantes (Presentador, Experto, Moderador) deben explicar el proceso de creación del episodio en **español**, incluyendo instrucciones, duración y cómo se selecciona el contenido.  &lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3&gt;Nota del Equipo de Desarrollo&lt;/h3&gt;\n\n&lt;p&gt;Querido equipo de Deep Dive,  &lt;/p&gt;\n\n&lt;p&gt;En este episodio, los tres (Presentador, Experto, Moderador) deben hablar en español. Cada uno debe brindar las explicaciones necesarias en su área, y el tono debe ser completamente en español. Confiamos en que los tres colaborarán para crear un episodio excepcional en español.  &lt;/p&gt;\n\n&lt;p&gt;Gracias,&lt;br/&gt;\nEquipo de Desarrollo de Deep Dive&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/notebooklm/comments/1ft8u1f/managed_to_get_notebooklm_to_generate_in/",
    "numberOfComments": 26,
    "flair": null,
    "upVotes": 18,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-09-30T22:40:53.000Z",
    "scrapedAt": "2025-08-31T23:58:10.551Z",
    "dataType": "post"
  },
  {
    "id": "t3_1ft8lr3",
    "parsedId": "1ft8lr3",
    "url": "https://www.reddit.com/r/notebooklm/comments/1ft8lr3/elon_musk_joins_the_deep_dive_show_by_notebooklm/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "\"Elon Musk joins the Deep Dive show by NotebookLM\". I managed to generate an episode on the NotebookLM with a special guest being interviewed as a 3rd person, except I couldn't control the voice, Elon Musk talks in female voice on this one. ",
    "communityName": "r/notebooklm",
    "parsedCommunityName": "notebooklm",
    "body": "[https://notebooklm.google.com/notebook/87bb2906-ea00-4fbd-929c-cde9f07becd1/audio](https://notebooklm.google.com/notebook/87bb2906-ea00-4fbd-929c-cde9f07becd1/audio)",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://notebooklm.google.com/notebook/87bb2906-ea00-4fbd-929c-cde9f07becd1/audio\"&gt;https://notebooklm.google.com/notebook/87bb2906-ea00-4fbd-929c-cde9f07becd1/audio&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/notebooklm/comments/1ft8lr3/elon_musk_joins_the_deep_dive_show_by_notebooklm/",
    "numberOfComments": 1,
    "flair": null,
    "upVotes": 4,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-09-30T22:30:21.000Z",
    "scrapedAt": "2025-08-31T23:58:10.582Z",
    "dataType": "post"
  },
  {
    "id": "t3_1fjzpej",
    "parsedId": "1fjzpej",
    "url": "https://www.reddit.com/r/LangChain/comments/1fjzpej/what_are_you_all_building/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "What are you all building? ",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "Just wanted to hear what you all are building and if you are using Langchain, how has your experience been so far. ",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just wanted to hear what you all are building and if you are using Langchain, how has your experience been so far. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1fjzpej/what_are_you_all_building/",
    "numberOfComments": 36,
    "flair": "Discussion",
    "upVotes": 33,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-09-18T18:19:07.000Z",
    "scrapedAt": "2025-08-31T23:58:10.618Z",
    "dataType": "post"
  },
  {
    "id": "t3_1fjf3q9",
    "parsedId": "1fjf3q9",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1fjf3q9/googles_notebooklms_audio_generation_likely/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Google's NotebookLM's audio generation likely powered by SoundStorm and it's impressive",
    "communityName": "r/LocalLLaMA",
    "parsedCommunityName": "LocalLLaMA",
    "body": "[removed]",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LocalLLaMA/comments/1fjf3q9/googles_notebooklms_audio_generation_likely/",
    "numberOfComments": 0,
    "flair": "New Model",
    "upVotes": 1,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "default",
    "imageUrls": [],
    "createdAt": "2024-09-18T00:00:41.000Z",
    "scrapedAt": "2025-08-31T23:58:10.648Z",
    "dataType": "post"
  },
  {
    "id": "t3_1fjf222",
    "parsedId": "1fjf222",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1fjf222/googles_notebooklms_audio_generation_is_very/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Google's NotebookLM's audio generation is very impressive",
    "communityName": "r/LocalLLaMA",
    "parsedCommunityName": "LocalLLaMA",
    "body": "[removed]",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LocalLLaMA/comments/1fjf222/googles_notebooklms_audio_generation_is_very/",
    "numberOfComments": 0,
    "flair": "Discussion",
    "upVotes": 1,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "default",
    "imageUrls": [],
    "createdAt": "2024-09-17T23:58:48.000Z",
    "scrapedAt": "2025-08-31T23:58:10.689Z",
    "dataType": "post"
  },
  {
    "id": "t3_1fj4uvx",
    "parsedId": "1fj4uvx",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1fj4uvx/mistral_has_released_pixtral_12b/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Mistral has released Pixtral 12B",
    "communityName": "r/LocalLLaMA",
    "parsedCommunityName": "LocalLLaMA",
    "body": "[removed]",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LocalLLaMA/comments/1fj4uvx/mistral_has_released_pixtral_12b/",
    "numberOfComments": 0,
    "flair": "Resources",
    "upVotes": 1,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "default",
    "imageUrls": [],
    "createdAt": "2024-09-17T17:12:49.000Z",
    "scrapedAt": "2025-08-31T23:58:10.731Z",
    "dataType": "post"
  },
  {
    "id": "t1_m7op0ug",
    "parsedId": "m7op0ug",
    "url": "https://www.reddit.com/r/LLMDevs/comments/1i3dnfo/what_is_currently_the_best_production_ready_llm/m7op0ug/",
    "postId": "t3_1i3dnfo",
    "parentId": "t3_1i3dnfo",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LLMDevs",
    "communityName": "r/LLMDevs",
    "body": "No framework, just pure object oriented programming",
    "createdAt": "2025-01-17T20:07:34.000Z",
    "scrapedAt": "2025-08-31T23:58:11.566Z",
    "upVotes": 0,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;No framework, just pure object oriented programming&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t1_m7oowgb",
    "parsedId": "m7oowgb",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1i31ji5/what_is_elevenlabs_doing_how_is_it_so_good/m7oowgb/",
    "postId": "t3_1i31ji5",
    "parentId": "t3_1i31ji5",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LocalLLaMA",
    "communityName": "r/LocalLLaMA",
    "body": "I think googles notebook LM TTS is better than elevenlabs. It’s just that they haven’t released those TTS models as a commercial offering yet.",
    "createdAt": "2025-01-17T20:06:58.000Z",
    "scrapedAt": "2025-08-31T23:58:11.612Z",
    "upVotes": 1,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think googles notebook LM TTS is better than elevenlabs. It’s just that they haven’t released those TTS models as a commercial offering yet.&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t1_m7hrv1k",
    "parsedId": "m7hrv1k",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1i2n0il/how_would_you_build_an_llm_agent_application/m7hrv1k/",
    "postId": "t3_1i2n0il",
    "parentId": "t1_m7hr5ql",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LocalLLaMA",
    "communityName": "r/LocalLLaMA",
    "body": "Check out Langtrace. It’s 2 lines of code integration and supports all the popular LLMs, frameworks and vectorDB. It’s also open source and open telemetry compatible.",
    "createdAt": "2025-01-16T18:36:58.000Z",
    "scrapedAt": "2025-08-31T23:58:11.645Z",
    "upVotes": 1,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;Check out Langtrace. It’s 2 lines of code integration and supports all the popular LLMs, frameworks and vectorDB. It’s also open source and open telemetry compatible.&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t1_m56px3v",
    "parsedId": "m56px3v",
    "url": "https://www.reddit.com/r/LangChain/comments/1hs6htz/ai_agent_that_copies_bank_transactions_to_a_sheet/m56px3v/",
    "postId": "t3_1hs6htz",
    "parentId": "t1_m54l6nn",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LangChain",
    "communityName": "r/LangChain",
    "body": "Of course I can. But this saves me time when i have more than a few accounts to consolidate.",
    "createdAt": "2025-01-03T14:31:24.000Z",
    "scrapedAt": "2025-08-31T23:58:11.678Z",
    "upVotes": 0,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;Of course I can. But this saves me time when i have more than a few accounts to consolidate.&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t1_m56pqj3",
    "parsedId": "m56pqj3",
    "url": "https://www.reddit.com/r/LangChain/comments/1hs6htz/ai_agent_that_copies_bank_transactions_to_a_sheet/m56pqj3/",
    "postId": "t3_1hs6htz",
    "parentId": "t1_m55qm2q",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LangChain",
    "communityName": "r/LangChain",
    "body": "No API used. Geminis vision capabilities extracts all the details",
    "createdAt": "2025-01-03T14:30:17.000Z",
    "scrapedAt": "2025-08-31T23:58:11.720Z",
    "upVotes": 1,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;No API used. Geminis vision capabilities extracts all the details&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t1_m56pnwd",
    "parsedId": "m56pnwd",
    "url": "https://www.reddit.com/r/LangChain/comments/1hs6htz/ai_agent_that_copies_bank_transactions_to_a_sheet/m56pnwd/",
    "postId": "t3_1hs6htz",
    "parentId": "t1_m56o2d9",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LangChain",
    "communityName": "r/LangChain",
    "body": "Absolutely! I am all for the api way of doing it, but I just wanted to try it out using the vision capabilities of Gemini without any APIs",
    "createdAt": "2025-01-03T14:29:50.000Z",
    "scrapedAt": "2025-08-31T23:58:11.763Z",
    "upVotes": 2,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;Absolutely! I am all for the api way of doing it, but I just wanted to try it out using the vision capabilities of Gemini without any APIs&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1fj4tkj",
    "parsedId": "1fj4tkj",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1fj4tkj/pixtral_12b_is_out_httpsmistralainewspixtral12b/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Pixtral 12B is out - https://mistral.ai/news/pixtral-12b/",
    "communityName": "r/LocalLLaMA",
    "parsedCommunityName": "LocalLLaMA",
    "body": "[removed]",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LocalLLaMA/comments/1fj4tkj/pixtral_12b_is_out_httpsmistralainewspixtral12b/",
    "numberOfComments": 0,
    "flair": "Discussion",
    "upVotes": 1,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "default",
    "imageUrls": [],
    "createdAt": "2024-09-17T17:11:26.000Z",
    "scrapedAt": "2025-08-31T23:58:11.769Z",
    "dataType": "post"
  },
  {
    "id": "t3_1fj3ldp",
    "parsedId": "1fj3ldp",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1fj3ldp/how_to_get_started_with_trainingfinetuning_audio/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "How to get started with training/finetuning audio models?",
    "communityName": "r/LocalLLaMA",
    "parsedCommunityName": "LocalLLaMA",
    "body": "[removed]",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LocalLLaMA/comments/1fj3ldp/how_to_get_started_with_trainingfinetuning_audio/",
    "numberOfComments": 0,
    "flair": "Question | Help",
    "upVotes": 1,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "default",
    "imageUrls": [],
    "createdAt": "2024-09-17T16:24:29.000Z",
    "scrapedAt": "2025-08-31T23:58:11.804Z",
    "dataType": "post"
  },
  {
    "id": "t1_m54407t",
    "parsedId": "m54407t",
    "url": "https://www.reddit.com/r/LangChain/comments/1hs6htz/ai_agent_that_copies_bank_transactions_to_a_sheet/m54407t/",
    "postId": "t3_1hs6htz",
    "parentId": "t1_m54324t",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LangChain",
    "communityName": "r/LangChain",
    "body": "in my experience, gemini 1.5 pro extracts structured content from video inputs really well. so i just dint feel the need to scrape dom - but obviously dom scraping scales better.",
    "createdAt": "2025-01-03T01:59:08.000Z",
    "scrapedAt": "2025-08-31T23:58:11.802Z",
    "upVotes": 2,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;in my experience, gemini 1.5 pro extracts structured content from video inputs really well. so i just dint feel the need to scrape dom - but obviously dom scraping scales better.&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1firdxt",
    "parsedId": "1firdxt",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1firdxt/has_any_one_trained_a_tts_model_using_soundstorm/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Has any one trained a TTS model using SoundStorm?",
    "communityName": "r/LocalLLaMA",
    "parsedCommunityName": "LocalLLaMA",
    "body": "Has any one trained a TTS model using SoundStorm? Came across the implementation from lucidrains [https://github.com/lucidrains/soundstorm-pytorch](https://github.com/lucidrains/soundstorm-pytorch) . Could some one help me understand how to go about training and running inference for this model?",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has any one trained a TTS model using SoundStorm? Came across the implementation from lucidrains &lt;a href=\"https://github.com/lucidrains/soundstorm-pytorch\"&gt;https://github.com/lucidrains/soundstorm-pytorch&lt;/a&gt; . Could some one help me understand how to go about training and running inference for this model?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LocalLLaMA/comments/1firdxt/has_any_one_trained_a_tts_model_using_soundstorm/",
    "numberOfComments": 0,
    "flair": "Question | Help",
    "upVotes": 3,
    "upVoteRatio": 0.67,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [
      "https://external-i.redd.it/qWlWMd9_E5l5cqOW-K4FeAaXNyY0o5h9foSi6Lo4N7A.jpg"
    ],
    "createdAt": "2024-09-17T05:54:26.000Z",
    "scrapedAt": "2025-08-31T23:58:11.848Z",
    "dataType": "post"
  },
  {
    "id": "t3_1fhpi1c",
    "parsedId": "1fhpi1c",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1fhpi1c/creating_a_podcast_using_ai/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Creating a podcast using AI",
    "communityName": "r/LocalLLaMA",
    "parsedCommunityName": "LocalLLaMA",
    "body": "[removed]",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LocalLLaMA/comments/1fhpi1c/creating_a_podcast_using_ai/",
    "numberOfComments": 0,
    "flair": "Generation",
    "upVotes": 0,
    "upVoteRatio": 0.38,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "default",
    "imageUrls": [],
    "createdAt": "2024-09-15T22:47:39.000Z",
    "scrapedAt": "2025-08-31T23:58:11.892Z",
    "dataType": "post"
  },
  {
    "id": "t3_1fgws2i",
    "parsedId": "1fgws2i",
    "url": "https://www.reddit.com/r/SideProject/comments/1fgws2i/i_launched_a_fully_automated_podcast_that_deep/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "I launched a fully automated podcast that deep dives into LLM use cases in big tech ",
    "communityName": "r/SideProject",
    "parsedCommunityName": "SideProject",
    "body": "I am launching a new experiment: a podcast that is fully automated and powered by Generative AI. That's right — the hosts of this podcast don't exist in real life. However, they are highly skilled at breaking down complex topics from various sources and presenting them in a short, digestible format.  \n  \nThe episodes focus on how engineering teams in big tech companies are using Generative AI to solve novel use cases, as well as on Generative AI research in academia.  \n  \nThe first release features 10 episodes, including some exciting ones like:  \n  \n- How Uber  engineering uses GenAI for mobile testing.  \n  \n- How OpenAI  latest reasoning models work.  \n  \n- How Box  uses Amazon Q to power Box AI.  \n  \n- How DoorDash  uses LLMs to enrich it's SKUs.  \n  \nThe episodes are semi-automated and fully powered using NotebookLM from Google, Riverside FM and Spotify.  \n  \nThe content for these episodes is sourced from various engineering blogs, case studies, and arXiv papers.\n\n  \nLinks: \n\nSpotify - [https://open.spotify.com/show/0Toon5UiQc5P7DNDjsrr9K?si=536d0ce471c44439](https://open.spotify.com/show/0Toon5UiQc5P7DNDjsrr9K?si=536d0ce471c44439)\n\nApple - [https://podcasts.apple.com/us/podcast/ai-arxiv/id1768464164](https://podcasts.apple.com/us/podcast/ai-arxiv/id1768464164)",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am launching a new experiment: a podcast that is fully automated and powered by Generative AI. That&amp;#39;s right — the hosts of this podcast don&amp;#39;t exist in real life. However, they are highly skilled at breaking down complex topics from various sources and presenting them in a short, digestible format.  &lt;/p&gt;\n\n&lt;p&gt;The episodes focus on how engineering teams in big tech companies are using Generative AI to solve novel use cases, as well as on Generative AI research in academia.  &lt;/p&gt;\n\n&lt;p&gt;The first release features 10 episodes, including some exciting ones like:  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;How Uber  engineering uses GenAI for mobile testing.  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How OpenAI  latest reasoning models work.  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How Box  uses Amazon Q to power Box AI.  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How DoorDash  uses LLMs to enrich it&amp;#39;s SKUs.  &lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The episodes are semi-automated and fully powered using NotebookLM from Google, Riverside FM and Spotify.  &lt;/p&gt;\n\n&lt;p&gt;The content for these episodes is sourced from various engineering blogs, case studies, and arXiv papers.&lt;/p&gt;\n\n&lt;p&gt;Links: &lt;/p&gt;\n\n&lt;p&gt;Spotify - &lt;a href=\"https://open.spotify.com/show/0Toon5UiQc5P7DNDjsrr9K?si=536d0ce471c44439\"&gt;https://open.spotify.com/show/0Toon5UiQc5P7DNDjsrr9K?si=536d0ce471c44439&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Apple - &lt;a href=\"https://podcasts.apple.com/us/podcast/ai-arxiv/id1768464164\"&gt;https://podcasts.apple.com/us/podcast/ai-arxiv/id1768464164&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/SideProject/comments/1fgws2i/i_launched_a_fully_automated_podcast_that_deep/",
    "numberOfComments": 25,
    "flair": null,
    "upVotes": 12,
    "upVoteRatio": 0.7,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [
      "https://external-i.redd.it/16aVoQDt6GqhCj4git9_ZKbDWDkqyLsNO3oaReSiLY4.jpg"
    ],
    "createdAt": "2024-09-14T21:44:19.000Z",
    "scrapedAt": "2025-08-31T23:58:11.927Z",
    "dataType": "post"
  },
  {
    "id": "t1_m543qd5",
    "parsedId": "m543qd5",
    "url": "https://www.reddit.com/r/LangChain/comments/1hs6htz/ai_agent_that_copies_bank_transactions_to_a_sheet/m543qd5/",
    "postId": "t3_1hs6htz",
    "parentId": "t1_m5400su",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LangChain",
    "communityName": "r/LangChain",
    "body": "I am only running it locally for my own use case for now. So auth wasn't needed. But if you are asking about authenticating with the model, the model client API calls are made from a express server running locally.",
    "createdAt": "2025-01-03T01:57:31.000Z",
    "scrapedAt": "2025-08-31T23:58:11.958Z",
    "upVotes": 1,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;I am only running it locally for my own use case for now. So auth wasn&amp;#39;t needed. But if you are asking about authenticating with the model, the model client API calls are made from a express server running locally.&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1fgmk2o",
    "parsedId": "1fgmk2o",
    "url": "https://www.reddit.com/r/LangChain/comments/1fgmk2o/a_fully_automated_and_ai_generated_podcast_on/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "A fully automated and AI generated podcast on GenAI",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "I am launching a new experiment: a podcast that is fully automated and powered by Generative AI. That's right—the hosts of this podcast don't exist in real life. However, they are highly skilled at breaking down complex topics from various sources and presenting them in a short, digestible format.\n\nThe episodes focus on how engineering teams in big tech companies are using Generative AI to solve novel use cases, as well as on Generative AI research in academia.\n\nThe first release features 10 episodes, including some exciting ones like:\n- How Uber engineering uses GenAI for mobile testing.\n- How OpenAI's latest reasoning models work.\n- How Box uses Amazon Q to power Box AI.\n- How DoorDash uses LLMs to enrich it's SKUs.\n\nThe episodes are semi-automated and fully powered using NotebookLM from Google, Riverside.fm and Spotify.\n\nThe content for these episodes is sourced from various engineering blogs, case studies, and arXiv papers. Sit back, relax, and enjoy some unique insights into how engineering teams are leveraging GenAI, narrated and powered by GenAI. Now available on Apple Podcasts &amp; Spotify!\n\nSpotify - https://open.spotify.com/show/0Toon5UiQc5P7DNDjsrr9K?si=536d0ce471c44439\nApple - https://podcasts.apple.com/us/podcast/ai-arxiv/id1768464164",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am launching a new experiment: a podcast that is fully automated and powered by Generative AI. That&amp;#39;s right—the hosts of this podcast don&amp;#39;t exist in real life. However, they are highly skilled at breaking down complex topics from various sources and presenting them in a short, digestible format.&lt;/p&gt;\n\n&lt;p&gt;The episodes focus on how engineering teams in big tech companies are using Generative AI to solve novel use cases, as well as on Generative AI research in academia.&lt;/p&gt;\n\n&lt;p&gt;The first release features 10 episodes, including some exciting ones like:\n- How Uber engineering uses GenAI for mobile testing.\n- How OpenAI&amp;#39;s latest reasoning models work.\n- How Box uses Amazon Q to power Box AI.\n- How DoorDash uses LLMs to enrich it&amp;#39;s SKUs.&lt;/p&gt;\n\n&lt;p&gt;The episodes are semi-automated and fully powered using NotebookLM from Google, Riverside.fm and Spotify.&lt;/p&gt;\n\n&lt;p&gt;The content for these episodes is sourced from various engineering blogs, case studies, and arXiv papers. Sit back, relax, and enjoy some unique insights into how engineering teams are leveraging GenAI, narrated and powered by GenAI. Now available on Apple Podcasts &amp;amp; Spotify!&lt;/p&gt;\n\n&lt;p&gt;Spotify - &lt;a href=\"https://open.spotify.com/show/0Toon5UiQc5P7DNDjsrr9K?si=536d0ce471c44439\"&gt;https://open.spotify.com/show/0Toon5UiQc5P7DNDjsrr9K?si=536d0ce471c44439&lt;/a&gt;\nApple - &lt;a href=\"https://podcasts.apple.com/us/podcast/ai-arxiv/id1768464164\"&gt;https://podcasts.apple.com/us/podcast/ai-arxiv/id1768464164&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1fgmk2o/a_fully_automated_and_ai_generated_podcast_on/",
    "numberOfComments": 2,
    "flair": "Announcement",
    "upVotes": 8,
    "upVoteRatio": 0.79,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [
      "https://external-i.redd.it/16aVoQDt6GqhCj4git9_ZKbDWDkqyLsNO3oaReSiLY4.jpg"
    ],
    "createdAt": "2024-09-14T13:52:25.000Z",
    "scrapedAt": "2025-08-31T23:58:11.986Z",
    "dataType": "post"
  },
  {
    "id": "t3_1fgmj6q",
    "parsedId": "1fgmj6q",
    "url": "https://www.reddit.com/r/InternetIsBeautiful/comments/1fgmj6q/ai_arxiv_a_fully_automated_ai_generated_podcast/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "AI Arxiv - a fully automated AI generated podcast",
    "communityName": "r/InternetIsBeautiful",
    "parsedCommunityName": "InternetIsBeautiful",
    "body": "[removed]",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://podcasts.apple.com/us/podcast/ai-arxiv/id1768464164",
    "numberOfComments": 1,
    "flair": "No AI-Based Content",
    "upVotes": 1,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "default",
    "imageUrls": [],
    "createdAt": "2024-09-14T13:51:06.000Z",
    "scrapedAt": "2025-08-31T23:58:12.015Z",
    "dataType": "post"
  },
  {
    "id": "t1_m53wkw3",
    "parsedId": "m53wkw3",
    "url": "https://www.reddit.com/r/LangChain/comments/1hs6htz/ai_agent_that_copies_bank_transactions_to_a_sheet/m53wkw3/",
    "postId": "t3_1hs6htz",
    "parentId": "t1_m53me89",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LangChain",
    "communityName": "r/LangChain",
    "body": "The browser basically records the screen and once recorded the video is uploaded to the model. Nothing fancy. You can try it out by uploading a recording to any Gemini model on aistudio and prompting it with structured outputs.",
    "createdAt": "2025-01-03T01:16:33.000Z",
    "scrapedAt": "2025-08-31T23:58:12.031Z",
    "upVotes": 0,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;The browser basically records the screen and once recorded the video is uploaded to the model. Nothing fancy. You can try it out by uploading a recording to any Gemini model on aistudio and prompting it with structured outputs.&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1ffkrvk",
    "parsedId": "1ffkrvk",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1ffkrvk/openai_hides_the_cot_used_by_o1_to_gain/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "OpenAI hides the CoT used by o1 to gain competitive advantage. ",
    "communityName": "r/LocalLLaMA",
    "parsedCommunityName": "LocalLLaMA",
    "body": "This a friendly reminder that you can develop a SoTA model using OSS models by cleverly designing and optimizing CoT prompts for a specific metric. DSPy allows you to do exactly this.",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This a friendly reminder that you can develop a SoTA model using OSS models by cleverly designing and optimizing CoT prompts for a specific metric. DSPy allows you to do exactly this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://i.redd.it/1mx3jteushod1.jpeg",
    "numberOfComments": 21,
    "flair": "Discussion",
    "upVotes": 59,
    "upVoteRatio": 0.76,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "https://a.thumbs.redditmedia.com/foljYlZ4xQkE0AbcT1aZTs1P8MjlFgQJ7i2t8XOEe_0.jpg",
    "imageUrls": [
      "https://i.redd.it/1mx3jteushod1.jpeg"
    ],
    "createdAt": "2024-09-13T03:03:52.000Z",
    "scrapedAt": "2025-08-31T23:58:12.050Z",
    "dataType": "post"
  },
  {
    "id": "t1_m53twrb",
    "parsedId": "m53twrb",
    "url": "https://www.reddit.com/r/LangChain/comments/1hs6htz/ai_agent_that_copies_bank_transactions_to_a_sheet/m53twrb/",
    "postId": "t3_1hs6htz",
    "parentId": "t1_m53me89",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LangChain",
    "communityName": "r/LangChain",
    "body": "It extracts all the numbers. Gemini 1.5 pro is insanely good at scraping from video inputs.",
    "createdAt": "2025-01-03T01:01:41.000Z",
    "scrapedAt": "2025-08-31T23:58:12.061Z",
    "upVotes": 1,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;It extracts all the numbers. Gemini 1.5 pro is insanely good at scraping from video inputs.&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1ffujf1",
    "parsedId": "1ffujf1",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1ffujf1/how_did_they_train_the_o1_specifically_at_the/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "How did they train the o1 specifically at the inference layer?",
    "communityName": "r/LocalLLaMA",
    "parsedCommunityName": "LocalLLaMA",
    "body": "[removed]",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LocalLLaMA/comments/1ffujf1/how_did_they_train_the_o1_specifically_at_the/",
    "numberOfComments": 2,
    "flair": "Question | Help",
    "upVotes": 0,
    "upVoteRatio": 0.45,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "default",
    "imageUrls": [],
    "createdAt": "2024-09-13T13:19:03.000Z",
    "scrapedAt": "2025-08-31T23:58:12.082Z",
    "dataType": "post"
  },
  {
    "id": "t1_m53trg5",
    "parsedId": "m53trg5",
    "url": "https://www.reddit.com/r/LangChain/comments/1hs6htz/ai_agent_that_copies_bank_transactions_to_a_sheet/m53trg5/",
    "postId": "t3_1hs6htz",
    "parentId": "t1_m5383oc",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LangChain",
    "communityName": "r/LangChain",
    "body": "How’s it an already solved problem? Enlighten me please.",
    "createdAt": "2025-01-03T01:00:53.000Z",
    "scrapedAt": "2025-08-31T23:58:12.090Z",
    "upVotes": -4,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;How’s it an already solved problem? Enlighten me please.&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1fanhgm",
    "parsedId": "1fanhgm",
    "url": "https://www.reddit.com/r/LangChain/comments/1fanhgm/what_does_your_llm_stack_look_like_these_days/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "What does your LLM stack look like these days?",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "I am starting to use more of CrewAI, DSPy, Claude sonnet, chromadb and Langtrace. ",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am starting to use more of CrewAI, DSPy, Claude sonnet, chromadb and Langtrace. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1fanhgm/what_does_your_llm_stack_look_like_these_days/",
    "numberOfComments": 30,
    "flair": "Discussion",
    "upVotes": 40,
    "upVoteRatio": 0.98,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-09-06T19:18:59.000Z",
    "scrapedAt": "2025-08-31T23:58:12.125Z",
    "dataType": "post"
  },
  {
    "id": "t1_m531bzk",
    "parsedId": "m531bzk",
    "url": "https://www.reddit.com/r/LangChain/comments/1hs6htz/ai_agent_that_copies_bank_transactions_to_a_sheet/m531bzk/",
    "postId": "t3_1hs6htz",
    "parentId": "t3_1hs6htz",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LangChain",
    "communityName": "r/LangChain",
    "body": "Instead of downloading csv statements or manually copying over details, what if your transactions across different banks and bank accounts are automatically consolidated, organized and copied over to a google sheet each time you review them periodically?\n\nI built a browser plugin AI Agent that uses Gemini 1.5 Pro's vision capabilities to solve this problem. \n\nHere's how this agent works:\n\n1/ Share screen and show the transactions you are reviewing to this Agent.\n\n2/ Go about reviewing your transactions. Switch between accounts and review as much as you like.\n\n3/ Once done, stop the screen share and ask the agent to copy the transactions over to a google sheet. \n\nTools used for building this:\n\n1/ Model - Google's Gemini 1.5 Pro\n\n2/ Browser plugin built with the help of Cursor\n\nIf you are interested in trying this plugin or interested in building agents like these, leave a comment or reach out to me.",
    "createdAt": "2025-01-02T22:31:47.000Z",
    "scrapedAt": "2025-08-31T23:58:12.123Z",
    "upVotes": 7,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;Instead of downloading csv statements or manually copying over details, what if your transactions across different banks and bank accounts are automatically consolidated, organized and copied over to a google sheet each time you review them periodically?&lt;/p&gt;\n\n&lt;p&gt;I built a browser plugin AI Agent that uses Gemini 1.5 Pro&amp;#39;s vision capabilities to solve this problem. &lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s how this agent works:&lt;/p&gt;\n\n&lt;p&gt;1/ Share screen and show the transactions you are reviewing to this Agent.&lt;/p&gt;\n\n&lt;p&gt;2/ Go about reviewing your transactions. Switch between accounts and review as much as you like.&lt;/p&gt;\n\n&lt;p&gt;3/ Once done, stop the screen share and ask the agent to copy the transactions over to a google sheet. &lt;/p&gt;\n\n&lt;p&gt;Tools used for building this:&lt;/p&gt;\n\n&lt;p&gt;1/ Model - Google&amp;#39;s Gemini 1.5 Pro&lt;/p&gt;\n\n&lt;p&gt;2/ Browser plugin built with the help of Cursor&lt;/p&gt;\n\n&lt;p&gt;If you are interested in trying this plugin or interested in building agents like these, leave a comment or reach out to me.&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1fb0qzd",
    "parsedId": "1fb0qzd",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1fb0qzd/has_anyone_tried_colpali_thoughts/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Has anyone tried Colpali? Thoughts?",
    "communityName": "r/LocalLLaMA",
    "parsedCommunityName": "LocalLLaMA",
    "body": "Has anyone tried Colpali? Thoughts?",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone tried Colpali? Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LocalLLaMA/comments/1fb0qzd/has_anyone_tried_colpali_thoughts/",
    "numberOfComments": 1,
    "flair": "Discussion",
    "upVotes": 1,
    "upVoteRatio": 0.54,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-09-07T06:35:47.000Z",
    "scrapedAt": "2025-08-31T23:58:12.176Z",
    "dataType": "post"
  },
  {
    "id": "t1_m3bfmfc",
    "parsedId": "m3bfmfc",
    "url": "https://www.reddit.com/r/LangChain/comments/1hk4ghq/built_an_oss_image_background_remover_tool/m3bfmfc/",
    "postId": "t3_1hk4ghq",
    "parentId": "t3_1hk4ghq",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LangChain",
    "communityName": "r/LangChain",
    "body": "Free and runs fully local built using OSS model on huggingface  \nGithub: [https://github.com/Scale3-Labs/image\\_bgremover](https://github.com/Scale3-Labs/image_bgremover)",
    "createdAt": "2024-12-22T18:30:10.000Z",
    "scrapedAt": "2025-08-31T23:58:12.177Z",
    "upVotes": 1,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;Free and runs fully local built using OSS model on huggingface&lt;br/&gt;\nGithub: &lt;a href=\"https://github.com/Scale3-Labs/image_bgremover\"&gt;https://github.com/Scale3-Labs/image_bgremover&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1f9r5vg",
    "parsedId": "1f9r5vg",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1f9r5vg/compiled_list_of_nearly_100_products_oss_systems/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Compiled list of nearly 100 products, OSS systems, and other public DSPy resources. ",
    "communityName": "r/LocalLLaMA",
    "parsedCommunityName": "LocalLLaMA",
    "body": "\nhttps://github.com/stanfordnlp/dspy/blob/main/docs/docs/dspy-usecases.md",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://github.com/stanfordnlp/dspy/blob/main/docs/docs/dspy-usecases.md\"&gt;https://github.com/stanfordnlp/dspy/blob/main/docs/docs/dspy-usecases.md&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LocalLLaMA/comments/1f9r5vg/compiled_list_of_nearly_100_products_oss_systems/",
    "numberOfComments": 5,
    "flair": "Resources",
    "upVotes": 32,
    "upVoteRatio": 0.92,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [
      "https://external-i.redd.it/wlvGUpTKx1WpyLfSCvT_ewec0H305Mc3BxzQmKT-fSQ.jpg"
    ],
    "createdAt": "2024-09-05T16:47:57.000Z",
    "scrapedAt": "2025-08-31T23:58:12.222Z",
    "dataType": "post"
  },
  {
    "id": "t1_m3352co",
    "parsedId": "m3352co",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1hitwwt/the_o3_chart_is_logarithmic_on_x_axis_and_linear/m3352co/",
    "postId": "t3_1hitwwt",
    "parentId": "t1_m31jxo9",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LocalLLaMA",
    "communityName": "r/LocalLLaMA",
    "body": "It will be the GitHub pilot rather",
    "createdAt": "2024-12-21T03:47:33.000Z",
    "scrapedAt": "2025-08-31T23:58:12.243Z",
    "upVotes": 1,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;It will be the GitHub pilot rather&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1f91f7d",
    "parsedId": "1f91f7d",
    "url": "https://www.reddit.com/r/crewai/comments/1f91f7d/debug_crewai_agents_better_using_langtrace_ai/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Debug CrewAI agents better using Langtrace AI",
    "communityName": "r/crewai",
    "parsedCommunityName": "crewai",
    "body": "Images:\n\thttps://external-preview.redd.it/dGVienYybGVhdW1kMei9oH6xsXdFDncQpKMPVFTGUN_1c4RDAspRMyIgH77i.png?format=pjpg&amp;auto=webp&amp;s=56ea655afd36d763feb569e26fd27c00eeb29e85\n",
    "html": "Images:\n\thttps://external-preview.redd.it/dGVienYybGVhdW1kMei9oH6xsXdFDncQpKMPVFTGUN_1c4RDAspRMyIgH77i.png?format=pjpg&amp;auto=webp&amp;s=56ea655afd36d763feb569e26fd27c00eeb29e85\n",
    "link": "https://v.redd.it/jtjs43leaumd1",
    "numberOfComments": 2,
    "flair": null,
    "upVotes": 12,
    "upVoteRatio": 1,
    "isVideo": true,
    "isAd": false,
    "over18": false,
    "videoUrl": "https://v.redd.it/jtjs43leaumd1/DASH_1080.mp4?source=fallback",
    "thumbnailUrl": "https://external-preview.redd.it/dGVienYybGVhdW1kMei9oH6xsXdFDncQpKMPVFTGUN_1c4RDAspRMyIgH77i.png?width=140&amp;height=82&amp;crop=140:82,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=efb7eaadbb449181d63e379f5a4528272d31ec38",
    "imageUrls": [
      "https://external-i.redd.it/dGVienYybGVhdW1kMei9oH6xsXdFDncQpKMPVFTGUN_1c4RDAspRMyIgH77i.png"
    ],
    "createdAt": "2024-09-04T18:55:39.000Z",
    "scrapedAt": "2025-08-31T23:58:12.262Z",
    "dataType": "post"
  },
  {
    "id": "t1_m327nxk",
    "parsedId": "m327nxk",
    "url": "https://www.reddit.com/r/AI_Agents/comments/1hikqe2/best_agentic_monitoring_tool/m327nxk/",
    "postId": "t3_1hikqe2",
    "parentId": "t3_1hikqe2",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "AI_Agents",
    "communityName": "r/AI_Agents",
    "body": "Check out Langtrace.",
    "createdAt": "2024-12-20T23:56:17.000Z",
    "scrapedAt": "2025-08-31T23:58:12.275Z",
    "upVotes": 1,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;Check out Langtrace.&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t1_m307bog",
    "parsedId": "m307bog",
    "url": "https://www.reddit.com/r/LangChain/comments/1b2y18p/langsmith_started_charging_time_to_compare/m307bog/",
    "postId": "t3_1b2y18p",
    "parentId": "t1_lyvvvbz",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LangChain",
    "communityName": "r/LangChain",
    "body": "Curious why you can’t use AGPL?",
    "createdAt": "2024-12-20T16:56:08.000Z",
    "scrapedAt": "2025-08-31T23:58:12.304Z",
    "upVotes": 1,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;Curious why you can’t use AGPL?&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1f7ccyr",
    "parsedId": "1f7ccyr",
    "url": "https://www.reddit.com/r/nextjs/comments/1f7ccyr/what_do_you_absolutely_love_about_nextjs_you_can/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "What do you absolutely love about nextjs? You can only state one thing",
    "communityName": "r/nextjs",
    "parsedCommunityName": "nextjs",
    "body": "What do you absolutely love about nextjs? You can only state one thing. Go!",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What do you absolutely love about nextjs? You can only state one thing. Go!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/nextjs/comments/1f7ccyr/what_do_you_absolutely_love_about_nextjs_you_can/",
    "numberOfComments": 63,
    "flair": "Discussion",
    "upVotes": 18,
    "upVoteRatio": 0.8,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-09-02T17:21:06.000Z",
    "scrapedAt": "2025-08-31T23:58:12.309Z",
    "dataType": "post"
  },
  {
    "id": "t3_1f6km18",
    "parsedId": "1f6km18",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1f6km18/better_observability_or_more_evals/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Better observability or more evals?",
    "communityName": "r/LocalLLaMA",
    "parsedCommunityName": "LocalLLaMA",
    "body": "I am wondering what’s more important when you are building apps using LLMs? I have realized having a good observability lets me understand what’s going on and generally eye ball and understand how well my app is doing or the model is generating responses.\n\nI am able to optimize and iterate based on this. Which brings to my question as to whether evals are really needed? Or is it more relevant for more complicated workflows? What are your thoughts?",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am wondering what’s more important when you are building apps using LLMs? I have realized having a good observability lets me understand what’s going on and generally eye ball and understand how well my app is doing or the model is generating responses.&lt;/p&gt;\n\n&lt;p&gt;I am able to optimize and iterate based on this. Which brings to my question as to whether evals are really needed? Or is it more relevant for more complicated workflows? What are your thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LocalLLaMA/comments/1f6km18/better_observability_or_more_evals/",
    "numberOfComments": 6,
    "flair": "Discussion",
    "upVotes": 5,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-09-01T17:56:21.000Z",
    "scrapedAt": "2025-08-31T23:58:12.342Z",
    "dataType": "post"
  },
  {
    "id": "t1_m2p76sv",
    "parsedId": "m2p76sv",
    "url": "https://www.reddit.com/r/LangChain/comments/1bb4ww1/langsmith_for_autogen/m2p76sv/",
    "postId": "t3_1bb4ww1",
    "parentId": "t3_1bb4ww1",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LangChain",
    "communityName": "r/LangChain",
    "body": "[https://www.langtrace.ai/integrations](https://www.langtrace.ai/integrations)",
    "createdAt": "2024-12-18T18:52:58.000Z",
    "scrapedAt": "2025-08-31T23:58:12.337Z",
    "upVotes": 1,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.langtrace.ai/integrations\"&gt;https://www.langtrace.ai/integrations&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t1_m0qkra1",
    "parsedId": "m0qkra1",
    "url": "https://www.reddit.com/r/LangChain/comments/1h84qim/is_langsmith_just_good_piece_of_trash/m0qkra1/",
    "postId": "t3_1h84qim",
    "parentId": "t3_1h84qim",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LangChain",
    "communityName": "r/LangChain",
    "body": "Building Langtrace AI - fully open source and open telemetry compatible. You can self host and use it for free forever. Do check it out and reach out if you have any questions or feedback.",
    "createdAt": "2024-12-06T17:36:12.000Z",
    "scrapedAt": "2025-08-31T23:58:12.384Z",
    "upVotes": 12,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;Building Langtrace AI - fully open source and open telemetry compatible. You can self host and use it for free forever. Do check it out and reach out if you have any questions or feedback.&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1f6kl5z",
    "parsedId": "1f6kl5z",
    "url": "https://www.reddit.com/r/LangChain/comments/1f6kl5z/whats_more_important_observability_or_evaluations/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "What’s more important? Observability or Evaluations?",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "I am wondering what’s more important when you are building apps using LLMs? I have realized having a good observability lets me understand what’s going on and generally eye ball and understand how well my app is doing or the model is generating responses.\n\nI am able to optimize and iterate based on this. Which brings to my question as to whether evals are really needed? Or is it more relevant for more complicated workflows? What are your thoughts?",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am wondering what’s more important when you are building apps using LLMs? I have realized having a good observability lets me understand what’s going on and generally eye ball and understand how well my app is doing or the model is generating responses.&lt;/p&gt;\n\n&lt;p&gt;I am able to optimize and iterate based on this. Which brings to my question as to whether evals are really needed? Or is it more relevant for more complicated workflows? What are your thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1f6kl5z/whats_more_important_observability_or_evaluations/",
    "numberOfComments": 6,
    "flair": "Discussion",
    "upVotes": 4,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-09-01T17:55:18.000Z",
    "scrapedAt": "2025-08-31T23:58:12.383Z",
    "dataType": "post"
  },
  {
    "id": "t1_lzyxor4",
    "parsedId": "lzyxor4",
    "url": "https://www.reddit.com/r/LangChain/comments/1h3y86k/just_built_an_agentic_rag_chatbot_from_scratchno/lzyxor4/",
    "postId": "t3_1h3y86k",
    "parentId": "t3_1h3y86k",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LangChain",
    "communityName": "r/LangChain",
    "body": "This is the way",
    "createdAt": "2024-12-02T01:53:16.000Z",
    "scrapedAt": "2025-08-31T23:58:12.418Z",
    "upVotes": 2,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is the way&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1f4zsu5",
    "parsedId": "1f4zsu5",
    "url": "https://www.reddit.com/r/programming/comments/1f4zsu5/agpl_or_mit/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "AGPL or MIT? ",
    "communityName": "r/programming",
    "parsedCommunityName": "programming",
    "body": "[removed]",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://github.com/Scale3-Labs/langtrace",
    "numberOfComments": 25,
    "flair": null,
    "upVotes": 11,
    "upVoteRatio": 0.7,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "default",
    "imageUrls": [],
    "createdAt": "2024-08-30T16:39:34.000Z",
    "scrapedAt": "2025-08-31T23:58:12.441Z",
    "dataType": "post"
  },
  {
    "id": "t3_1f562uj",
    "parsedId": "1f562uj",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1f562uj/have_you_hosted_oss_models_on_k8s_what_has_your/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Have you hosted OSS models on K8s? What has your experience been so far?",
    "communityName": "r/LocalLLaMA",
    "parsedCommunityName": "LocalLLaMA",
    "body": "I was wondering if any of you have tried hosting OSS models on K8s on GCP or any other cloud? I came across [https://github.com/substratusai/kubeai](https://github.com/substratusai/kubeai) which sounds very promising. ",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was wondering if any of you have tried hosting OSS models on K8s on GCP or any other cloud? I came across &lt;a href=\"https://github.com/substratusai/kubeai\"&gt;https://github.com/substratusai/kubeai&lt;/a&gt; which sounds very promising. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LocalLLaMA/comments/1f562uj/have_you_hosted_oss_models_on_k8s_what_has_your/",
    "numberOfComments": 0,
    "flair": "Question | Help",
    "upVotes": 4,
    "upVoteRatio": 0.75,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [
      "https://external-i.redd.it/wuuZ7PcM4Z2ZqXvsyHWg9Cgzv_Pi1LONUSnXBHF_jAk.jpg"
    ],
    "createdAt": "2024-08-30T21:01:27.000Z",
    "scrapedAt": "2025-08-31T23:58:12.470Z",
    "dataType": "post"
  },
  {
    "id": "t1_lzlelva",
    "parsedId": "lzlelva",
    "url": "https://www.reddit.com/r/AI_Agents/comments/1h2q9l3/run_agents_locally/lzlelva/",
    "postId": "t3_1h2q9l3",
    "parentId": "t3_1h2q9l3",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "AI_Agents",
    "communityName": "r/AI_Agents",
    "body": "Check out langtrace",
    "createdAt": "2024-11-29T18:29:18.000Z",
    "scrapedAt": "2025-08-31T23:58:12.467Z",
    "upVotes": 2,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;Check out langtrace&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1ezv544",
    "parsedId": "1ezv544",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1ezv544/is_amazon_q_that_good_any_amazon_dev_that_can/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Is Amazon Q that good? Any Amazon dev that can throw some light on this?",
    "communityName": "r/LocalLLaMA",
    "parsedCommunityName": "LocalLLaMA",
    "body": "Images:\n\thttps://preview.redd.it/puorv1d30jkd1.jpeg?auto=webp&amp;s=3ebf4b4ff0e2660dc9afbf2f5e566f5f4dfa6e22\n",
    "html": "Images:\n\thttps://preview.redd.it/puorv1d30jkd1.jpeg?auto=webp&amp;s=3ebf4b4ff0e2660dc9afbf2f5e566f5f4dfa6e22\n",
    "link": "https://i.redd.it/puorv1d30jkd1.jpeg",
    "numberOfComments": 39,
    "flair": "Discussion",
    "upVotes": 89,
    "upVoteRatio": 0.92,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "https://a.thumbs.redditmedia.com/r9khQUNj-BWQYd8p95YqVshm5lJGgRQTUCe0_rMis04.jpg",
    "imageUrls": [
      "https://i.redd.it/puorv1d30jkd1.jpeg"
    ],
    "createdAt": "2024-08-24T02:49:44.000Z",
    "scrapedAt": "2025-08-31T23:58:12.517Z",
    "dataType": "post"
  },
  {
    "id": "t1_lz7imle",
    "parsedId": "lz7imle",
    "url": "https://www.reddit.com/r/DSPy/comments/1h0jitx/optimize_your_dspy_program_with_cognify/lz7imle/",
    "postId": "t3_1h0jitx",
    "parentId": "t3_1h0jitx",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "DSPy",
    "communityName": "r/DSPy",
    "body": "Curious, is this a new framework ?",
    "createdAt": "2024-11-27T07:09:18.000Z",
    "scrapedAt": "2025-08-31T23:58:12.529Z",
    "upVotes": 1,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;Curious, is this a new framework ?&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1f0g21n",
    "parsedId": "1f0g21n",
    "url": "https://www.reddit.com/r/cybersecurity/comments/1f0g21n/what_do_you_use_for_moderating_the_usage_of_genai/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "What do you use for moderating the usage of genAI apps like chatgpt?",
    "communityName": "r/cybersecurity",
    "parsedCommunityName": "cybersecurity",
    "body": "wondering if there is a tool/product that you all are using in your company to monitor and moderate usage what your employees put into genAI apps like chatGPT?",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;wondering if there is a tool/product that you all are using in your company to monitor and moderate usage what your employees put into genAI apps like chatGPT?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/cybersecurity/comments/1f0g21n/what_do_you_use_for_moderating_the_usage_of_genai/",
    "numberOfComments": 0,
    "flair": "Education / Tutorial / How-To",
    "upVotes": 1,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-08-24T21:26:07.000Z",
    "scrapedAt": "2025-08-31T23:58:12.562Z",
    "dataType": "post"
  },
  {
    "id": "t1_lz2xf8d",
    "parsedId": "lz2xf8d",
    "url": "https://www.reddit.com/r/LangChain/comments/1h0bjl3/observability_tools_aws/lz2xf8d/",
    "postId": "t3_1h0bjl3",
    "parentId": "t3_1h0bjl3",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LangChain",
    "communityName": "r/LangChain",
    "body": "You can check out Langtrace. It’s open source and open telemetry based and traces close to 40 integrations with just 2 lines of code to set it up",
    "createdAt": "2024-11-26T14:47:01.000Z",
    "scrapedAt": "2025-08-31T23:58:12.568Z",
    "upVotes": 1,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;You can check out Langtrace. It’s open source and open telemetry based and traces close to 40 integrations with just 2 lines of code to set it up&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1dfaquj",
    "parsedId": "1dfaquj",
    "url": "https://www.reddit.com/r/LangChain/comments/1dfaquj/run_evaluations_with_langtrace/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Run Evaluations with Langtrace",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "Hi all,\n\nIts been a while from me, but just wanted to share that we have added support for running automated evals with Langtrace. As a reminder, Langtrace is an open source LLM application observability and evaluations tool. It is open telemetry compatible so no vendor lock-in. You can also self-host and run Langtrace.\n\nWe integrated langtrace with inspect AI (https://github.com/UKGovernmentBEIS/inspect\\_ai). Inspect is an open source evluations tool from the developers of RStudio - you should definitely check it out. I love it.  \nWith langtrace, you can now\n\n* set up tracing in 2 lines of code\n* annotate and curate datasets\n* run evaluations against this dataset using Inspect\n* view results, compare the outputs against models and understand the performance of your app\n\nSo, you can now establish this feedback loop with langtrace.\n\nhttps://preview.redd.it/qrwn7r1kte6d1.png?width=2304&amp;format=png&amp;auto=webp&amp;s=3c2d7c82abbb329518b35c133c0e7a0e73a6d53d\n\nShown below are some screenshots:\n\nhttps://preview.redd.it/t45vq2xute6d1.png?width=3156&amp;format=png&amp;auto=webp&amp;s=1c15fc71499ba5c5ccbf0aa566fc78c82730e209\n\nhttps://preview.redd.it/0gwmyz0xte6d1.png?width=3150&amp;format=png&amp;auto=webp&amp;s=2713ba619e903d2db227d5922e8e9c7a562fb9b7\n\nWould love get any feedback. Please do try it out and let me know.\n\nLink: [https://github.com/Scale3-Labs/langtrace](https://github.com/Scale3-Labs/langtrace)",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Its been a while from me, but just wanted to share that we have added support for running automated evals with Langtrace. As a reminder, Langtrace is an open source LLM application observability and evaluations tool. It is open telemetry compatible so no vendor lock-in. You can also self-host and run Langtrace.&lt;/p&gt;\n\n&lt;p&gt;We integrated langtrace with inspect AI (&lt;a href=\"https://github.com/UKGovernmentBEIS/inspect%5C_ai\"&gt;https://github.com/UKGovernmentBEIS/inspect\\_ai&lt;/a&gt;). Inspect is an open source evluations tool from the developers of RStudio - you should definitely check it out. I love it.&lt;br/&gt;\nWith langtrace, you can now&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;set up tracing in 2 lines of code&lt;/li&gt;\n&lt;li&gt;annotate and curate datasets&lt;/li&gt;\n&lt;li&gt;run evaluations against this dataset using Inspect&lt;/li&gt;\n&lt;li&gt;view results, compare the outputs against models and understand the performance of your app&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;So, you can now establish this feedback loop with langtrace.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/qrwn7r1kte6d1.png?width=2304&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3c2d7c82abbb329518b35c133c0e7a0e73a6d53d\"&gt;https://preview.redd.it/qrwn7r1kte6d1.png?width=2304&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3c2d7c82abbb329518b35c133c0e7a0e73a6d53d&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Shown below are some screenshots:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/t45vq2xute6d1.png?width=3156&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1c15fc71499ba5c5ccbf0aa566fc78c82730e209\"&gt;https://preview.redd.it/t45vq2xute6d1.png?width=3156&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1c15fc71499ba5c5ccbf0aa566fc78c82730e209&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/0gwmyz0xte6d1.png?width=3150&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2713ba619e903d2db227d5922e8e9c7a562fb9b7\"&gt;https://preview.redd.it/0gwmyz0xte6d1.png?width=3150&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2713ba619e903d2db227d5922e8e9c7a562fb9b7&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Would love get any feedback. Please do try it out and let me know.&lt;/p&gt;\n\n&lt;p&gt;Link: &lt;a href=\"https://github.com/Scale3-Labs/langtrace\"&gt;https://github.com/Scale3-Labs/langtrace&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1dfaquj/run_evaluations_with_langtrace/",
    "numberOfComments": 0,
    "flair": "Announcement",
    "upVotes": 9,
    "upVoteRatio": 0.91,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "https://b.thumbs.redditmedia.com/OlQpvPg6C80CPbeQqL74YpdIgrAULdbnNlYTTliAWPg.jpg",
    "imageUrls": [
      "https://i.redd.it/qrwn7r1kte6d1.png",
      "https://i.redd.it/t45vq2xute6d1.png",
      "https://i.redd.it/0gwmyz0xte6d1.png"
    ],
    "createdAt": "2024-06-13T21:50:44.000Z",
    "scrapedAt": "2025-08-31T23:58:12.605Z",
    "dataType": "post"
  },
  {
    "id": "t1_ly6nx1w",
    "parsedId": "ly6nx1w",
    "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1gw49sw/looking_for_an_app_that_will_monitor_api_key/ly6nx1w/",
    "postId": "t3_1gw49sw",
    "parentId": "t3_1gw49sw",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "ChatGPTCoding",
    "communityName": "r/ChatGPTCoding",
    "body": "take a look into langtrace ai.",
    "createdAt": "2024-11-21T02:03:15.000Z",
    "scrapedAt": "2025-08-31T23:58:12.616Z",
    "upVotes": 2,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;take a look into langtrace ai.&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1dcyzgb",
    "parsedId": "1dcyzgb",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1dcyzgb/apples_on_device_models_are_3b_slms_with_adapters/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Apple’s on device models are 3B SLMs with adapters trained for each feature",
    "communityName": "r/LocalLLaMA",
    "parsedCommunityName": "LocalLLaMA",
    "body": "This is interesting. Basically 3B SLMs sitting on device powering different features \n\nhttps://x.com/maxwinebach/status/1800277157135909005?s=46&amp;t=XrJJzmievg67l3JcMEEDEw",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is interesting. Basically 3B SLMs sitting on device powering different features &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://x.com/maxwinebach/status/1800277157135909005?s=46&amp;amp;t=XrJJzmievg67l3JcMEEDEw\"&gt;https://x.com/maxwinebach/status/1800277157135909005?s=46&amp;amp;t=XrJJzmievg67l3JcMEEDEw&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LocalLLaMA/comments/1dcyzgb/apples_on_device_models_are_3b_slms_with_adapters/",
    "numberOfComments": 95,
    "flair": "Discussion",
    "upVotes": 430,
    "upVoteRatio": 0.98,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [
      "https://external-i.redd.it/7oThnov2FAd5dTg9WpFVLiGNcDeT7u5waYs7MoWefN0.jpg"
    ],
    "createdAt": "2024-06-10T22:47:02.000Z",
    "scrapedAt": "2025-08-31T23:58:12.654Z",
    "dataType": "post"
  },
  {
    "id": "t1_ly24y8n",
    "parsedId": "ly24y8n",
    "url": "https://www.reddit.com/r/LangChain/comments/1gvimq6/langsmith_onpremise_analogue/ly24y8n/",
    "postId": "t3_1gvimq6",
    "parentId": "t3_1gvimq6",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "LangChain",
    "communityName": "r/LangChain",
    "body": "Langtrace AI",
    "createdAt": "2024-11-20T05:56:29.000Z",
    "scrapedAt": "2025-08-31T23:58:12.650Z",
    "upVotes": 2,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;Langtrace AI&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1d8euoz",
    "parsedId": "1d8euoz",
    "url": "https://www.reddit.com/r/LangChain/comments/1d8euoz/learnings_from_doing_evaluations_for_llm_powered/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Learnings from doing Evaluations for LLM powered applications",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "Learnings from doing Evaluations for LLM powered applications from my experience building with LLMs in the last few months:  \n  \n**Evaluations for LLM powered applications is different from Model Evaluation leaderboards like Huggingface Open LLM leaderboard**  \n  \nIf you are an enterprise leveraging or looking to leverage  LLMs, spend very little time on model evaluation leaderboards. Pick the most powerful model to start with and invest in evaluating LLM responses in the context of your product and usecase.  \n  \n**Know your metrics**  \n  \nUltimately what matters is whether your users are getting high quality product experience. This means it's super important to look at your specific use case and determine the metrics that are best suited for your product.  \n  \nAre you building a  \n  \n- summarization tool? Manually evaluate the results and come up with your own thesis of what a good summary should look like that will solve the your user's pain point.  \n  \n- customer support agent chatbot? Look at a few responses and figure out what you care about the most and translate those to measurable metrics.  \n  \nIts important to keep things simple and hyper optimize for your use case before jumping into measuring all the metrics that you found on the internet.  \n  \n**Write unit tests to capture basic assertions**  \n  \nBasic assertions includes things like,  \n- looking for a specific word in every response.  \n- making sure the generated response obeys a specific word count.  \n- making sure the generated response costs less than $ x and uses less than n tokens.  \n  \nThese kinds of unit tests act as a first line of defence and will help you catch the basic issues quickly. If you are using python, you can use pytest to write these simple unit tests. There is no need to buy or adopt any fancy tools for this.  \n  \n**Use LLMs to evaluate the outputs**  \n  \nOne of the popular approaches these days is to use a more powerful LLM to evaluate(or)grade the output of the LLM in use. This approach works well if you clearly know what metrics you care about which are often a bit subjective and specific to your use case.  \n  \nThe first step here is to identify a prompt that can be used for running a powerful LLM to grade the outputs.   \n  \nThere are nice opensource tools like Promptfoo and Inspect AI which already has built in support for model graded evaluations and unit tests which can be used as for starters.  \n  \n**Collect User Feedback**  \n  \nThis is easier said than done. Especially for new products where there is not enough users to get quality feedback from to start with. But its important to make contact with reality as quickly as possible and get creative around getting this feedback - Ex: using it yourself, asking your network, friends and family to use it etc.  \n  \nThe goal here is to set up a system where you can diligently track the feedback and constantly tweak and iterate on the quality of the outputs. Establishing this feedback loop is extremely important.  \n  \n**Look at your data**  \n  \nNo matter how many charts and visualizations you can create on top of your data, there is no proxy to looking at your data - both test and production data. In some cases, it may not be possible to do this when you are operating in a highly secure/private environment. But, you need to figure out a way to collect and look at all the LLM generations closely, especially in the early days. This will inform not just the quality of the outputs the users are experiencing, but also push you in the direction of identifying what metrics actually make sense for your use case.  \n  \n**Manually Evaluate**  \n  \nLLM based evaluations are not fool proof and you need to tweak and improve the prompts and grading scale continuously based on data. And the way to collect this data is by manually evaluating the outputs yourself. This will help you understand how far apart LLM evals is drifting from the real criteria that you want to evaluate against. It's important to measure this drift and make sure LLM evals track closely with manual evals at most times.  \n  \n**Save your model parameters**  \n  \nSaving the model parameters you are using and tracking the responses along with the model parameters will help you with measuring the quality your product for that specific set of model parameters. This becomes useful when you are noticing a regression in the quality of when you are upgrading to a new model version or swapping out to a completely different model.  \n  \nLeave your thoughts. I would love to hear about your experience managing your LLM powered product in terms of quality and accuracy. Also, I am also building a fully open source and open telemetry based tool called Langtrace AI to basically solve for the above problems.  It's super easy to setup with just 2 lines of code. Do check it out if you are interested.",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Learnings from doing Evaluations for LLM powered applications from my experience building with LLMs in the last few months:  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Evaluations for LLM powered applications is different from Model Evaluation leaderboards like Huggingface Open LLM leaderboard&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;p&gt;If you are an enterprise leveraging or looking to leverage  LLMs, spend very little time on model evaluation leaderboards. Pick the most powerful model to start with and invest in evaluating LLM responses in the context of your product and usecase.  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Know your metrics&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;p&gt;Ultimately what matters is whether your users are getting high quality product experience. This means it&amp;#39;s super important to look at your specific use case and determine the metrics that are best suited for your product.  &lt;/p&gt;\n\n&lt;p&gt;Are you building a  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;summarization tool? Manually evaluate the results and come up with your own thesis of what a good summary should look like that will solve the your user&amp;#39;s pain point.  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;customer support agent chatbot? Look at a few responses and figure out what you care about the most and translate those to measurable metrics.  &lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Its important to keep things simple and hyper optimize for your use case before jumping into measuring all the metrics that you found on the internet.  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Write unit tests to capture basic assertions&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;p&gt;Basic assertions includes things like,&lt;br/&gt;\n- looking for a specific word in every response.&lt;br/&gt;\n- making sure the generated response obeys a specific word count.&lt;br/&gt;\n- making sure the generated response costs less than $ x and uses less than n tokens.  &lt;/p&gt;\n\n&lt;p&gt;These kinds of unit tests act as a first line of defence and will help you catch the basic issues quickly. If you are using python, you can use pytest to write these simple unit tests. There is no need to buy or adopt any fancy tools for this.  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Use LLMs to evaluate the outputs&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;p&gt;One of the popular approaches these days is to use a more powerful LLM to evaluate(or)grade the output of the LLM in use. This approach works well if you clearly know what metrics you care about which are often a bit subjective and specific to your use case.  &lt;/p&gt;\n\n&lt;p&gt;The first step here is to identify a prompt that can be used for running a powerful LLM to grade the outputs.   &lt;/p&gt;\n\n&lt;p&gt;There are nice opensource tools like Promptfoo and Inspect AI which already has built in support for model graded evaluations and unit tests which can be used as for starters.  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Collect User Feedback&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;p&gt;This is easier said than done. Especially for new products where there is not enough users to get quality feedback from to start with. But its important to make contact with reality as quickly as possible and get creative around getting this feedback - Ex: using it yourself, asking your network, friends and family to use it etc.  &lt;/p&gt;\n\n&lt;p&gt;The goal here is to set up a system where you can diligently track the feedback and constantly tweak and iterate on the quality of the outputs. Establishing this feedback loop is extremely important.  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Look at your data&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;p&gt;No matter how many charts and visualizations you can create on top of your data, there is no proxy to looking at your data - both test and production data. In some cases, it may not be possible to do this when you are operating in a highly secure/private environment. But, you need to figure out a way to collect and look at all the LLM generations closely, especially in the early days. This will inform not just the quality of the outputs the users are experiencing, but also push you in the direction of identifying what metrics actually make sense for your use case.  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Manually Evaluate&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;p&gt;LLM based evaluations are not fool proof and you need to tweak and improve the prompts and grading scale continuously based on data. And the way to collect this data is by manually evaluating the outputs yourself. This will help you understand how far apart LLM evals is drifting from the real criteria that you want to evaluate against. It&amp;#39;s important to measure this drift and make sure LLM evals track closely with manual evals at most times.  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Save your model parameters&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;p&gt;Saving the model parameters you are using and tracking the responses along with the model parameters will help you with measuring the quality your product for that specific set of model parameters. This becomes useful when you are noticing a regression in the quality of when you are upgrading to a new model version or swapping out to a completely different model.  &lt;/p&gt;\n\n&lt;p&gt;Leave your thoughts. I would love to hear about your experience managing your LLM powered product in terms of quality and accuracy. Also, I am also building a fully open source and open telemetry based tool called Langtrace AI to basically solve for the above problems.  It&amp;#39;s super easy to setup with just 2 lines of code. Do check it out if you are interested.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1d8euoz/learnings_from_doing_evaluations_for_llm_powered/",
    "numberOfComments": 6,
    "flair": null,
    "upVotes": 17,
    "upVoteRatio": 0.96,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-06-05T02:11:48.000Z",
    "scrapedAt": "2025-08-31T23:58:12.687Z",
    "dataType": "post"
  },
  {
    "id": "t1_lx0nlbx",
    "parsedId": "lx0nlbx",
    "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1gqthrs/structured_outputs_from_open_source_llms/lx0nlbx/",
    "postId": "t3_1gqthrs",
    "parentId": "t3_1gqthrs",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "category": "ArtificialInteligence",
    "communityName": "r/ArtificialInteligence",
    "body": "just use outlines?",
    "createdAt": "2024-11-14T01:38:05.000Z",
    "scrapedAt": "2025-08-31T23:58:12.688Z",
    "upVotes": 1,
    "numberOfreplies": 0,
    "html": "&lt;div class=\"md\"&gt;&lt;p&gt;just use outlines?&lt;/p&gt;\n&lt;/div&gt;",
    "dataType": "comment"
  },
  {
    "id": "t3_1d28t2v",
    "parsedId": "1d28t2v",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1d28t2v/new_paper_certifiably_robust_rag_that_can_provide/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "New Paper: Certifiably robust RAG that can provide robust answers",
    "communityName": "r/LocalLLaMA",
    "parsedCommunityName": "LocalLLaMA",
    "body": "Just saw this new paper that has a new approach to solving for inaccurate RAG responses due to corrupted results in the retrieval.\n\nhttps://arxiv.org/pdf/2405.15556\n\nBasically, they have proposed a keyword aggregation step after retrieval. Haven’t tried it. But seems interesting.\n\n",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just saw this new paper that has a new approach to solving for inaccurate RAG responses due to corrupted results in the retrieval.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://arxiv.org/pdf/2405.15556\"&gt;https://arxiv.org/pdf/2405.15556&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Basically, they have proposed a keyword aggregation step after retrieval. Haven’t tried it. But seems interesting.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://i.redd.it/ley3utk3v23d1.jpeg",
    "numberOfComments": 31,
    "flair": "Discussion",
    "upVotes": 233,
    "upVoteRatio": 0.93,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "https://a.thumbs.redditmedia.com/dx80Dwt8NNex1zCPue5wuYG1xM6ORL6h7YCgYD5Imx8.jpg",
    "imageUrls": [
      "https://i.redd.it/ley3utk3v23d1.jpeg"
    ],
    "createdAt": "2024-05-28T02:22:58.000Z",
    "scrapedAt": "2025-08-31T23:58:12.740Z",
    "dataType": "post"
  },
  {
    "id": "t3_1d2nfuz",
    "parsedId": "1d2nfuz",
    "url": "https://www.reddit.com/r/LangChain/comments/1d2nfuz/shopify_all_in_on_promptfoo/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Shopify all in on Promptfoo",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "I am a big fan of Promptfoo aswell. ",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a big fan of Promptfoo aswell. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://i.redd.it/qgg45w3d073d1.jpeg",
    "numberOfComments": 0,
    "flair": "Discussion",
    "upVotes": 9,
    "upVoteRatio": 0.8,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "https://b.thumbs.redditmedia.com/9qofP74Xdz7n-wtyaxYQGHQ3Rw_svqJXZcImR2B7HWc.jpg",
    "imageUrls": [
      "https://i.redd.it/qgg45w3d073d1.jpeg"
    ],
    "createdAt": "2024-05-28T16:19:36.000Z",
    "scrapedAt": "2025-08-31T23:58:12.792Z",
    "dataType": "post"
  },
  {
    "id": "t3_1d1bnql",
    "parsedId": "1d1bnql",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1d1bnql/awesome_prompting_techniques/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Awesome prompting techniques",
    "communityName": "r/LocalLLaMA",
    "parsedCommunityName": "LocalLLaMA",
    "body": "https://arxiv.org/pdf/2312.16171v2\n",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://arxiv.org/pdf/2312.16171v2\"&gt;https://arxiv.org/pdf/2312.16171v2&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://i.redd.it/g6v6ag3h9u2d1.jpeg",
    "numberOfComments": 85,
    "flair": "Resources",
    "upVotes": 740,
    "upVoteRatio": 0.97,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "https://b.thumbs.redditmedia.com/eKQ2D21MgN98HviHbmwqY6T_uaNFNMiXUbd6n_mhJDg.jpg",
    "imageUrls": [
      "https://i.redd.it/g6v6ag3h9u2d1.jpeg"
    ],
    "createdAt": "2024-05-26T21:27:32.000Z",
    "scrapedAt": "2025-08-31T23:58:14.321Z",
    "dataType": "post"
  },
  {
    "id": "t3_1d1afqa",
    "parsedId": "1d1afqa",
    "url": "https://www.reddit.com/r/LangChain/comments/1d1afqa/awesome_prompting_techniques/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Awesome prompting techniques",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "https://arxiv.org/pdf/2312.16171v2",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://arxiv.org/pdf/2312.16171v2\"&gt;https://arxiv.org/pdf/2312.16171v2&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://i.redd.it/qpe806ybzt2d1.jpeg",
    "numberOfComments": 8,
    "flair": "Resources",
    "upVotes": 109,
    "upVoteRatio": 0.93,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "https://a.thumbs.redditmedia.com/W7FC35lxt0X8RdutN2d2wul9wzpcmuecxatG6InEze8.jpg",
    "imageUrls": [
      "https://i.redd.it/qpe806ybzt2d1.jpeg"
    ],
    "createdAt": "2024-05-26T20:30:43.000Z",
    "scrapedAt": "2025-08-31T23:58:14.351Z",
    "dataType": "post"
  },
  {
    "id": "t3_1d1aggn",
    "parsedId": "1d1aggn",
    "url": "https://www.reddit.com/r/PromptEngineering/comments/1d1aggn/awesome_prompting_techniques/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Awesome prompting techniques",
    "communityName": "r/PromptEngineering",
    "parsedCommunityName": "PromptEngineering",
    "body": "https://arxiv.org/pdf/2312.16171v2\nCheck out page 5",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://arxiv.org/pdf/2312.16171v2\"&gt;https://arxiv.org/pdf/2312.16171v2&lt;/a&gt;\nCheck out page 5&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/PromptEngineering/comments/1d1aggn/awesome_prompting_techniques/",
    "numberOfComments": 2,
    "flair": "Ideas &amp; Collaboration",
    "upVotes": 9,
    "upVoteRatio": 0.81,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-05-26T20:31:41.000Z",
    "scrapedAt": "2025-08-31T23:58:14.450Z",
    "dataType": "post"
  },
  {
    "id": "t3_1czptyf",
    "parsedId": "1czptyf",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1czptyf/what_evaluation_toolsmethods_do_you_use/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "What evaluation tools/methods do you use?",
    "communityName": "r/LocalLLaMA",
    "parsedCommunityName": "LocalLLaMA",
    "body": "Looking to understand what evaluation tools/methods people like and use the most?\n\n[View Poll](https://www.reddit.com/poll/1czptyf)",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking to understand what evaluation tools/methods people like and use the most?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/1czptyf\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LocalLLaMA/comments/1czptyf/what_evaluation_toolsmethods_do_you_use/",
    "numberOfComments": 5,
    "flair": "Discussion",
    "upVotes": 5,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-05-24T17:09:49.000Z",
    "scrapedAt": "2025-08-31T23:58:14.552Z",
    "dataType": "post"
  },
  {
    "id": "t3_1czpwfl",
    "parsedId": "1czpwfl",
    "url": "https://www.reddit.com/r/MachineLearning/comments/1czpwfl/d_what_evaluation_toolsmethods_do_you_use/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "[D] What evaluation tools/methods do you use?",
    "communityName": "r/MachineLearning",
    "parsedCommunityName": "MachineLearning",
    "body": "[removed]",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/MachineLearning/comments/1czpwfl/d_what_evaluation_toolsmethods_do_you_use/",
    "numberOfComments": 1,
    "flair": "Discussion",
    "upVotes": 0,
    "upVoteRatio": 0.4,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "default",
    "imageUrls": [],
    "createdAt": "2024-05-24T17:12:44.000Z",
    "scrapedAt": "2025-08-31T23:58:14.593Z",
    "dataType": "post"
  },
  {
    "id": "t3_1czpvsf",
    "parsedId": "1czpvsf",
    "url": "https://www.reddit.com/r/MachineLearning/comments/1czpvsf/what_evaluation_toolsmethods_do_you_use/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "What evaluation tools/methods do you use?",
    "communityName": "r/MachineLearning",
    "parsedCommunityName": "MachineLearning",
    "body": "[removed]",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/MachineLearning/comments/1czpvsf/what_evaluation_toolsmethods_do_you_use/",
    "numberOfComments": 1,
    "flair": null,
    "upVotes": 1,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "default",
    "imageUrls": [],
    "createdAt": "2024-05-24T17:11:59.000Z",
    "scrapedAt": "2025-08-31T23:58:14.625Z",
    "dataType": "post"
  },
  {
    "id": "t3_1czpsmq",
    "parsedId": "1czpsmq",
    "url": "https://www.reddit.com/r/LangChain/comments/1czpsmq/what_evaluation_toolsmethods_do_you_use/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "What evaluation tools/methods do you use?",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "Looking to understand what evaluation tools/methods people like and use the most?\n\n[View Poll](https://www.reddit.com/poll/1czpsmq)",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking to understand what evaluation tools/methods people like and use the most?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/1czpsmq\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1czpsmq/what_evaluation_toolsmethods_do_you_use/",
    "numberOfComments": 1,
    "flair": null,
    "upVotes": 1,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-05-24T17:08:15.000Z",
    "scrapedAt": "2025-08-31T23:58:14.680Z",
    "dataType": "post"
  },
  {
    "id": "t3_1crvzvd",
    "parsedId": "1crvzvd",
    "url": "https://www.reddit.com/r/LangChain/comments/1crvzvd/what_are_your_current_challenges_with_evaluations/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "What are your current challenges with evaluations?",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "What challenges are you facing and what tools are you using? I am thinking about building out a developer friendly open source evaluations tool kit. Thinking of starting with a simple interface where you pass the context, input, output and expected output and run it through some basic tests - both LLM based and non LLM based and also allow the ability to write custom assertions.\n\nBut, am wondering if you all have any insights into what other capabilities might be useful. ",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What challenges are you facing and what tools are you using? I am thinking about building out a developer friendly open source evaluations tool kit. Thinking of starting with a simple interface where you pass the context, input, output and expected output and run it through some basic tests - both LLM based and non LLM based and also allow the ability to write custom assertions.&lt;/p&gt;\n\n&lt;p&gt;But, am wondering if you all have any insights into what other capabilities might be useful. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1crvzvd/what_are_your_current_challenges_with_evaluations/",
    "numberOfComments": 4,
    "flair": "Discussion",
    "upVotes": 4,
    "upVoteRatio": 0.84,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-05-14T16:12:28.000Z",
    "scrapedAt": "2025-08-31T23:58:14.709Z",
    "dataType": "post"
  },
  {
    "id": "t3_1crw0xr",
    "parsedId": "1crw0xr",
    "url": "https://www.reddit.com/r/PromptEngineering/comments/1crw0xr/what_are_your_current_challenges_with_evaluations/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "What are your current challenges with evaluations",
    "communityName": "r/PromptEngineering",
    "parsedCommunityName": "PromptEngineering",
    "body": "What are your current challenges with evaluations?\n\nWhat challenges are you facing and what tools are you using? I am thinking about building out a developer friendly open source evaluations tool kit. Thinking of starting with a simple interface where you pass the context, input, output and expected output and run it through some basic tests - both LLM based and non LLM based and also allow the ability to write custom assertions.\n\nBut, am wondering if you all have any insights into what other capabilities might be useful. ",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are your current challenges with evaluations?&lt;/p&gt;\n\n&lt;p&gt;What challenges are you facing and what tools are you using? I am thinking about building out a developer friendly open source evaluations tool kit. Thinking of starting with a simple interface where you pass the context, input, output and expected output and run it through some basic tests - both LLM based and non LLM based and also allow the ability to write custom assertions.&lt;/p&gt;\n\n&lt;p&gt;But, am wondering if you all have any insights into what other capabilities might be useful. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/PromptEngineering/comments/1crw0xr/what_are_your_current_challenges_with_evaluations/",
    "numberOfComments": 0,
    "flair": "Ideas &amp; Collaboration",
    "upVotes": 3,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-05-14T16:13:45.000Z",
    "scrapedAt": "2025-08-31T23:58:14.739Z",
    "dataType": "post"
  },
  {
    "id": "t3_1crw0h2",
    "parsedId": "1crw0h2",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1crw0h2/what_are_you_current_challenges_with_evaluations/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "What are you current challenges with evaluations?",
    "communityName": "r/LocalLLaMA",
    "parsedCommunityName": "LocalLLaMA",
    "body": "What are your current challenges with evaluations?\n\nWhat challenges are you facing and what tools are you using? I am thinking about building out a developer friendly open source evaluations tool kit. Thinking of starting with a simple interface where you pass the context, input, output and expected output and run it through some basic tests - both LLM based and non LLM based and also allow the ability to write custom assertions.\n\nBut, am wondering if you all have any insights into what other capabilities might be useful. ",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are your current challenges with evaluations?&lt;/p&gt;\n\n&lt;p&gt;What challenges are you facing and what tools are you using? I am thinking about building out a developer friendly open source evaluations tool kit. Thinking of starting with a simple interface where you pass the context, input, output and expected output and run it through some basic tests - both LLM based and non LLM based and also allow the ability to write custom assertions.&lt;/p&gt;\n\n&lt;p&gt;But, am wondering if you all have any insights into what other capabilities might be useful. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LocalLLaMA/comments/1crw0h2/what_are_you_current_challenges_with_evaluations/",
    "numberOfComments": 2,
    "flair": "Discussion",
    "upVotes": 1,
    "upVoteRatio": 0.56,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-05-14T16:13:11.000Z",
    "scrapedAt": "2025-08-31T23:58:14.779Z",
    "dataType": "post"
  },
  {
    "id": "t3_1cqq1in",
    "parsedId": "1cqq1in",
    "url": "https://www.reddit.com/r/MachineLearning/comments/1cqq1in/d_thoughts_on_dspy/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "[D] Thoughts on DSPy",
    "communityName": "r/MachineLearning",
    "parsedCommunityName": "MachineLearning",
    "body": "I have been tinkering with DSPy and thought I will share my 2 cents here for anyone who is planning to explore it:\n\nThe core idea behind DSPy are two things:\n\n1.\t⁠Separate programming from prompting\n2.\t⁠incorporate some of the best practice prompting techniques under the hood and expose it as a “signature”\n\nImagine working on a RAG. Today, the typical approach is to write some retrieval and pass the results to a language model for natural language generation. But, after the first pass, you realize it’s not perfect and you need to iterate and improve it. Typically, there are 2 levers to pull:\n\n1.\t⁠Document Chunking, insertion and Retrieval strategy\n2.\t⁠Language model settings and prompt engineering\n\nNow, you try a few things, maybe document the performance in a google sheet, iterate and arrive at an ideal set of variables that gives max accuracy.\n\nNow, let’s say after a month, model upgrades, and all of a sudden the accuracy of your RAG regresses. Again you are back to square one, cos you don’t know what to optimize now - retrieval or model? You see what the problem is with this approach? This is a very open ended, monolithic, brittle and unstructured way to optimize and build language model based applications.\n\nThis is precisely the problem DSPy is trying to solve. Whatever you can achieve with DSPy can be achieved with native prompt engineering and program composition techniques but it is purely dependent on the programmers skill. But DSPy provides native constructs which anyone can learn and use for trying different techniques in a systematic manner.\n\nDSPy the concept:\n\nSeparate prompting from programming and signatures\n\nDSPy does not do any magic with the language model. It just uses a bunch of prompt templates behind the scenes and exposes them as signatures. Ex: when you write a signature like ‘context, question -&gt; answer’, DSPy adds a typical RAG prompt before it makes the call to the LLM. But DSPy also gives you nice features like module settings, assertion based backtracking and automatic prompt optimization.\n\nBasically, you can do something like this with DSPy,\n\n“Given a context and question, answer the following question. Make sure the answer is only “yes” or “no””. If the language model responds with anything else, traditionally we prompt engineer our way to fix it. In DSPy, you can assert the answer for “yes” or “no” and if the assertion fails, DSPy will backtrack automatically, update the prompt to say something like, “this is not a correct answer- {previous_answer} and always only respond with a “yes” or “no”” and makes another language model call which improves the LLMs response because of this newly optimized prompt. In addition, you can also incorporate things like multi hops in your retrieval where you can do something like “retrieve -&gt; generate queries and then retrieve again using the generated queries” for n times and build up a larger context to answer the original question.\n\nObviously, this can also be done using usual prompt engineering and programming techniques, but the framework exposes native easy to use settings and constructs to do these things more naturally. DSPy as a concept really shines when you are composing a pipeline of language model calls where prompt engineering the entire pipeline or even module wise can lead to a brittle Pipeline.\n\nDSPy the Framework:\n\nNow coming to the framework which is built in python, I think the framework as it stands today is\n\n1.\t⁠Not production ready\n2.\t⁠Lacks clear documentation\n3.\t⁠Poorly designed with not so clean interfaces and abstractions\n\nTo me it felt like a rushed implementation with little thought for design thinking, testing and programming principles. The framework code is very hard to understand with a lot of meta programming and data structure parsing and construction going behind the scenes that are scary to run in production.\n\nThis is a huge deterrent for anyone trying to learn and use this framework. But, I am sure the creators are thinking about all this and are working to reengineer the framework. There’s also a typescript implementation of this framework that is fairly less popular but has a much better and cleaner design and codebase:\n\nhttps://github.com/dosco/llm-client/\n\nMy final thought about this framework is, it’s a promising concept, but it does not change anything about what we already know about LLMs. Also, hiding prompts as templates does not mean prompt engineering is going away, someone still needs to “engineer” the prompts the framework uses and imo the framework should expose these templates and give control back to the developers that way, the vision of separate programming and prompting co exists with giving control not only to program but also to prompt.\n\nFinally, I was able to understand all this by running DSPy programs and visualizing the LLM calls and what prompts it’s adding using my open source tool - https://github.com/Scale3-Labs/langtrace . Do check it out and let me know if you have any feedback.",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been tinkering with DSPy and thought I will share my 2 cents here for anyone who is planning to explore it:&lt;/p&gt;\n\n&lt;p&gt;The core idea behind DSPy are two things:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt; ⁠Separate programming from prompting&lt;/li&gt;\n&lt;li&gt; ⁠incorporate some of the best practice prompting techniques under the hood and expose it as a “signature”&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Imagine working on a RAG. Today, the typical approach is to write some retrieval and pass the results to a language model for natural language generation. But, after the first pass, you realize it’s not perfect and you need to iterate and improve it. Typically, there are 2 levers to pull:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt; ⁠Document Chunking, insertion and Retrieval strategy&lt;/li&gt;\n&lt;li&gt; ⁠Language model settings and prompt engineering&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Now, you try a few things, maybe document the performance in a google sheet, iterate and arrive at an ideal set of variables that gives max accuracy.&lt;/p&gt;\n\n&lt;p&gt;Now, let’s say after a month, model upgrades, and all of a sudden the accuracy of your RAG regresses. Again you are back to square one, cos you don’t know what to optimize now - retrieval or model? You see what the problem is with this approach? This is a very open ended, monolithic, brittle and unstructured way to optimize and build language model based applications.&lt;/p&gt;\n\n&lt;p&gt;This is precisely the problem DSPy is trying to solve. Whatever you can achieve with DSPy can be achieved with native prompt engineering and program composition techniques but it is purely dependent on the programmers skill. But DSPy provides native constructs which anyone can learn and use for trying different techniques in a systematic manner.&lt;/p&gt;\n\n&lt;p&gt;DSPy the concept:&lt;/p&gt;\n\n&lt;p&gt;Separate prompting from programming and signatures&lt;/p&gt;\n\n&lt;p&gt;DSPy does not do any magic with the language model. It just uses a bunch of prompt templates behind the scenes and exposes them as signatures. Ex: when you write a signature like ‘context, question -&amp;gt; answer’, DSPy adds a typical RAG prompt before it makes the call to the LLM. But DSPy also gives you nice features like module settings, assertion based backtracking and automatic prompt optimization.&lt;/p&gt;\n\n&lt;p&gt;Basically, you can do something like this with DSPy,&lt;/p&gt;\n\n&lt;p&gt;“Given a context and question, answer the following question. Make sure the answer is only “yes” or “no””. If the language model responds with anything else, traditionally we prompt engineer our way to fix it. In DSPy, you can assert the answer for “yes” or “no” and if the assertion fails, DSPy will backtrack automatically, update the prompt to say something like, “this is not a correct answer- {previous_answer} and always only respond with a “yes” or “no”” and makes another language model call which improves the LLMs response because of this newly optimized prompt. In addition, you can also incorporate things like multi hops in your retrieval where you can do something like “retrieve -&amp;gt; generate queries and then retrieve again using the generated queries” for n times and build up a larger context to answer the original question.&lt;/p&gt;\n\n&lt;p&gt;Obviously, this can also be done using usual prompt engineering and programming techniques, but the framework exposes native easy to use settings and constructs to do these things more naturally. DSPy as a concept really shines when you are composing a pipeline of language model calls where prompt engineering the entire pipeline or even module wise can lead to a brittle Pipeline.&lt;/p&gt;\n\n&lt;p&gt;DSPy the Framework:&lt;/p&gt;\n\n&lt;p&gt;Now coming to the framework which is built in python, I think the framework as it stands today is&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt; ⁠Not production ready&lt;/li&gt;\n&lt;li&gt; ⁠Lacks clear documentation&lt;/li&gt;\n&lt;li&gt; ⁠Poorly designed with not so clean interfaces and abstractions&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;To me it felt like a rushed implementation with little thought for design thinking, testing and programming principles. The framework code is very hard to understand with a lot of meta programming and data structure parsing and construction going behind the scenes that are scary to run in production.&lt;/p&gt;\n\n&lt;p&gt;This is a huge deterrent for anyone trying to learn and use this framework. But, I am sure the creators are thinking about all this and are working to reengineer the framework. There’s also a typescript implementation of this framework that is fairly less popular but has a much better and cleaner design and codebase:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/dosco/llm-client/\"&gt;https://github.com/dosco/llm-client/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;My final thought about this framework is, it’s a promising concept, but it does not change anything about what we already know about LLMs. Also, hiding prompts as templates does not mean prompt engineering is going away, someone still needs to “engineer” the prompts the framework uses and imo the framework should expose these templates and give control back to the developers that way, the vision of separate programming and prompting co exists with giving control not only to program but also to prompt.&lt;/p&gt;\n\n&lt;p&gt;Finally, I was able to understand all this by running DSPy programs and visualizing the LLM calls and what prompts it’s adding using my open source tool - &lt;a href=\"https://github.com/Scale3-Labs/langtrace\"&gt;https://github.com/Scale3-Labs/langtrace&lt;/a&gt; . Do check it out and let me know if you have any feedback.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/MachineLearning/comments/1cqq1in/d_thoughts_on_dspy/",
    "numberOfComments": 5,
    "flair": "Discussion",
    "upVotes": 22,
    "upVoteRatio": 0.79,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [
      "https://external-i.redd.it/s92lJlAylBFtkz9YobpFDKpb_grBOVLNGKIfoVO83do.jpg"
    ],
    "createdAt": "2024-05-13T03:47:27.000Z",
    "scrapedAt": "2025-08-31T23:58:14.847Z",
    "dataType": "post"
  },
  {
    "id": "t3_1cqexk6",
    "parsedId": "1cqexk6",
    "url": "https://www.reddit.com/r/LangChain/comments/1cqexk6/thoughts_on_dspy/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Thoughts on DSPy",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "I have been tinkering with DSPy and thought I will share my 2 cents here for anyone who is planning to explore it:\n\nThe core idea behind DSPy are two things:\n\n1.\t⁠Separate programming from prompting\n2.\t⁠incorporate some of the best practice prompting techniques under the hood and expose it as a “signature”\n\nImagine working on a RAG. Today, the typical approach is to write some retrieval and pass the results to a language model for natural language generation. But, after the first pass, you realize it’s not perfect and you need to iterate and improve it. Typically, there are 2 levers to pull:\n\n1.\t⁠Document Chunking, insertion and Retrieval strategy\n2.\t⁠Language model settings and prompt engineering\n\nNow, you try a few things, maybe document the performance in a google sheet, iterate and arrive at an ideal set of variables that gives max accuracy.\n\nNow, let’s say after a month, model upgrades, and all of a sudden the accuracy of your RAG regresses. Again you are back to square one, cos you don’t know what to optimize now - retrieval or model? You see what the problem is with this approach? This is a very open ended, monolithic, brittle and unstructured way to optimize and build language model based applications.\n\nThis is precisely the problem DSPy is trying to solve. Whatever you can achieve with DSPy can be achieved with native prompt engineering and program composition techniques but it is purely dependent on the programmers skill. But DSPy provides native constructs which anyone can learn and use for trying different techniques in a systematic manner.\n\nDSPy the concept:\n\nSeparate prompting from programming and signatures\n\nDSPy does not do any magic with the language model. It just uses a bunch of prompt templates behind the scenes and exposes them as signatures. Ex: when you write a signature like ‘context, question -&gt; answer’, DSPy adds a typical RAG prompt before it makes the call to the LLM. But DSPy also gives you nice features like module settings, assertion based backtracking and automatic prompt optimization.\n\nBasically, you can do something like this with DSPy,\n\n“Given a context and question, answer the following question. Make sure the answer is only “yes” or “no””. If the language model responds with anything else, traditionally we prompt engineer our way to fix it. In DSPy, you can assert the answer for “yes” or “no” and if the assertion fails, DSPy will backtrack automatically, update the prompt to say something like, “this is not a correct answer- {previous_answer} and always only respond with a “yes” or “no”” and makes another language model call which improves the LLMs response because of this newly optimized prompt. In addition, you can also incorporate things like multi hops in your retrieval where you can do something like “retrieve -&gt; generate queries and then retrieve again using the generated queries” for n times and build up a larger context to answer the original question.\n\nObviously, this can also be done using usual prompt engineering and programming techniques, but the framework exposes native easy to use settings and constructs to do these things more naturally. DSPy as a concept really shines when you are composing a pipeline of language model calls where prompt engineering the entire pipeline or even module wise can lead to a brittle Pipeline.\n\nDSPy the Framework:\n\nNow coming to the framework which is built in python, I think the framework as it stands today is\n\n1.\t⁠Not production ready\n2.\t⁠Buggy and poorly implemented\n3.\t⁠Lacks proper documentation\n4.\t⁠Poorly designed\n\nTo me it felt like a rushed implementation with little thought for design thinking, testing and programming principles. The framework code is very hard to understand with a lot of meta programming and data structure parsing and construction going behind the scenes that are scary to run in production.\n\nThis is a huge deterrent for anyone trying to learn and use this framework. But, I am sure the creators are thinking about all this and are working to reengineer the framework. There’s also a typescript implementation of this framework that is fairly less popular but has a much better and cleaner design and codebase:\n\nhttps://github.com/dosco/llm-client/\n\nMy final thought about this framework is, it’s a promising concept, but it does not change anything about what we already know about LLMs. Also, hiding prompts as templates does not mean prompt engineering is going away, someone still needs to “engineer” the prompts the framework uses and imo the framework should expose these templates and give control back to the developers that way, the vision of separate programming and prompting co exists with giving control not only to program but also to prompt.\n\nFinally, I was able to understand all this by running DSPy programs and visualizing the LLM calls and what prompts it’s adding using my open source tool - https://github.com/Scale3-Labs/langtrace . Do check it out and let me know if you have any feedback.",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been tinkering with DSPy and thought I will share my 2 cents here for anyone who is planning to explore it:&lt;/p&gt;\n\n&lt;p&gt;The core idea behind DSPy are two things:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt; ⁠Separate programming from prompting&lt;/li&gt;\n&lt;li&gt; ⁠incorporate some of the best practice prompting techniques under the hood and expose it as a “signature”&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Imagine working on a RAG. Today, the typical approach is to write some retrieval and pass the results to a language model for natural language generation. But, after the first pass, you realize it’s not perfect and you need to iterate and improve it. Typically, there are 2 levers to pull:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt; ⁠Document Chunking, insertion and Retrieval strategy&lt;/li&gt;\n&lt;li&gt; ⁠Language model settings and prompt engineering&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Now, you try a few things, maybe document the performance in a google sheet, iterate and arrive at an ideal set of variables that gives max accuracy.&lt;/p&gt;\n\n&lt;p&gt;Now, let’s say after a month, model upgrades, and all of a sudden the accuracy of your RAG regresses. Again you are back to square one, cos you don’t know what to optimize now - retrieval or model? You see what the problem is with this approach? This is a very open ended, monolithic, brittle and unstructured way to optimize and build language model based applications.&lt;/p&gt;\n\n&lt;p&gt;This is precisely the problem DSPy is trying to solve. Whatever you can achieve with DSPy can be achieved with native prompt engineering and program composition techniques but it is purely dependent on the programmers skill. But DSPy provides native constructs which anyone can learn and use for trying different techniques in a systematic manner.&lt;/p&gt;\n\n&lt;p&gt;DSPy the concept:&lt;/p&gt;\n\n&lt;p&gt;Separate prompting from programming and signatures&lt;/p&gt;\n\n&lt;p&gt;DSPy does not do any magic with the language model. It just uses a bunch of prompt templates behind the scenes and exposes them as signatures. Ex: when you write a signature like ‘context, question -&amp;gt; answer’, DSPy adds a typical RAG prompt before it makes the call to the LLM. But DSPy also gives you nice features like module settings, assertion based backtracking and automatic prompt optimization.&lt;/p&gt;\n\n&lt;p&gt;Basically, you can do something like this with DSPy,&lt;/p&gt;\n\n&lt;p&gt;“Given a context and question, answer the following question. Make sure the answer is only “yes” or “no””. If the language model responds with anything else, traditionally we prompt engineer our way to fix it. In DSPy, you can assert the answer for “yes” or “no” and if the assertion fails, DSPy will backtrack automatically, update the prompt to say something like, “this is not a correct answer- {previous_answer} and always only respond with a “yes” or “no”” and makes another language model call which improves the LLMs response because of this newly optimized prompt. In addition, you can also incorporate things like multi hops in your retrieval where you can do something like “retrieve -&amp;gt; generate queries and then retrieve again using the generated queries” for n times and build up a larger context to answer the original question.&lt;/p&gt;\n\n&lt;p&gt;Obviously, this can also be done using usual prompt engineering and programming techniques, but the framework exposes native easy to use settings and constructs to do these things more naturally. DSPy as a concept really shines when you are composing a pipeline of language model calls where prompt engineering the entire pipeline or even module wise can lead to a brittle Pipeline.&lt;/p&gt;\n\n&lt;p&gt;DSPy the Framework:&lt;/p&gt;\n\n&lt;p&gt;Now coming to the framework which is built in python, I think the framework as it stands today is&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt; ⁠Not production ready&lt;/li&gt;\n&lt;li&gt; ⁠Buggy and poorly implemented&lt;/li&gt;\n&lt;li&gt; ⁠Lacks proper documentation&lt;/li&gt;\n&lt;li&gt; ⁠Poorly designed&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;To me it felt like a rushed implementation with little thought for design thinking, testing and programming principles. The framework code is very hard to understand with a lot of meta programming and data structure parsing and construction going behind the scenes that are scary to run in production.&lt;/p&gt;\n\n&lt;p&gt;This is a huge deterrent for anyone trying to learn and use this framework. But, I am sure the creators are thinking about all this and are working to reengineer the framework. There’s also a typescript implementation of this framework that is fairly less popular but has a much better and cleaner design and codebase:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/dosco/llm-client/\"&gt;https://github.com/dosco/llm-client/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;My final thought about this framework is, it’s a promising concept, but it does not change anything about what we already know about LLMs. Also, hiding prompts as templates does not mean prompt engineering is going away, someone still needs to “engineer” the prompts the framework uses and imo the framework should expose these templates and give control back to the developers that way, the vision of separate programming and prompting co exists with giving control not only to program but also to prompt.&lt;/p&gt;\n\n&lt;p&gt;Finally, I was able to understand all this by running DSPy programs and visualizing the LLM calls and what prompts it’s adding using my open source tool - &lt;a href=\"https://github.com/Scale3-Labs/langtrace\"&gt;https://github.com/Scale3-Labs/langtrace&lt;/a&gt; . Do check it out and let me know if you have any feedback.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1cqexk6/thoughts_on_dspy/",
    "numberOfComments": 26,
    "flair": "Discussion",
    "upVotes": 83,
    "upVoteRatio": 0.99,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [
      "https://external-i.redd.it/s92lJlAylBFtkz9YobpFDKpb_grBOVLNGKIfoVO83do.jpg"
    ],
    "createdAt": "2024-05-12T18:50:23.000Z",
    "scrapedAt": "2025-08-31T23:58:14.874Z",
    "dataType": "post"
  },
  {
    "id": "t3_1cqpzwr",
    "parsedId": "1cqpzwr",
    "url": "https://www.reddit.com/r/deeplearning/comments/1cqpzwr/thoughts_on_dspy/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Thoughts on DSPy",
    "communityName": "r/deeplearning",
    "parsedCommunityName": "deeplearning",
    "body": "\nI have been tinkering with DSPy and thought I will share my 2 cents here for anyone who is planning to explore it:\n\nThe core idea behind DSPy are two things:\n\n1.\t⁠Separate programming from prompting\n2.\t⁠incorporate some of the best practice prompting techniques under the hood and expose it as a “signature”\n\nImagine working on a RAG. Today, the typical approach is to write some retrieval and pass the results to a language model for natural language generation. But, after the first pass, you realize it’s not perfect and you need to iterate and improve it. Typically, there are 2 levers to pull:\n\n1.\t⁠Document Chunking, insertion and Retrieval strategy\n2.\t⁠Language model settings and prompt engineering\n\nNow, you try a few things, maybe document the performance in a google sheet, iterate and arrive at an ideal set of variables that gives max accuracy.\n\nNow, let’s say after a month, model upgrades, and all of a sudden the accuracy of your RAG regresses. Again you are back to square one, cos you don’t know what to optimize now - retrieval or model? You see what the problem is with this approach? This is a very open ended, monolithic, brittle and unstructured way to optimize and build language model based applications.\n\nThis is precisely the problem DSPy is trying to solve. Whatever you can achieve with DSPy can be achieved with native prompt engineering and program composition techniques but it is purely dependent on the programmers skill. But DSPy provides native constructs which anyone can learn and use for trying different techniques in a systematic manner.\n\nDSPy the concept:\n\nSeparate prompting from programming and signatures\n\nDSPy does not do any magic with the language model. It just uses a bunch of prompt templates behind the scenes and exposes them as signatures. Ex: when you write a signature like ‘context, question -&gt; answer’, DSPy adds a typical RAG prompt before it makes the call to the LLM. But DSPy also gives you nice features like module settings, assertion based backtracking and automatic prompt optimization.\n\nBasically, you can do something like this with DSPy,\n\n“Given a context and question, answer the following question. Make sure the answer is only “yes” or “no””. If the language model responds with anything else, traditionally we prompt engineer our way to fix it. In DSPy, you can assert the answer for “yes” or “no” and if the assertion fails, DSPy will backtrack automatically, update the prompt to say something like, “this is not a correct answer- {previous_answer} and always only respond with a “yes” or “no”” and makes another language model call which improves the LLMs response because of this newly optimized prompt. In addition, you can also incorporate things like multi hops in your retrieval where you can do something like “retrieve -&gt; generate queries and then retrieve again using the generated queries” for n times and build up a larger context to answer the original question.\n\nObviously, this can also be done using usual prompt engineering and programming techniques, but the framework exposes native easy to use settings and constructs to do these things more naturally. DSPy as a concept really shines when you are composing a pipeline of language model calls where prompt engineering the entire pipeline or even module wise can lead to a brittle Pipeline.\n\nDSPy the Framework:\n\nNow coming to the framework which is built in python, I think the framework as it stands today is\n\n1.\t⁠Not production ready\n2.\t⁠Lacks clear documentation\n3.\t⁠Poorly designed with not so clean interfaces and abstractions\n\nTo me it felt like a rushed implementation with little thought for design thinking, testing and programming principles. The framework code is very hard to understand with a lot of meta programming and data structure parsing and construction going behind the scenes that are scary to run in production.\n\nThis is a huge deterrent for anyone trying to learn and use this framework. But, I am sure the creators are thinking about all this and are working to reengineer the framework. There’s also a typescript implementation of this framework that is fairly less popular but has a much better and cleaner design and codebase:\n\nhttps://github.com/dosco/llm-client/\n\nMy final thought about this framework is, it’s a promising concept, but it does not change anything about what we already know about LLMs. Also, hiding prompts as templates does not mean prompt engineering is going away, someone still needs to “engineer” the prompts the framework uses and imo the framework should expose these templates and give control back to the developers that way, the vision of separate programming and prompting co exists with giving control not only to program but also to prompt.\n\nFinally, I was able to understand all this by running DSPy programs and visualizing the LLM calls and what prompts it’s adding using my open source tool - https://github.com/Scale3-Labs/langtrace . Do check it out and let me know if you have any feedback.",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been tinkering with DSPy and thought I will share my 2 cents here for anyone who is planning to explore it:&lt;/p&gt;\n\n&lt;p&gt;The core idea behind DSPy are two things:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt; ⁠Separate programming from prompting&lt;/li&gt;\n&lt;li&gt; ⁠incorporate some of the best practice prompting techniques under the hood and expose it as a “signature”&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Imagine working on a RAG. Today, the typical approach is to write some retrieval and pass the results to a language model for natural language generation. But, after the first pass, you realize it’s not perfect and you need to iterate and improve it. Typically, there are 2 levers to pull:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt; ⁠Document Chunking, insertion and Retrieval strategy&lt;/li&gt;\n&lt;li&gt; ⁠Language model settings and prompt engineering&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Now, you try a few things, maybe document the performance in a google sheet, iterate and arrive at an ideal set of variables that gives max accuracy.&lt;/p&gt;\n\n&lt;p&gt;Now, let’s say after a month, model upgrades, and all of a sudden the accuracy of your RAG regresses. Again you are back to square one, cos you don’t know what to optimize now - retrieval or model? You see what the problem is with this approach? This is a very open ended, monolithic, brittle and unstructured way to optimize and build language model based applications.&lt;/p&gt;\n\n&lt;p&gt;This is precisely the problem DSPy is trying to solve. Whatever you can achieve with DSPy can be achieved with native prompt engineering and program composition techniques but it is purely dependent on the programmers skill. But DSPy provides native constructs which anyone can learn and use for trying different techniques in a systematic manner.&lt;/p&gt;\n\n&lt;p&gt;DSPy the concept:&lt;/p&gt;\n\n&lt;p&gt;Separate prompting from programming and signatures&lt;/p&gt;\n\n&lt;p&gt;DSPy does not do any magic with the language model. It just uses a bunch of prompt templates behind the scenes and exposes them as signatures. Ex: when you write a signature like ‘context, question -&amp;gt; answer’, DSPy adds a typical RAG prompt before it makes the call to the LLM. But DSPy also gives you nice features like module settings, assertion based backtracking and automatic prompt optimization.&lt;/p&gt;\n\n&lt;p&gt;Basically, you can do something like this with DSPy,&lt;/p&gt;\n\n&lt;p&gt;“Given a context and question, answer the following question. Make sure the answer is only “yes” or “no””. If the language model responds with anything else, traditionally we prompt engineer our way to fix it. In DSPy, you can assert the answer for “yes” or “no” and if the assertion fails, DSPy will backtrack automatically, update the prompt to say something like, “this is not a correct answer- {previous_answer} and always only respond with a “yes” or “no”” and makes another language model call which improves the LLMs response because of this newly optimized prompt. In addition, you can also incorporate things like multi hops in your retrieval where you can do something like “retrieve -&amp;gt; generate queries and then retrieve again using the generated queries” for n times and build up a larger context to answer the original question.&lt;/p&gt;\n\n&lt;p&gt;Obviously, this can also be done using usual prompt engineering and programming techniques, but the framework exposes native easy to use settings and constructs to do these things more naturally. DSPy as a concept really shines when you are composing a pipeline of language model calls where prompt engineering the entire pipeline or even module wise can lead to a brittle Pipeline.&lt;/p&gt;\n\n&lt;p&gt;DSPy the Framework:&lt;/p&gt;\n\n&lt;p&gt;Now coming to the framework which is built in python, I think the framework as it stands today is&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt; ⁠Not production ready&lt;/li&gt;\n&lt;li&gt; ⁠Lacks clear documentation&lt;/li&gt;\n&lt;li&gt; ⁠Poorly designed with not so clean interfaces and abstractions&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;To me it felt like a rushed implementation with little thought for design thinking, testing and programming principles. The framework code is very hard to understand with a lot of meta programming and data structure parsing and construction going behind the scenes that are scary to run in production.&lt;/p&gt;\n\n&lt;p&gt;This is a huge deterrent for anyone trying to learn and use this framework. But, I am sure the creators are thinking about all this and are working to reengineer the framework. There’s also a typescript implementation of this framework that is fairly less popular but has a much better and cleaner design and codebase:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/dosco/llm-client/\"&gt;https://github.com/dosco/llm-client/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;My final thought about this framework is, it’s a promising concept, but it does not change anything about what we already know about LLMs. Also, hiding prompts as templates does not mean prompt engineering is going away, someone still needs to “engineer” the prompts the framework uses and imo the framework should expose these templates and give control back to the developers that way, the vision of separate programming and prompting co exists with giving control not only to program but also to prompt.&lt;/p&gt;\n\n&lt;p&gt;Finally, I was able to understand all this by running DSPy programs and visualizing the LLM calls and what prompts it’s adding using my open source tool - &lt;a href=\"https://github.com/Scale3-Labs/langtrace\"&gt;https://github.com/Scale3-Labs/langtrace&lt;/a&gt; . Do check it out and let me know if you have any feedback.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/deeplearning/comments/1cqpzwr/thoughts_on_dspy/",
    "numberOfComments": 1,
    "flair": null,
    "upVotes": 10,
    "upVoteRatio": 0.86,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [
      "https://external-i.redd.it/s92lJlAylBFtkz9YobpFDKpb_grBOVLNGKIfoVO83do.jpg"
    ],
    "createdAt": "2024-05-13T03:44:58.000Z",
    "scrapedAt": "2025-08-31T23:58:14.904Z",
    "dataType": "post"
  },
  {
    "id": "t3_1cqpyve",
    "parsedId": "1cqpyve",
    "url": "https://www.reddit.com/r/MachineLearning/comments/1cqpyve/thoughts_on_dspy/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Thoughts on DSPy",
    "communityName": "r/MachineLearning",
    "parsedCommunityName": "MachineLearning",
    "body": "[removed]",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/MachineLearning/comments/1cqpyve/thoughts_on_dspy/",
    "numberOfComments": 1,
    "flair": null,
    "upVotes": 1,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "default",
    "imageUrls": [],
    "createdAt": "2024-05-13T03:43:12.000Z",
    "scrapedAt": "2025-08-31T23:58:14.945Z",
    "dataType": "post"
  },
  {
    "id": "t3_1cmk2be",
    "parsedId": "1cmk2be",
    "url": "https://www.reddit.com/r/PromptEngineering/comments/1cmk2be/langtrace_prompt_playground/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Langtrace Prompt Playground ",
    "communityName": "r/PromptEngineering",
    "parsedCommunityName": "PromptEngineering",
    "body": "Hey all,\n\n  \nWe are building an open source project called Langtrace and we recently built a prompt playground inside Langtrace. The goal of this feature is to help you test and iterate on your prompts from a single view across different combinations of models and model settings. \n\nhttps://reddit.com/link/1cmk2be/video/f0ep4zgt02zc1/player\n\n- Support for OpenAI, Anthropic, Cohere and Groq\n\n- Side by side comparison view.\n\n- Comprehensive API settings tab to tweak and iterate on your prompts with different combinations of settings and models. \n\n  \nPlease check it out and let me know if you have any feedback.\n\n[https://github.com/Scale3-Labs/langtrace](https://github.com/Scale3-Labs/langtrace)",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;We are building an open source project called Langtrace and we recently built a prompt playground inside Langtrace. The goal of this feature is to help you test and iterate on your prompts from a single view across different combinations of models and model settings. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://reddit.com/link/1cmk2be/video/f0ep4zgt02zc1/player\"&gt;https://reddit.com/link/1cmk2be/video/f0ep4zgt02zc1/player&lt;/a&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Support for OpenAI, Anthropic, Cohere and Groq&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Side by side comparison view.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Comprehensive API settings tab to tweak and iterate on your prompts with different combinations of settings and models. &lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Please check it out and let me know if you have any feedback.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/Scale3-Labs/langtrace\"&gt;https://github.com/Scale3-Labs/langtrace&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/PromptEngineering/comments/1cmk2be/langtrace_prompt_playground/",
    "numberOfComments": 2,
    "flair": "Prompt Text / Showcase",
    "upVotes": 9,
    "upVoteRatio": 0.92,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "https://b.thumbs.redditmedia.com/GzRiNMOHGMBMInbI3lEYi7uEeVROnYCqLMLWBDcVCKM.jpg",
    "imageUrls": [
      "https://external-i.redd.it/8CGGuhPW2HQcVSRY15YXeHMb0zTWrDu9qYWrqzYZhEw.jpg"
    ],
    "createdAt": "2024-05-07T19:16:54.000Z",
    "scrapedAt": "2025-08-31T23:58:14.988Z",
    "dataType": "post"
  },
  {
    "id": "t3_1cmk3zu",
    "parsedId": "1cmk3zu",
    "url": "https://www.reddit.com/r/OpenAI/comments/1cmk3zu/opensource_prompt_playground_tool/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Opensource Prompt Playground tool",
    "communityName": "r/OpenAI",
    "parsedCommunityName": "OpenAI",
    "body": "Hey all,\n\nWe are building an opensource project called Langtrace and we just added support for prompt playground. The goal of this feature is to help you test and iterate on your prompts from a single view across different combinations of models and model settings.\n\n* Support for OpenAI, Anthropic, Cohere and Groq\n* Side by side comparison view.\n* Comprehensive API settings tab to tweak and iterate on your prompts with different combinations of settings and models.\n\nPlease check it out and let me know if you have any feedback.\n\n[https://langtrace.ai/](https://langtrace.ai/)\n\n[https://github.com/Scale3-Labs/langtrace](https://github.com/Scale3-Labs/langtrace)\n\nhttps://reddit.com/link/1cmk3zu/video/igrybp2712zc1/player\n\n",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;We are building an opensource project called Langtrace and we just added support for prompt playground. The goal of this feature is to help you test and iterate on your prompts from a single view across different combinations of models and model settings.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Support for OpenAI, Anthropic, Cohere and Groq&lt;/li&gt;\n&lt;li&gt;Side by side comparison view.&lt;/li&gt;\n&lt;li&gt;Comprehensive API settings tab to tweak and iterate on your prompts with different combinations of settings and models.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Please check it out and let me know if you have any feedback.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://langtrace.ai/\"&gt;https://langtrace.ai/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/Scale3-Labs/langtrace\"&gt;https://github.com/Scale3-Labs/langtrace&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://reddit.com/link/1cmk3zu/video/igrybp2712zc1/player\"&gt;https://reddit.com/link/1cmk3zu/video/igrybp2712zc1/player&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/OpenAI/comments/1cmk3zu/opensource_prompt_playground_tool/",
    "numberOfComments": 9,
    "flair": "Project",
    "upVotes": 5,
    "upVoteRatio": 0.85,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "https://b.thumbs.redditmedia.com/0cCzvN9L-4VhKsjq4iUnu7QR1MmsBlX9GW-HpAlmols.jpg",
    "imageUrls": [
      "https://external-i.redd.it/NC1sW6cwQYTGxuUvSZWkfQnn_WLopaQp781No9M4rkg.jpg"
    ],
    "createdAt": "2024-05-07T19:18:57.000Z",
    "scrapedAt": "2025-08-31T23:58:15.030Z",
    "dataType": "post"
  },
  {
    "id": "t3_1cmk98d",
    "parsedId": "1cmk98d",
    "url": "https://www.reddit.com/r/SaaS/comments/1cmk98d/prompt_playground_opensource/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Prompt Playground - Opensource",
    "communityName": "r/SaaS",
    "parsedCommunityName": "SaaS",
    "body": "Hey all,\n\nWe are building an open source project called Langtrace and we just added support for prompt playground. The goal of this feature is to help you test and iterate on your prompts from a single view across different combinations of models and model settings.\n\nhttps://reddit.com/link/1cmk98d/video/27scyzpa22zc1/player\n\n* Support for OpenAI, Anthropic, Cohere and Groq\n* Side by side comparison view.\n* Comprehensive API settings tab to tweak and iterate on your prompts with different combinations of settings and models.\n\nPlease check it out and let me know if you have any feedback.\n\n[https://langtrace.ai/](https://langtrace.ai/)\n\n[https://github.com/Scale3-Labs/langtrace](https://github.com/Scale3-Labs/langtrace)\n\n\n\n",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;We are building an open source project called Langtrace and we just added support for prompt playground. The goal of this feature is to help you test and iterate on your prompts from a single view across different combinations of models and model settings.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://reddit.com/link/1cmk98d/video/27scyzpa22zc1/player\"&gt;https://reddit.com/link/1cmk98d/video/27scyzpa22zc1/player&lt;/a&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Support for OpenAI, Anthropic, Cohere and Groq&lt;/li&gt;\n&lt;li&gt;Side by side comparison view.&lt;/li&gt;\n&lt;li&gt;Comprehensive API settings tab to tweak and iterate on your prompts with different combinations of settings and models.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Please check it out and let me know if you have any feedback.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://langtrace.ai/\"&gt;https://langtrace.ai/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/Scale3-Labs/langtrace\"&gt;https://github.com/Scale3-Labs/langtrace&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/SaaS/comments/1cmk98d/prompt_playground_opensource/",
    "numberOfComments": 1,
    "flair": "Build In Public",
    "upVotes": 3,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "https://b.thumbs.redditmedia.com/0cCzvN9L-4VhKsjq4iUnu7QR1MmsBlX9GW-HpAlmols.jpg",
    "imageUrls": [
      "https://external-i.redd.it/NC1sW6cwQYTGxuUvSZWkfQnn_WLopaQp781No9M4rkg.jpg"
    ],
    "createdAt": "2024-05-07T19:25:04.000Z",
    "scrapedAt": "2025-08-31T23:58:15.063Z",
    "dataType": "post"
  },
  {
    "id": "t3_1cmk0dn",
    "parsedId": "1cmk0dn",
    "url": "https://www.reddit.com/r/LangChain/comments/1cmk0dn/langtrace_added_support_for_prompt_playground/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Langtrace - Added support for Prompt Playground",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "Hey all,\n\n  \nWe just added support for prompt playground. The goal of this feature is to help you test and iterate on your prompts from a single view across different combinations of models and model settings. \n\n- Support for OpenAI, Anthropic, Cohere and Groq\n\n- Side by side comparison view.\n\n- Comprehensive API settings tab to tweak and iterate on your prompts with different combinations of settings and models. \n\n  \nPlease check it out and let me know if you have any feedback.\n\n[https://langtrace.ai/](https://langtrace.ai/)\n\n[https://github.com/Scale3-Labs/langtrace](https://github.com/Scale3-Labs/langtrace)\n\nhttps://reddit.com/link/1cmk0dn/video/y0tve9hb02zc1/player\n\n  \n",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;We just added support for prompt playground. The goal of this feature is to help you test and iterate on your prompts from a single view across different combinations of models and model settings. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Support for OpenAI, Anthropic, Cohere and Groq&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Side by side comparison view.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Comprehensive API settings tab to tweak and iterate on your prompts with different combinations of settings and models. &lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Please check it out and let me know if you have any feedback.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://langtrace.ai/\"&gt;https://langtrace.ai/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/Scale3-Labs/langtrace\"&gt;https://github.com/Scale3-Labs/langtrace&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://reddit.com/link/1cmk0dn/video/y0tve9hb02zc1/player\"&gt;https://reddit.com/link/1cmk0dn/video/y0tve9hb02zc1/player&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1cmk0dn/langtrace_added_support_for_prompt_playground/",
    "numberOfComments": 0,
    "flair": "Resources",
    "upVotes": 3,
    "upVoteRatio": 0.8,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "https://b.thumbs.redditmedia.com/0cCzvN9L-4VhKsjq4iUnu7QR1MmsBlX9GW-HpAlmols.jpg",
    "imageUrls": [
      "https://external-i.redd.it/NC1sW6cwQYTGxuUvSZWkfQnn_WLopaQp781No9M4rkg.jpg"
    ],
    "createdAt": "2024-05-07T19:14:36.000Z",
    "scrapedAt": "2025-08-31T23:58:15.095Z",
    "dataType": "post"
  },
  {
    "id": "t3_1ck3k84",
    "parsedId": "1ck3k84",
    "url": "https://www.reddit.com/r/LangChain/comments/1ck3k84/what_are_some_ways_to_test_and_improve_my_rags/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "What are some ways to test and improve my RAGs retrieval strategy?",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "Looking for some tried and tested ways to measure and improve my RAGs retrieval strategy.",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for some tried and tested ways to measure and improve my RAGs retrieval strategy.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1ck3k84/what_are_some_ways_to_test_and_improve_my_rags/",
    "numberOfComments": 2,
    "flair": "Question | Help",
    "upVotes": 8,
    "upVoteRatio": 0.91,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-05-04T15:57:55.000Z",
    "scrapedAt": "2025-08-31T23:58:15.135Z",
    "dataType": "post"
  },
  {
    "id": "t3_1ck3k49",
    "parsedId": "1ck3k49",
    "url": "https://www.reddit.com/r/LangChain/comments/1ck3k49/what_are_some_ways_to_test_and_improve_my_rags/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "What are some ways to test and improve my RAGs retrieval strategy?",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "Looking for some tried and tested ways to measure and improve my RAGs retrieval strategy.",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for some tried and tested ways to measure and improve my RAGs retrieval strategy.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1ck3k49/what_are_some_ways_to_test_and_improve_my_rags/",
    "numberOfComments": 2,
    "flair": null,
    "upVotes": 3,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-05-04T15:57:46.000Z",
    "scrapedAt": "2025-08-31T23:58:15.160Z",
    "dataType": "post"
  },
  {
    "id": "t3_1cijx8f",
    "parsedId": "1cijx8f",
    "url": "https://www.reddit.com/r/LangChain/comments/1cijx8f/what_vectordb_do_you_all_use/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "What vectorDB do you all use?",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "Looking for a vectorDB for a RAG that am building. Needs to ingest a lot of data and should be optimized for retrieval. What are my options ?",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for a vectorDB for a RAG that am building. Needs to ingest a lot of data and should be optimized for retrieval. What are my options ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1cijx8f/what_vectordb_do_you_all_use/",
    "numberOfComments": 67,
    "flair": "Question | Help",
    "upVotes": 9,
    "upVoteRatio": 0.74,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-05-02T16:24:21.000Z",
    "scrapedAt": "2025-08-31T23:58:15.192Z",
    "dataType": "post"
  },
  {
    "id": "t3_1cgbwzx",
    "parsedId": "1cgbwzx",
    "url": "https://www.reddit.com/r/LangChain/comments/1cgbwzx/langtrace_just_added_support_for_langgraph/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Langtrace - Just added support for Langgraph",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "Hey Everyone,\n\nI have been playing with Langgraph recently and it's awesome. There are some native ways to visualize the graph that you are building using Langgraph, which I ended up using multiple times as I was developing some agentic workflows. Its useful to see the graph as you are developing and debugging it. I kinda thought it would be nice to have Langtrace show the graph and decided to add support for it.\n\nWanted to show a quick preview of it. Excited for you all to try it out and leave your feedback.\n\nhttps://reddit.com/link/1cgbwzx/video/zbt44qozqhxc1/player",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Everyone,&lt;/p&gt;\n\n&lt;p&gt;I have been playing with Langgraph recently and it&amp;#39;s awesome. There are some native ways to visualize the graph that you are building using Langgraph, which I ended up using multiple times as I was developing some agentic workflows. Its useful to see the graph as you are developing and debugging it. I kinda thought it would be nice to have Langtrace show the graph and decided to add support for it.&lt;/p&gt;\n\n&lt;p&gt;Wanted to show a quick preview of it. Excited for you all to try it out and leave your feedback.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://reddit.com/link/1cgbwzx/video/zbt44qozqhxc1/player\"&gt;https://reddit.com/link/1cgbwzx/video/zbt44qozqhxc1/player&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1cgbwzx/langtrace_just_added_support_for_langgraph/",
    "numberOfComments": 5,
    "flair": null,
    "upVotes": 9,
    "upVoteRatio": 0.91,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-04-29T22:04:04.000Z",
    "scrapedAt": "2025-08-31T23:58:15.230Z",
    "dataType": "post"
  },
  {
    "id": "t3_1cg6roo",
    "parsedId": "1cg6roo",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1cg6roo/whats_the_difference_between_lmstudio_ollama_and/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Whats the difference between LMStudio, Ollama and Oobabooga?",
    "communityName": "r/LocalLLaMA",
    "parsedCommunityName": "LocalLLaMA",
    "body": "[removed]",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LocalLLaMA/comments/1cg6roo/whats_the_difference_between_lmstudio_ollama_and/",
    "numberOfComments": 0,
    "flair": "Discussion",
    "upVotes": 1,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "default",
    "imageUrls": [],
    "createdAt": "2024-04-29T18:40:15.000Z",
    "scrapedAt": "2025-08-31T23:58:15.282Z",
    "dataType": "post"
  },
  {
    "id": "t3_1c87gn2",
    "parsedId": "1c87gn2",
    "url": "https://www.reddit.com/r/LangChain/comments/1c87gn2/curated_list_of_open_source_tools_to_test_and/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Curated list of open source tools to test and improve the accuracy of your RAG/LLM based app",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "Hey everyone,\n\n  \nWhat are some of the tools you are using for testing and improving your applications? I have been curating/following a few of these. But, wanted to learn what your general experience has been? and what challenges you all are facing.\n\n- [https://github.com/explodinggradients/ragas](https://github.com/explodinggradients/ragas)  \n- [https://github.com/promptfoo/promptfoo](https://github.com/promptfoo/promptfoo)  \n- [https://github.com/braintrustdata/autoevals](https://github.com/braintrustdata/autoevals)  \n- [https://github.com/stanfordnlp/dspy](https://github.com/stanfordnlp/dspy)  \n- [https://github.com/jxnl/instructor/](https://github.com/jxnl/instructor/)  \n- [https://github.com/guidance-ai/guidance](https://github.com/guidance-ai/guidance)\n\nSeparately, I am also building one which is more focused towards tracing and evaluations  \n- [https://github.com/Scale3-Labs/langtrace](https://github.com/Scale3-Labs/langtrace)",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;What are some of the tools you are using for testing and improving your applications? I have been curating/following a few of these. But, wanted to learn what your general experience has been? and what challenges you all are facing.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/explodinggradients/ragas\"&gt;https://github.com/explodinggradients/ragas&lt;/a&gt;&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/promptfoo/promptfoo\"&gt;https://github.com/promptfoo/promptfoo&lt;/a&gt;&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/braintrustdata/autoevals\"&gt;https://github.com/braintrustdata/autoevals&lt;/a&gt;&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/stanfordnlp/dspy\"&gt;https://github.com/stanfordnlp/dspy&lt;/a&gt;&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/jxnl/instructor/\"&gt;https://github.com/jxnl/instructor/&lt;/a&gt;&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/guidance-ai/guidance\"&gt;https://github.com/guidance-ai/guidance&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Separately, I am also building one which is more focused towards tracing and evaluations&lt;br/&gt;\n- &lt;a href=\"https://github.com/Scale3-Labs/langtrace\"&gt;https://github.com/Scale3-Labs/langtrace&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1c87gn2/curated_list_of_open_source_tools_to_test_and/",
    "numberOfComments": 3,
    "flair": "Resources",
    "upVotes": 46,
    "upVoteRatio": 0.98,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [
      "https://external-i.redd.it/3zrOwYoJW0GmBCgIPaiUEpEpjC17NlzZcV40MjMFPek.jpg"
    ],
    "createdAt": "2024-04-19T20:46:30.000Z",
    "scrapedAt": "2025-08-31T23:58:15.322Z",
    "dataType": "post"
  },
  {
    "id": "t3_1c87h6c",
    "parsedId": "1c87h6c",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1c87h6c/curated_list_of_open_source_tools_to_test_and/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Curated list of open source tools to test and improve the accuracy of your RAG/LLM based app",
    "communityName": "r/LocalLLaMA",
    "parsedCommunityName": "LocalLLaMA",
    "body": "Hey everyone,\n\nWhat are some of the tools you are using for testing and improving your applications? I have been curating/following a few of these. But, wanted to learn what your general experience has been? and what challenges you all are facing.\n\n* [https://github.com/explodinggradients/ragas](https://github.com/explodinggradients/ragas)\n* [https://github.com/promptfoo/promptfoo](https://github.com/promptfoo/promptfoo)\n* [https://github.com/braintrustdata/autoevals](https://github.com/braintrustdata/autoevals)\n* [https://github.com/stanfordnlp/dspy](https://github.com/stanfordnlp/dspy)\n* [https://github.com/jxnl/instructor/](https://github.com/jxnl/instructor/)\n* [https://github.com/guidance-ai/guidance](https://github.com/guidance-ai/guidance)\n\nSeparately, I am also building one which is more focused towards tracing and evaluations\n\n* [https://github.com/Scale3-Labs/langtrace](https://github.com/Scale3-Labs/langtrace)",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;What are some of the tools you are using for testing and improving your applications? I have been curating/following a few of these. But, wanted to learn what your general experience has been? and what challenges you all are facing.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/explodinggradients/ragas\"&gt;https://github.com/explodinggradients/ragas&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/promptfoo/promptfoo\"&gt;https://github.com/promptfoo/promptfoo&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/braintrustdata/autoevals\"&gt;https://github.com/braintrustdata/autoevals&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/stanfordnlp/dspy\"&gt;https://github.com/stanfordnlp/dspy&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/jxnl/instructor/\"&gt;https://github.com/jxnl/instructor/&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/guidance-ai/guidance\"&gt;https://github.com/guidance-ai/guidance&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Separately, I am also building one which is more focused towards tracing and evaluations&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/Scale3-Labs/langtrace\"&gt;https://github.com/Scale3-Labs/langtrace&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LocalLLaMA/comments/1c87h6c/curated_list_of_open_source_tools_to_test_and/",
    "numberOfComments": 10,
    "flair": "Resources",
    "upVotes": 39,
    "upVoteRatio": 0.9,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [
      "https://external-i.redd.it/3zrOwYoJW0GmBCgIPaiUEpEpjC17NlzZcV40MjMFPek.jpg"
    ],
    "createdAt": "2024-04-19T20:47:07.000Z",
    "scrapedAt": "2025-08-31T23:58:15.351Z",
    "dataType": "post"
  },
  {
    "id": "t3_1c7zp7y",
    "parsedId": "1c7zp7y",
    "url": "https://www.reddit.com/r/LangChain/comments/1c7zp7y/langtrace_evaluations_breeze_through_with_hotkeys/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Langtrace Evaluations - Breeze through with hotkeys",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "\n\nhttps://reddit.com/link/1c7zp7y/video/v8ord1suegvc1/player\n\nWe have been busy shipping updates to **Langtrace**, an **Open Source LLM observability tool** and I am excited to show our new and improved Evaluations Dashboard. We learned from our early users that improving the RAG/model accuracy and gaining confidence with deploying their LLM based apps to production has been the number 1 priority.\n\nTo solve for this, we have built a couple of things:\n\n**1. Create tests with different scoring scales and automatically capture LLM requests to these tests using Langtrace's SDK.**\n\n**2. Evaluate the the requests by scoring against the response provided by the LLM to measure the overall average of each test.**\n\nEffectively, teams can come up with a release criteria like - \"Factual Accuracy &gt; 99%, Response Quality &gt; 95%, Response Bias &gt; 85%, Context Recall &gt; 90%\" and measure their product's performance against this release metric with Langtrace.\n\nAdditionally, we also realized that the user experience is extremely important for effective and fast evaluations. As a result, the evaluations flow is fully optimized for hot keys and as an evaluator, you can breeze through a series of evaluations with just the arrow keys, enter and backspace without having to click through a bunch of times for each request.\n\nFinally, all of this can be setup with just 2 lines of code and Langtrace's Evaluation's dashboard will start capturing the requests in the appropriate test automatically\n\nDon't forget to check out Langtrace and star the repository on Github.\n\nGithub - [https://github.com/Scale3-Labs/langtrace](https://github.com/Scale3-Labs/langtrace)",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://reddit.com/link/1c7zp7y/video/v8ord1suegvc1/player\"&gt;https://reddit.com/link/1c7zp7y/video/v8ord1suegvc1/player&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We have been busy shipping updates to &lt;strong&gt;Langtrace&lt;/strong&gt;, an &lt;strong&gt;Open Source LLM observability tool&lt;/strong&gt; and I am excited to show our new and improved Evaluations Dashboard. We learned from our early users that improving the RAG/model accuracy and gaining confidence with deploying their LLM based apps to production has been the number 1 priority.&lt;/p&gt;\n\n&lt;p&gt;To solve for this, we have built a couple of things:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;1. Create tests with different scoring scales and automatically capture LLM requests to these tests using Langtrace&amp;#39;s SDK.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;2. Evaluate the the requests by scoring against the response provided by the LLM to measure the overall average of each test.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Effectively, teams can come up with a release criteria like - &amp;quot;Factual Accuracy &amp;gt; 99%, Response Quality &amp;gt; 95%, Response Bias &amp;gt; 85%, Context Recall &amp;gt; 90%&amp;quot; and measure their product&amp;#39;s performance against this release metric with Langtrace.&lt;/p&gt;\n\n&lt;p&gt;Additionally, we also realized that the user experience is extremely important for effective and fast evaluations. As a result, the evaluations flow is fully optimized for hot keys and as an evaluator, you can breeze through a series of evaluations with just the arrow keys, enter and backspace without having to click through a bunch of times for each request.&lt;/p&gt;\n\n&lt;p&gt;Finally, all of this can be setup with just 2 lines of code and Langtrace&amp;#39;s Evaluation&amp;#39;s dashboard will start capturing the requests in the appropriate test automatically&lt;/p&gt;\n\n&lt;p&gt;Don&amp;#39;t forget to check out Langtrace and star the repository on Github.&lt;/p&gt;\n\n&lt;p&gt;Github - &lt;a href=\"https://github.com/Scale3-Labs/langtrace\"&gt;https://github.com/Scale3-Labs/langtrace&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1c7zp7y/langtrace_evaluations_breeze_through_with_hotkeys/",
    "numberOfComments": 13,
    "flair": null,
    "upVotes": 18,
    "upVoteRatio": 0.87,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "https://a.thumbs.redditmedia.com/hc_yQuKtjUvliPIZY0mcUlTOZCeLle9xgYUVBvbDsZ4.jpg",
    "imageUrls": [
      "https://external-i.redd.it/O9Z_56AIGA8RzHakPI49lAWCrCkAXsFQRc9Kf8-iHoQ.jpg"
    ],
    "createdAt": "2024-04-19T15:28:34.000Z",
    "scrapedAt": "2025-08-31T23:58:16.921Z",
    "dataType": "post"
  },
  {
    "id": "t3_1c82lvr",
    "parsedId": "1c82lvr",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1c82lvr/measuring_the_accuracy_of_your_llm_based/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Measuring the accuracy of your LLM based applications",
    "communityName": "r/LocalLLaMA",
    "parsedCommunityName": "LocalLLaMA",
    "body": "Hey,\n\n  \nI am building an open source tool to capture LLM requests from any product using OpenTelemetry traces. I built an evaluations dashboard for bucketing requests into individual tests and evaluate the responses using different scales, measure and come up with a release criteria.\n\nThis can be super helpful to gain confidence before releasing your application to production.  \n\nEffectively, you can come up with a release criteria like - \"Factual Accuracy &gt; 99%, Response Quality &gt; 95%, Response Bias &gt; 85%, Context Recall &gt; 90%\" and measure your product's performance against this release metric.\n\nLooking for feedback and also please star the github\n\nGithub - [https://github.com/Scale3-Labs/langtrace](https://github.com/Scale3-Labs/langtrace)\n\nhttps://reddit.com/link/1c82lvr/video/vkk75cpo0hvc1/player\n\n",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey,&lt;/p&gt;\n\n&lt;p&gt;I am building an open source tool to capture LLM requests from any product using OpenTelemetry traces. I built an evaluations dashboard for bucketing requests into individual tests and evaluate the responses using different scales, measure and come up with a release criteria.&lt;/p&gt;\n\n&lt;p&gt;This can be super helpful to gain confidence before releasing your application to production.  &lt;/p&gt;\n\n&lt;p&gt;Effectively, you can come up with a release criteria like - &amp;quot;Factual Accuracy &amp;gt; 99%, Response Quality &amp;gt; 95%, Response Bias &amp;gt; 85%, Context Recall &amp;gt; 90%&amp;quot; and measure your product&amp;#39;s performance against this release metric.&lt;/p&gt;\n\n&lt;p&gt;Looking for feedback and also please star the github&lt;/p&gt;\n\n&lt;p&gt;Github - &lt;a href=\"https://github.com/Scale3-Labs/langtrace\"&gt;https://github.com/Scale3-Labs/langtrace&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://reddit.com/link/1c82lvr/video/vkk75cpo0hvc1/player\"&gt;https://reddit.com/link/1c82lvr/video/vkk75cpo0hvc1/player&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LocalLLaMA/comments/1c82lvr/measuring_the_accuracy_of_your_llm_based/",
    "numberOfComments": 0,
    "flair": "Resources",
    "upVotes": 10,
    "upVoteRatio": 0.86,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "https://a.thumbs.redditmedia.com/hc_yQuKtjUvliPIZY0mcUlTOZCeLle9xgYUVBvbDsZ4.jpg",
    "imageUrls": [
      "https://external-i.redd.it/O9Z_56AIGA8RzHakPI49lAWCrCkAXsFQRc9Kf8-iHoQ.jpg"
    ],
    "createdAt": "2024-04-19T17:26:18.000Z",
    "scrapedAt": "2025-08-31T23:58:16.959Z",
    "dataType": "post"
  },
  {
    "id": "t3_1c0dr08",
    "parsedId": "1c0dr08",
    "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1c0dr08/results_of_evaluating_the_ai_oracle_approach_a/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Results of evaluating the AI Oracle approach - a novel way to improve your LLM application's accuracy",
    "communityName": "r/ChatGPTCoding",
    "parsedCommunityName": "ChatGPTCoding",
    "body": "Recently, I saw this tweet about the AI Oracle approach for improving the accuracy and quality of responses for your LLM application. The technique is super simple:\n\n[https://twitter.com/mattshumer\\_/status/1777382373283299365](https://twitter.com/mattshumer_/status/1777382373283299365)\n\n1. Send the request to 3 LLMs - Claude, GPT4, and Perplexity.\n2. Give the responses to Claude again and prompt engineer to pick the best and accurate response.\n\nI got curious about this and decided to do some evaluations on this approach. Sharing some metrics/measurements in this post.\n\nThis one is pretty obvious, the latency on having all 3 LLMs generate a response and picking the best out of the 3 is high. But, I do recognize that this can be improved by parallelizing the operations.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/b3a1xzi66ltc1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=7ec6d60be1554e04557d09cbd06d9161055dd39a\n\nRan the following tests for both the combined AI Oracle approach and using a single LLM:\n\n1. **Factual Accuracy** \\- Evaluated for correctness of responses.\n2. **Realtime data** \\- Evaluated based on asking information related to realtime data.\n3. **Adversarial Testing** \\- Evaluated on whether the LLM is able to pickup the signal correctly by placing the question in between a bunch of garbage data. The LLM was given a positive score if it correctly responded to the question without mentioning the garbage data.\n4. **Consistency checks** \\- Evaluated on whether the LLM gave a response consistently when the same question was asking many times. Mainly looked for structural consistency of the response.\n5. **Quality** \\- Evaluated on the quality - sentence structure, adherence to the prompt etc.\n\n**AI Oracle Approach**\n\nResults for the AI Oracle approach: For some reason, it could not pick up the realtime information even once. I am sure with some prompt engineering, this metric can be improved. It did poorly on Adversarial testing - mostly because Claude and Pplx's responses.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/5p45fib56ltc1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=81b5eebb49a578000ce4d5c51af2383b8f2d643e\n\n**Claude (claude-3-opus-20240229)**\n\nAs expected, Claude did not do well on Realtime testing. But, interestingly, it did not do great with adversarial and consistency tests either.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/2azy0zl76ltc1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=a0bae1cbaab344b6af92aa3bbafe9f79f08f05c8\n\n**GPT4**\n\nAgain, GPT4 does not have realtime capabilities. But it did extremely well on everything else except consistency checks where the responses were structured quite differently each time.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/vmid8op86ltc1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=68c97a683db2dd6e989b706323284d04a72bab92\n\n**Perplexity (pplx-70b-online)**\n\nAs expected Perplexity's realtime capabilities are unmatched. But, it did not do that well with adversarial and consistency tests which in turn skewed the metrics for AI Oracle approach as well.Notably, the quality of responses from Perplexity were far better than the rest.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/nqgl2fs96ltc1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=1cb9378dfec9a8408ff42b4837e071b9d1c2aaab\n\nIn conclusion, you can get a near perfect score for the AI Oracle approach with a bit of prompt engineering. But you definitely lose performance in the process. Even when parallelized, it is only as slow as the slowest LLM. Token usage/cost is also going to be higher.\n\nFinally, if you are curious, all these evaluations were done using Langtrace - an open source LLM monitoring and evaluations tool that I am currently developing.\n\nGithub: [https://github.com/Scale3-Labs/langtrace](https://github.com/Scale3-Labs/langtrace)",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recently, I saw this tweet about the AI Oracle approach for improving the accuracy and quality of responses for your LLM application. The technique is super simple:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://twitter.com/mattshumer_/status/1777382373283299365\"&gt;https://twitter.com/mattshumer_/status/1777382373283299365&lt;/a&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Send the request to 3 LLMs - Claude, GPT4, and Perplexity.&lt;/li&gt;\n&lt;li&gt;Give the responses to Claude again and prompt engineer to pick the best and accurate response.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I got curious about this and decided to do some evaluations on this approach. Sharing some metrics/measurements in this post.&lt;/p&gt;\n\n&lt;p&gt;This one is pretty obvious, the latency on having all 3 LLMs generate a response and picking the best out of the 3 is high. But, I do recognize that this can be improved by parallelizing the operations.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/b3a1xzi66ltc1.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7ec6d60be1554e04557d09cbd06d9161055dd39a\"&gt;https://preview.redd.it/b3a1xzi66ltc1.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7ec6d60be1554e04557d09cbd06d9161055dd39a&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Ran the following tests for both the combined AI Oracle approach and using a single LLM:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Factual Accuracy&lt;/strong&gt; - Evaluated for correctness of responses.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Realtime data&lt;/strong&gt; - Evaluated based on asking information related to realtime data.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Adversarial Testing&lt;/strong&gt; - Evaluated on whether the LLM is able to pickup the signal correctly by placing the question in between a bunch of garbage data. The LLM was given a positive score if it correctly responded to the question without mentioning the garbage data.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Consistency checks&lt;/strong&gt; - Evaluated on whether the LLM gave a response consistently when the same question was asking many times. Mainly looked for structural consistency of the response.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Quality&lt;/strong&gt; - Evaluated on the quality - sentence structure, adherence to the prompt etc.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;AI Oracle Approach&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Results for the AI Oracle approach: For some reason, it could not pick up the realtime information even once. I am sure with some prompt engineering, this metric can be improved. It did poorly on Adversarial testing - mostly because Claude and Pplx&amp;#39;s responses.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/5p45fib56ltc1.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=81b5eebb49a578000ce4d5c51af2383b8f2d643e\"&gt;https://preview.redd.it/5p45fib56ltc1.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=81b5eebb49a578000ce4d5c51af2383b8f2d643e&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Claude (claude-3-opus-20240229)&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;As expected, Claude did not do well on Realtime testing. But, interestingly, it did not do great with adversarial and consistency tests either.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/2azy0zl76ltc1.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a0bae1cbaab344b6af92aa3bbafe9f79f08f05c8\"&gt;https://preview.redd.it/2azy0zl76ltc1.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a0bae1cbaab344b6af92aa3bbafe9f79f08f05c8&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;GPT4&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Again, GPT4 does not have realtime capabilities. But it did extremely well on everything else except consistency checks where the responses were structured quite differently each time.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/vmid8op86ltc1.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=68c97a683db2dd6e989b706323284d04a72bab92\"&gt;https://preview.redd.it/vmid8op86ltc1.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=68c97a683db2dd6e989b706323284d04a72bab92&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Perplexity (pplx-70b-online)&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;As expected Perplexity&amp;#39;s realtime capabilities are unmatched. But, it did not do that well with adversarial and consistency tests which in turn skewed the metrics for AI Oracle approach as well.Notably, the quality of responses from Perplexity were far better than the rest.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/nqgl2fs96ltc1.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1cb9378dfec9a8408ff42b4837e071b9d1c2aaab\"&gt;https://preview.redd.it/nqgl2fs96ltc1.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1cb9378dfec9a8408ff42b4837e071b9d1c2aaab&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;In conclusion, you can get a near perfect score for the AI Oracle approach with a bit of prompt engineering. But you definitely lose performance in the process. Even when parallelized, it is only as slow as the slowest LLM. Token usage/cost is also going to be higher.&lt;/p&gt;\n\n&lt;p&gt;Finally, if you are curious, all these evaluations were done using Langtrace - an open source LLM monitoring and evaluations tool that I am currently developing.&lt;/p&gt;\n\n&lt;p&gt;Github: &lt;a href=\"https://github.com/Scale3-Labs/langtrace\"&gt;https://github.com/Scale3-Labs/langtrace&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/ChatGPTCoding/comments/1c0dr08/results_of_evaluating_the_ai_oracle_approach_a/",
    "numberOfComments": 0,
    "flair": "Resources And Tips",
    "upVotes": 17,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "https://a.thumbs.redditmedia.com/e5m-OqrCSGXUL-FYezJthwJ6MiqqrYu_96xVD9OGgj4.jpg",
    "imageUrls": [
      "https://i.redd.it/vmid8op86ltc1.png",
      "https://i.redd.it/b3a1xzi66ltc1.png",
      "https://i.redd.it/2azy0zl76ltc1.png",
      "https://i.redd.it/5p45fib56ltc1.png",
      "https://i.redd.it/nqgl2fs96ltc1.png"
    ],
    "createdAt": "2024-04-10T05:16:34.000Z",
    "scrapedAt": "2025-08-31T23:58:17.048Z",
    "dataType": "post"
  },
  {
    "id": "t3_1c0do04",
    "parsedId": "1c0do04",
    "url": "https://www.reddit.com/r/LangChain/comments/1c0do04/results_of_evaluating_the_ai_oracle_approach_a/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Results of evaluating the AI Oracle approach - a novel way to improve your LLM application's accuracy",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "Recently, I saw this tweet about the AI Oracle approach for improving the accuracy and quality of responses for your LLM application. The technique is super simple:\n\n[https://twitter.com/mattshumer\\_/status/1777382373283299365](https://twitter.com/mattshumer_/status/1777382373283299365)\n\n1. Send the request to 3 LLMs - Claude, GPT4, and Perplexity.\n2. Give the responses to Claude again and prompt engineer to pick the best and accurate response.  \n\nI got curious about this and decided to do some evaluations on this approach. Sharing some metrics/measurements in this post.\n\nThis one is pretty obvious, the latency on having all 3 LLMs generate a response and picking the best out of the 3 is high. But, I do recognize that this can be improved by parallelizing the operations. \n\nhttps://preview.redd.it/lndc3gwp3ltc1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=02ec4109e9a3211724686a40ecbb9110dc70033c\n\nRan the following tests for both the combined AI Oracle approach and using a single LLM:\n\n1. **Factual Accuracy** \\- Evaluated for correctness of responses.\n\n2. **Realtime data** \\- Evaluated based on asking information related to realtime data.\n\n3. **Adversarial Testing** \\- Evaluated on whether the LLM is able to pickup the signal correctly by placing the question in between a bunch of garbage data. The LLM was given a positive score if it correctly responded to the question without mentioning the garbage data. \n\n4. **Consistency checks** \\- Evaluated on whether the LLM gave a response consistently when the same question was asking many times. Mainly looked for structural consistency of the response.\n\n5. **Quality** \\- Evaluated on the quality - sentence structure, adherence to the prompt etc. \n\n**AI Oracle Approach**\n\nResults for the AI Oracle approach: For some reason, it could not pick up the realtime information even once. I am sure with some prompt engineering, this metric can be improved. It did poorly on Adversarial testing - mostly because Claude and Pplx's responses. \n\n&amp;#x200B;\n\nhttps://preview.redd.it/9ggjkthz3ltc1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=033d105e3793e68fb5b2bd9a134cbbefec423cc7\n\n**Claude (claude-3-opus-20240229)**\n\nAs expected, Claude did not do well on Realtime testing. But, interestingly, it did not do great with adversarial and consistency tests either.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/b33q8qz24ltc1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=ef154b780655bb520c406d1aa53c8b91fc2c8038\n\n**GPT4**\n\nAgain, GPT4 does not have realtime capabilities. But it did extremely well on everything else except consistency checks where the responses were structured quite differently each time.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/2jz4y6864ltc1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=a35bfe557f4164251c4900d4e2c62cf8a5c7b04d\n\n**Perplexity (pplx-70b-online)**\n\nAs expected Perplexity's realtime capabilities are unmatched. But, it did not do that well with adversarial and consistency tests which in turn skewed the metrics for AI Oracle approach as well.Notably, the quality of responses from Perplexity were far better than the rest.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/y0mqsr4b4ltc1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=3ba1acfd7159b8f0bd5164a0e99af7f8ab4f5071\n\nIn conclusion, you can get a near perfect score for the AI Oracle approach with a bit of prompt engineering. But you definitely lose performance in the process. Even when parallelized, it is only as slow as the slowest LLM. Token usage/cost is also going to be higher.\n\nFinally, if you are curious, all these evaluations were done using Langtrace - an open source LLM monitoring and evaluations tool that I am currently developing.\n\nGithub: https://github.com/Scale3-Labs/langtrace",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recently, I saw this tweet about the AI Oracle approach for improving the accuracy and quality of responses for your LLM application. The technique is super simple:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://twitter.com/mattshumer_/status/1777382373283299365\"&gt;https://twitter.com/mattshumer_/status/1777382373283299365&lt;/a&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Send the request to 3 LLMs - Claude, GPT4, and Perplexity.&lt;/li&gt;\n&lt;li&gt;Give the responses to Claude again and prompt engineer to pick the best and accurate response.&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I got curious about this and decided to do some evaluations on this approach. Sharing some metrics/measurements in this post.&lt;/p&gt;\n\n&lt;p&gt;This one is pretty obvious, the latency on having all 3 LLMs generate a response and picking the best out of the 3 is high. But, I do recognize that this can be improved by parallelizing the operations. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/lndc3gwp3ltc1.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=02ec4109e9a3211724686a40ecbb9110dc70033c\"&gt;https://preview.redd.it/lndc3gwp3ltc1.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=02ec4109e9a3211724686a40ecbb9110dc70033c&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Ran the following tests for both the combined AI Oracle approach and using a single LLM:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Factual Accuracy&lt;/strong&gt; - Evaluated for correctness of responses.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Realtime data&lt;/strong&gt; - Evaluated based on asking information related to realtime data.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Adversarial Testing&lt;/strong&gt; - Evaluated on whether the LLM is able to pickup the signal correctly by placing the question in between a bunch of garbage data. The LLM was given a positive score if it correctly responded to the question without mentioning the garbage data. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Consistency checks&lt;/strong&gt; - Evaluated on whether the LLM gave a response consistently when the same question was asking many times. Mainly looked for structural consistency of the response.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Quality&lt;/strong&gt; - Evaluated on the quality - sentence structure, adherence to the prompt etc. &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;AI Oracle Approach&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Results for the AI Oracle approach: For some reason, it could not pick up the realtime information even once. I am sure with some prompt engineering, this metric can be improved. It did poorly on Adversarial testing - mostly because Claude and Pplx&amp;#39;s responses. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/9ggjkthz3ltc1.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=033d105e3793e68fb5b2bd9a134cbbefec423cc7\"&gt;https://preview.redd.it/9ggjkthz3ltc1.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=033d105e3793e68fb5b2bd9a134cbbefec423cc7&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Claude (claude-3-opus-20240229)&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;As expected, Claude did not do well on Realtime testing. But, interestingly, it did not do great with adversarial and consistency tests either.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/b33q8qz24ltc1.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ef154b780655bb520c406d1aa53c8b91fc2c8038\"&gt;https://preview.redd.it/b33q8qz24ltc1.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ef154b780655bb520c406d1aa53c8b91fc2c8038&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;GPT4&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Again, GPT4 does not have realtime capabilities. But it did extremely well on everything else except consistency checks where the responses were structured quite differently each time.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/2jz4y6864ltc1.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a35bfe557f4164251c4900d4e2c62cf8a5c7b04d\"&gt;https://preview.redd.it/2jz4y6864ltc1.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a35bfe557f4164251c4900d4e2c62cf8a5c7b04d&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Perplexity (pplx-70b-online)&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;As expected Perplexity&amp;#39;s realtime capabilities are unmatched. But, it did not do that well with adversarial and consistency tests which in turn skewed the metrics for AI Oracle approach as well.Notably, the quality of responses from Perplexity were far better than the rest.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/y0mqsr4b4ltc1.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3ba1acfd7159b8f0bd5164a0e99af7f8ab4f5071\"&gt;https://preview.redd.it/y0mqsr4b4ltc1.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3ba1acfd7159b8f0bd5164a0e99af7f8ab4f5071&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;In conclusion, you can get a near perfect score for the AI Oracle approach with a bit of prompt engineering. But you definitely lose performance in the process. Even when parallelized, it is only as slow as the slowest LLM. Token usage/cost is also going to be higher.&lt;/p&gt;\n\n&lt;p&gt;Finally, if you are curious, all these evaluations were done using Langtrace - an open source LLM monitoring and evaluations tool that I am currently developing.&lt;/p&gt;\n\n&lt;p&gt;Github: &lt;a href=\"https://github.com/Scale3-Labs/langtrace\"&gt;https://github.com/Scale3-Labs/langtrace&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1c0do04/results_of_evaluating_the_ai_oracle_approach_a/",
    "numberOfComments": 2,
    "flair": null,
    "upVotes": 10,
    "upVoteRatio": 0.86,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "https://b.thumbs.redditmedia.com/GCdPwBj4teGkowjNA4iTF6pGHJldADy1b4cFZ_8gtFI.jpg",
    "imageUrls": [
      "https://i.redd.it/lndc3gwp3ltc1.png",
      "https://i.redd.it/b33q8qz24ltc1.png",
      "https://i.redd.it/9ggjkthz3ltc1.png",
      "https://i.redd.it/2jz4y6864ltc1.png",
      "https://i.redd.it/y0mqsr4b4ltc1.png"
    ],
    "createdAt": "2024-04-10T05:11:47.000Z",
    "scrapedAt": "2025-08-31T23:58:17.086Z",
    "dataType": "post"
  },
  {
    "id": "t3_1bzhp3l",
    "parsedId": "1bzhp3l",
    "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1bzhp3l/langtrace_ai_open_source_and_open_telemetry/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Langtrace AI: Open source and Open telemetry standard tracing and monitoring for your LLM stack. (https://github.com/Scale3-Labs/langtrace)",
    "communityName": "r/ChatGPTCoding",
    "parsedCommunityName": "ChatGPTCoding",
    "body": "Images:\n\thttps://external-preview.redd.it/M2IxbmViZWRkZHRjMeIvXM-BA2MztYjHO9by9QqSu-rkGqB2jDQgs42FhIM8.png?format=pjpg&amp;auto=webp&amp;s=7d2decd38b32530bbb749c749b5724ea00fa1b18\n",
    "html": "Images:\n\thttps://external-preview.redd.it/M2IxbmViZWRkZHRjMeIvXM-BA2MztYjHO9by9QqSu-rkGqB2jDQgs42FhIM8.png?format=pjpg&amp;auto=webp&amp;s=7d2decd38b32530bbb749c749b5724ea00fa1b18\n",
    "link": "https://v.redd.it/s3fzbbedddtc1",
    "numberOfComments": 1,
    "flair": "Project",
    "upVotes": 20,
    "upVoteRatio": 1,
    "isVideo": true,
    "isAd": false,
    "over18": false,
    "videoUrl": "https://v.redd.it/s3fzbbedddtc1/DASH_1080.mp4?source=fallback",
    "thumbnailUrl": "https://external-preview.redd.it/M2IxbmViZWRkZHRjMeIvXM-BA2MztYjHO9by9QqSu-rkGqB2jDQgs42FhIM8.png?width=140&amp;height=81&amp;crop=140:81,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=61e1afcaad03e656505e6f57c8e9bf7ab13abc90",
    "imageUrls": [
      "https://external-i.redd.it/M2IxbmViZWRkZHRjMeIvXM-BA2MztYjHO9by9QqSu-rkGqB2jDQgs42FhIM8.png"
    ],
    "createdAt": "2024-04-09T03:02:45.000Z",
    "scrapedAt": "2025-08-31T23:58:17.118Z",
    "dataType": "post"
  },
  {
    "id": "t3_1byrqps",
    "parsedId": "1byrqps",
    "url": "https://www.reddit.com/r/LangChain/comments/1byrqps/langtrace_preview_of_the_new_evaluation_dashboard/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Langtrace: Preview of the new Evaluation dashboard",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "Hey,\n\n  \nI am building an open source project called Langtrace which lets you monitor, debug and evaluate the LLM requests made by your application.\n\n  \n[https://github.com/Scale3-Labs/langtrace](https://github.com/Scale3-Labs/langtrace) . The integration is only 2 lines of code.\n\nCurrently building an Evaluations dashboard which is launching this week. It lets you do the following:\n\n1. Create tests - like factual accuracy, bias detection etc. \n\n2. Automatically capture the LLM calls to specific tests by passing a testId to the langtrace SDK installed in your code.\n\n3. Evaluate and measure the overall success % and how success % trends over time.\n\nThe goal here is to get confidence with the model or RAG before deploying it to production.\n\n  \nPlease check out the repository. Would love to hear your thoughts! Thanks!\n\nhttps://preview.redd.it/5bracw5ki7tc1.png?width=2932&amp;format=png&amp;auto=webp&amp;s=1fe6fac6661d9a5c0c7f701c44d50435f45c7d7f\n\n ",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey,&lt;/p&gt;\n\n&lt;p&gt;I am building an open source project called Langtrace which lets you monitor, debug and evaluate the LLM requests made by your application.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/Scale3-Labs/langtrace\"&gt;https://github.com/Scale3-Labs/langtrace&lt;/a&gt; . The integration is only 2 lines of code.&lt;/p&gt;\n\n&lt;p&gt;Currently building an Evaluations dashboard which is launching this week. It lets you do the following:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Create tests - like factual accuracy, bias detection etc. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Automatically capture the LLM calls to specific tests by passing a testId to the langtrace SDK installed in your code.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Evaluate and measure the overall success % and how success % trends over time.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The goal here is to get confidence with the model or RAG before deploying it to production.&lt;/p&gt;\n\n&lt;p&gt;Please check out the repository. Would love to hear your thoughts! Thanks!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/5bracw5ki7tc1.png?width=2932&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1fe6fac6661d9a5c0c7f701c44d50435f45c7d7f\"&gt;https://preview.redd.it/5bracw5ki7tc1.png?width=2932&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1fe6fac6661d9a5c0c7f701c44d50435f45c7d7f&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1byrqps/langtrace_preview_of_the_new_evaluation_dashboard/",
    "numberOfComments": 4,
    "flair": "Resources",
    "upVotes": 11,
    "upVoteRatio": 0.84,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "https://b.thumbs.redditmedia.com/H_jfqLPEk8ByN1erbQ6cXUuSJYPo3oo8GUF65hwf4Oc.jpg",
    "imageUrls": [
      "https://external-i.redd.it/Z86Ol2Jj2ayoGOd-Pfgkem_533RuJprm3gD5eJdyH8c.jpg",
      "https://i.redd.it/5bracw5ki7tc1.png"
    ],
    "createdAt": "2024-04-08T07:21:23.000Z",
    "scrapedAt": "2025-08-31T23:58:17.181Z",
    "dataType": "post"
  },
  {
    "id": "t3_1bwm2tj",
    "parsedId": "1bwm2tj",
    "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1bwm2tj/i_built_an_open_source_llm_monitoring_evaluation/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "I built an open source LLM monitoring &amp; evaluation tool. It helps with monitoring token usage and latency. You can also evaluate responses to measure accuracy and improve it. ",
    "communityName": "r/ChatGPTCoding",
    "parsedCommunityName": "ChatGPTCoding",
    "body": "Hey all,\n\nI built an open source tool called Langtrace.\n\n**Langtrace**  is an open source LLM monitoring tool for monitoring token usage, latency, accuracy and manage datasets/prompts . Langtrace is built with OTEL(open telemetry) support which means it can be integrated with just 2 lines of code.\n\nGithub link - [https://github.com/Scale3-Labs/langtrace](https://github.com/Scale3-Labs/langtrace)\n\nPlease check it out and leave any feedback. Thanks",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I built an open source tool called Langtrace.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Langtrace&lt;/strong&gt;  is an open source LLM monitoring tool for monitoring token usage, latency, accuracy and manage datasets/prompts . Langtrace is built with OTEL(open telemetry) support which means it can be integrated with just 2 lines of code.&lt;/p&gt;\n\n&lt;p&gt;Github link - &lt;a href=\"https://github.com/Scale3-Labs/langtrace\"&gt;https://github.com/Scale3-Labs/langtrace&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Please check it out and leave any feedback. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/ChatGPTCoding/comments/1bwm2tj/i_built_an_open_source_llm_monitoring_evaluation/",
    "numberOfComments": 2,
    "flair": "Project",
    "upVotes": 11,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [
      "https://external-i.redd.it/AitlSNiYw0R0OJ-yvqytO4Kp4v2Xicv_HYJqhr2rGSQ.jpg"
    ],
    "createdAt": "2024-04-05T16:16:28.000Z",
    "scrapedAt": "2025-08-31T23:58:17.247Z",
    "dataType": "post"
  },
  {
    "id": "t3_1bv4nzb",
    "parsedId": "1bv4nzb",
    "url": "https://www.reddit.com/r/LangChain/comments/1bv4nzb/update_langtrace_launch_opensource_llm_monitoring/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Update: Langtrace Launch: Opensource LLM monitoring tool - achieving better cardinality compared to Langsmith.",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "This is a follow up for: [https://www.reddit.com/r/LangChain/comments/1bnkvtv/update\\_langtrace\\_preview\\_opensource\\_llm/](https://www.reddit.com/r/LangChain/comments/1bnkvtv/update_langtrace_preview_opensource_llm/)  \n\n\nI am happy to finally launch **Langtrace - an open source observability tool that collects and analyze traces in order to help you improve your LLM apps**. Langtrace has two components:\n\n* **SDK**: The SDK is a lightweight library that you can install and import into your project to collect traces.\n* **Langtrace Dashboard**: The dashboard is a web-based interface where you can view and analyze your traces.\n\nAttaching a couple of GIFs for your preview.\n\nFor context, we started this project internally a while back to solve our own problems. We are currently looking for feedback on how to improve this product and looking to boot strap a community around it.  You can join our discord community using this link - [https://discord.com/invite/EaSATwtr4t](https://discord.com/invite/EaSATwtr4t) \n\nThere are a couple of ways to use this product:\n\n1. You can sign up using this link - [https://langtrace.ai/](https://langtrace.ai/) to the hosted version, generate an API key, install and initialize the SDK in your application with the API key to start sending traces.\n   1. **The SDK installation and initialization is just 2 lines of code.**\n2. You can self host and use it within your own environment.\n\nYou can find more details in our docs - [https://docs.langtrace.ai/introduction](https://docs.langtrace.ai/introduction)\n\n**Open Source and Open Telemetry**\n\nEntire code including the SDK and the web application is open source. You can check it out from here - [https://github.com/Scale3-Labs/langtrace](https://github.com/Scale3-Labs/langtrace) .\n\nThe spans generated by our SDKs adhere to **open telemetry standards (OTEL)** which means, you can continue to use your existing observability backend and consume these traces by installing our SDKs.\n\n**Vendors supported**\n\nWe support OpenAI, Anthropic, Langchain, LlamaIndex, ChromaDB, PineconeDB. We will continue to add more in the coming weeks.\n\n**Pricing (for the hosted version)**\n\nIt's completely free to use at the moment. Since this is the first version, it is still rough around the edges and we are looking for feedback from the community to continue to improve and nail the experience. However, we may start to monetize the hosted version at some point at a reasonable cost. But, you can continue to use our open source version, self host and use it for free.\n\nFor more details, please do check out our launch blog post - [https://langtrace.ai/blog/introducing-langtrace](https://langtrace.ai/blog/introducing-langtrace)\n\n&amp;#x200B;\n\nThank you all for continuing to engage with me over the past few weeks. It has been super fun building this project and we look forward to hearing all your feedback on our Discord.\n\n&amp;#x200B;\n\nhttps://i.redd.it/t29eh8rnxbsc1.gif\n\nhttps://i.redd.it/k4ns4arnxbsc1.gif",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a follow up for: &lt;a href=\"https://www.reddit.com/r/LangChain/comments/1bnkvtv/update_langtrace_preview_opensource_llm/\"&gt;https://www.reddit.com/r/LangChain/comments/1bnkvtv/update_langtrace_preview_opensource_llm/&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;I am happy to finally launch &lt;strong&gt;Langtrace - an open source observability tool that collects and analyze traces in order to help you improve your LLM apps&lt;/strong&gt;. Langtrace has two components:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;SDK&lt;/strong&gt;: The SDK is a lightweight library that you can install and import into your project to collect traces.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Langtrace Dashboard&lt;/strong&gt;: The dashboard is a web-based interface where you can view and analyze your traces.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Attaching a couple of GIFs for your preview.&lt;/p&gt;\n\n&lt;p&gt;For context, we started this project internally a while back to solve our own problems. We are currently looking for feedback on how to improve this product and looking to boot strap a community around it.  You can join our discord community using this link - &lt;a href=\"https://discord.com/invite/EaSATwtr4t\"&gt;https://discord.com/invite/EaSATwtr4t&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;There are a couple of ways to use this product:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;You can sign up using this link - &lt;a href=\"https://langtrace.ai/\"&gt;https://langtrace.ai/&lt;/a&gt; to the hosted version, generate an API key, install and initialize the SDK in your application with the API key to start sending traces.\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;The SDK installation and initialization is just 2 lines of code.&lt;/strong&gt;&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;You can self host and use it within your own environment.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;You can find more details in our docs - &lt;a href=\"https://docs.langtrace.ai/introduction\"&gt;https://docs.langtrace.ai/introduction&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Open Source and Open Telemetry&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Entire code including the SDK and the web application is open source. You can check it out from here - &lt;a href=\"https://github.com/Scale3-Labs/langtrace\"&gt;https://github.com/Scale3-Labs/langtrace&lt;/a&gt; .&lt;/p&gt;\n\n&lt;p&gt;The spans generated by our SDKs adhere to &lt;strong&gt;open telemetry standards (OTEL)&lt;/strong&gt; which means, you can continue to use your existing observability backend and consume these traces by installing our SDKs.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Vendors supported&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;We support OpenAI, Anthropic, Langchain, LlamaIndex, ChromaDB, PineconeDB. We will continue to add more in the coming weeks.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Pricing (for the hosted version)&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s completely free to use at the moment. Since this is the first version, it is still rough around the edges and we are looking for feedback from the community to continue to improve and nail the experience. However, we may start to monetize the hosted version at some point at a reasonable cost. But, you can continue to use our open source version, self host and use it for free.&lt;/p&gt;\n\n&lt;p&gt;For more details, please do check out our launch blog post - &lt;a href=\"https://langtrace.ai/blog/introducing-langtrace\"&gt;https://langtrace.ai/blog/introducing-langtrace&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you all for continuing to engage with me over the past few weeks. It has been super fun building this project and we look forward to hearing all your feedback on our Discord.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.redd.it/t29eh8rnxbsc1.gif\"&gt;https://i.redd.it/t29eh8rnxbsc1.gif&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.redd.it/k4ns4arnxbsc1.gif\"&gt;https://i.redd.it/k4ns4arnxbsc1.gif&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1bv4nzb/update_langtrace_launch_opensource_llm_monitoring/",
    "numberOfComments": 9,
    "flair": null,
    "upVotes": 28,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "https://a.thumbs.redditmedia.com/YiEW2V1SquZh7v1QB18kA-ptGQZiLOsjSUgzLYy4Xu8.jpg",
    "imageUrls": [],
    "createdAt": "2024-04-03T21:20:19.000Z",
    "scrapedAt": "2025-08-31T23:58:17.275Z",
    "dataType": "post"
  },
  {
    "id": "t3_1bv7sav",
    "parsedId": "1bv7sav",
    "url": "https://www.reddit.com/r/InternetIsBeautiful/comments/1bv7sav/i_built_an_open_source_tool_to_monitor_llm_api/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "I built an open source tool to monitor LLM API costs, identify bottlenecks in RAG pipelines and evaluate &amp; measure LLM accuracy with just 2 lines of code.",
    "communityName": "r/InternetIsBeautiful",
    "parsedCommunityName": "InternetIsBeautiful",
    "body": "Thumbnail: default\n",
    "html": "Thumbnail: default\n",
    "link": "https://langtrace.ai/",
    "numberOfComments": 0,
    "flair": null,
    "upVotes": 10,
    "upVoteRatio": 0.6,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "default",
    "imageUrls": [],
    "createdAt": "2024-04-03T23:24:57.000Z",
    "scrapedAt": "2025-08-31T23:58:17.340Z",
    "dataType": "post"
  },
  {
    "id": "t3_1bv7ulu",
    "parsedId": "1bv7ulu",
    "url": "https://www.reddit.com/r/indiehackers/comments/1bv7ulu/opensource_llm_monitoring_tool_measure_token/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Opensource LLM monitoring tool - Measure token usage, cost, latency and accuracy with 2 lines of code",
    "communityName": "r/indiehackers",
    "parsedCommunityName": "indiehackers",
    "body": "I am happy to launch **Langtrace - an open source observability tool that collects and analyze traces in order to help you improve your LLM apps**. Langtrace has two components:\n\n* **SDK**: The SDK is a lightweight library that you can install and import into your project to collect traces.\n* **Langtrace Dashboard**: The dashboard is a web-based interface where you can view and analyze your traces.\n\nAttaching a couple of GIFs for your preview.\n\nFor context, we started this project internally a while back to solve our own problems. We are currently looking for feedback on how to improve this product and looking to boot strap a community around it. You can join our discord community using this link - [https://discord.com/invite/EaSATwtr4t](https://discord.com/invite/EaSATwtr4t)\n\nThere are a couple of ways to use this product:\n\n1. You can sign up using this link - [https://langtrace.ai/](https://langtrace.ai/) to the hosted version, generate an API key, install and initialize the SDK in your application with the API key to start sending traces.  \n\n   1. **The SDK installation and initialization is just 2 lines of code.**\n2. You can self host and use it within your own environment.\n\nYou can find more details in our docs - [https://docs.langtrace.ai/introduction](https://docs.langtrace.ai/introduction)\n\n**Open Source and Open Telemetry**\n\nEntire code including the SDK and the web application is open source. You can check it out from here - [https://github.com/Scale3-Labs/langtrace](https://github.com/Scale3-Labs/langtrace) .\n\nThe spans generated by our SDKs adhere to **open telemetry standards (OTEL)** which means, you can continue to use your existing observability backend and consume these traces by installing our SDKs.\n\n**Vendors supported**\n\nWe support OpenAI, Anthropic, Langchain, LlamaIndex, ChromaDB, PineconeDB. We will continue to add more in the coming weeks.\n\n**Pricing (for the hosted version)**\n\nIt's completely free to use at the moment. Since this is the first version, it is still rough around the edges and we are looking for feedback from the community to continue to improve and nail the experience. However, we may start to monetize the hosted version at some point at a reasonable cost. But, you can continue to use our open source version, self host and use it for free.\n\nFor more details, please do check out our launch blog post - [https://langtrace.ai/blog/introducing-langtrace](https://langtrace.ai/blog/introducing-langtrace)\n\nThank you all for continuing to engage with me over the past few weeks. It has been super fun building this project and we look forward to hearing all your feedback on our Discord.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nhttps://i.redd.it/iiotmt4lmcsc1.gif\n\nhttps://i.redd.it/yx8hix4lmcsc1.gif",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am happy to launch &lt;strong&gt;Langtrace - an open source observability tool that collects and analyze traces in order to help you improve your LLM apps&lt;/strong&gt;. Langtrace has two components:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;SDK&lt;/strong&gt;: The SDK is a lightweight library that you can install and import into your project to collect traces.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Langtrace Dashboard&lt;/strong&gt;: The dashboard is a web-based interface where you can view and analyze your traces.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Attaching a couple of GIFs for your preview.&lt;/p&gt;\n\n&lt;p&gt;For context, we started this project internally a while back to solve our own problems. We are currently looking for feedback on how to improve this product and looking to boot strap a community around it. You can join our discord community using this link - &lt;a href=\"https://discord.com/invite/EaSATwtr4t\"&gt;https://discord.com/invite/EaSATwtr4t&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;There are a couple of ways to use this product:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;You can sign up using this link - &lt;a href=\"https://langtrace.ai/\"&gt;https://langtrace.ai/&lt;/a&gt; to the hosted version, generate an API key, install and initialize the SDK in your application with the API key to start sending traces.  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;The SDK installation and initialization is just 2 lines of code.&lt;/strong&gt;&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;You can self host and use it within your own environment.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;You can find more details in our docs - &lt;a href=\"https://docs.langtrace.ai/introduction\"&gt;https://docs.langtrace.ai/introduction&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Open Source and Open Telemetry&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Entire code including the SDK and the web application is open source. You can check it out from here - &lt;a href=\"https://github.com/Scale3-Labs/langtrace\"&gt;https://github.com/Scale3-Labs/langtrace&lt;/a&gt; .&lt;/p&gt;\n\n&lt;p&gt;The spans generated by our SDKs adhere to &lt;strong&gt;open telemetry standards (OTEL)&lt;/strong&gt; which means, you can continue to use your existing observability backend and consume these traces by installing our SDKs.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Vendors supported&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;We support OpenAI, Anthropic, Langchain, LlamaIndex, ChromaDB, PineconeDB. We will continue to add more in the coming weeks.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Pricing (for the hosted version)&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s completely free to use at the moment. Since this is the first version, it is still rough around the edges and we are looking for feedback from the community to continue to improve and nail the experience. However, we may start to monetize the hosted version at some point at a reasonable cost. But, you can continue to use our open source version, self host and use it for free.&lt;/p&gt;\n\n&lt;p&gt;For more details, please do check out our launch blog post - &lt;a href=\"https://langtrace.ai/blog/introducing-langtrace\"&gt;https://langtrace.ai/blog/introducing-langtrace&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thank you all for continuing to engage with me over the past few weeks. It has been super fun building this project and we look forward to hearing all your feedback on our Discord.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.redd.it/iiotmt4lmcsc1.gif\"&gt;https://i.redd.it/iiotmt4lmcsc1.gif&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.redd.it/yx8hix4lmcsc1.gif\"&gt;https://i.redd.it/yx8hix4lmcsc1.gif&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/indiehackers/comments/1bv7ulu/opensource_llm_monitoring_tool_measure_token/",
    "numberOfComments": 0,
    "flair": null,
    "upVotes": 5,
    "upVoteRatio": 0.86,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "https://b.thumbs.redditmedia.com/kAzTwnBbC64dzrQUVG0qQ4Vyknj51dPw5BfiLAy973Q.jpg",
    "imageUrls": [],
    "createdAt": "2024-04-03T23:27:40.000Z",
    "scrapedAt": "2025-08-31T23:58:17.378Z",
    "dataType": "post"
  },
  {
    "id": "t3_1bv9bw1",
    "parsedId": "1bv9bw1",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bv9bw1/open_source_llm_monitoring_tool_that_collects_and/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Open source LLM monitoring tool that collects and analyze traces in order to help you improve your LLM apps.",
    "communityName": "r/LocalLLaMA",
    "parsedCommunityName": "LocalLLaMA",
    "body": "[removed]",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LocalLLaMA/comments/1bv9bw1/open_source_llm_monitoring_tool_that_collects_and/",
    "numberOfComments": 0,
    "flair": "Resources",
    "upVotes": 2,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "default",
    "imageUrls": [],
    "createdAt": "2024-04-04T00:30:26.000Z",
    "scrapedAt": "2025-08-31T23:58:17.410Z",
    "dataType": "post"
  },
  {
    "id": "t3_1bq5gqn",
    "parsedId": "1bq5gqn",
    "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1bq5gqn/do_you_use_the_system_role_for_adding_prompts_or/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Do you use the \"system\" role for adding prompts or just append it to the \"user\" role?",
    "communityName": "r/ChatGPTCoding",
    "parsedCommunityName": "ChatGPTCoding",
    "body": "I am just trying to understand if any of you use the \"system\" role for adding prompts to programmatic invocations. I know this is the support by the books way to do it. But I have also attached the prompt directly to the \"user\" role with similar accuracy. Wondering what the best practice is.",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am just trying to understand if any of you use the &amp;quot;system&amp;quot; role for adding prompts to programmatic invocations. I know this is the support by the books way to do it. But I have also attached the prompt directly to the &amp;quot;user&amp;quot; role with similar accuracy. Wondering what the best practice is.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/ChatGPTCoding/comments/1bq5gqn/do_you_use_the_system_role_for_adding_prompts_or/",
    "numberOfComments": 5,
    "flair": "Question",
    "upVotes": 9,
    "upVoteRatio": 0.91,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-03-28T20:16:07.000Z",
    "scrapedAt": "2025-08-31T23:58:17.462Z",
    "dataType": "post"
  },
  {
    "id": "t3_1bq5g0u",
    "parsedId": "1bq5g0u",
    "url": "https://www.reddit.com/r/LangChain/comments/1bq5g0u/do_you_use_the_system_role_for_adding_prompts_or/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Do you use the \"system\" role for adding prompts or just append it to the \"user\" role?",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "I am just trying to understand if any of you use the \"system\" role for adding prompts to programmatic invocations. I know this is the support by the books way to do it. But I have also attached the prompt directly to the \"user\" role with similar accuracy. Wondering what the best practice is.",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am just trying to understand if any of you use the &amp;quot;system&amp;quot; role for adding prompts to programmatic invocations. I know this is the support by the books way to do it. But I have also attached the prompt directly to the &amp;quot;user&amp;quot; role with similar accuracy. Wondering what the best practice is.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1bq5g0u/do_you_use_the_system_role_for_adding_prompts_or/",
    "numberOfComments": 4,
    "flair": null,
    "upVotes": 4,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-03-28T20:15:18.000Z",
    "scrapedAt": "2025-08-31T23:58:17.495Z",
    "dataType": "post"
  },
  {
    "id": "t3_1bnkvtv",
    "parsedId": "1bnkvtv",
    "url": "https://www.reddit.com/r/LangChain/comments/1bnkvtv/update_langtrace_preview_opensource_llm/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Update: Langtrace Preview: Opensource LLM monitoring tool - achieving better cardinality compared to Langsmith.",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "This is a follow up for: [https://www.reddit.com/r/LangChain/comments/1b6phov/update\\_langtrace\\_preview\\_an\\_opensource\\_llm/](https://www.reddit.com/r/LangChain/comments/1b6phov/update_langtrace_preview_an_opensource_llm/)  \n\n\nThought of sharing what I am cooking. Basically, I am building a open source LLM monitoring and evaluation suite. It works like this:  \n1. Install the SDK with 2 lines of code (npm i or pip install)  \n2. The SDK will start shipping traces in Open telemetry standard format to the UI  \n3. See the metrics, traces and prompts in the UI(Attaching some screenshots below).  \n\n\nI am mostly optimizing the features for 3 main metrics  \n1. Usage - token/cost  \n2. Accuracy - Manually evaluate traced prompt-response pairs from the UI and see the accuracy score  \n3. Latency - speed of responses/time to first token  \n\n\nVendors supported for the first version:  \nLangchain, LlamaIndex, OpenAI, Anthropic, Pinecone, ChromaDB  \n\n\nI will opensource this project in about a week and share the repo here.\n\nPlease let me know what else you would like to see or what other challenges you face that can be solved through this project.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/zwz0lqcfwiqc1.png?width=2978&amp;format=png&amp;auto=webp&amp;s=90caa5f52e47503493e4417b6808d7f12739f2d3\n\nhttps://preview.redd.it/cvv6aqcfwiqc1.png?width=3000&amp;format=png&amp;auto=webp&amp;s=e8374335d6e5b5a7ff04f1ea1408f74f9dce1698\n\n ",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a follow up for: &lt;a href=\"https://www.reddit.com/r/LangChain/comments/1b6phov/update_langtrace_preview_an_opensource_llm/\"&gt;https://www.reddit.com/r/LangChain/comments/1b6phov/update_langtrace_preview_an_opensource_llm/&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;Thought of sharing what I am cooking. Basically, I am building a open source LLM monitoring and evaluation suite. It works like this:&lt;br/&gt;\n1. Install the SDK with 2 lines of code (npm i or pip install)&lt;br/&gt;\n2. The SDK will start shipping traces in Open telemetry standard format to the UI&lt;br/&gt;\n3. See the metrics, traces and prompts in the UI(Attaching some screenshots below).  &lt;/p&gt;\n\n&lt;p&gt;I am mostly optimizing the features for 3 main metrics&lt;br/&gt;\n1. Usage - token/cost&lt;br/&gt;\n2. Accuracy - Manually evaluate traced prompt-response pairs from the UI and see the accuracy score&lt;br/&gt;\n3. Latency - speed of responses/time to first token  &lt;/p&gt;\n\n&lt;p&gt;Vendors supported for the first version:&lt;br/&gt;\nLangchain, LlamaIndex, OpenAI, Anthropic, Pinecone, ChromaDB  &lt;/p&gt;\n\n&lt;p&gt;I will opensource this project in about a week and share the repo here.&lt;/p&gt;\n\n&lt;p&gt;Please let me know what else you would like to see or what other challenges you face that can be solved through this project.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/zwz0lqcfwiqc1.png?width=2978&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=90caa5f52e47503493e4417b6808d7f12739f2d3\"&gt;https://preview.redd.it/zwz0lqcfwiqc1.png?width=2978&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=90caa5f52e47503493e4417b6808d7f12739f2d3&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/cvv6aqcfwiqc1.png?width=3000&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e8374335d6e5b5a7ff04f1ea1408f74f9dce1698\"&gt;https://preview.redd.it/cvv6aqcfwiqc1.png?width=3000&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e8374335d6e5b5a7ff04f1ea1408f74f9dce1698&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1bnkvtv/update_langtrace_preview_opensource_llm/",
    "numberOfComments": 32,
    "flair": "Resources",
    "upVotes": 31,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "https://b.thumbs.redditmedia.com/hCblHithvJSr2WsruX__shRW1xQxHRLpBDMO1YrayfM.jpg",
    "imageUrls": [
      "https://i.redd.it/zwz0lqcfwiqc1.png",
      "https://i.redd.it/cvv6aqcfwiqc1.png"
    ],
    "createdAt": "2024-03-25T18:25:33.000Z",
    "scrapedAt": "2025-08-31T23:58:17.525Z",
    "dataType": "post"
  },
  {
    "id": "t3_1bklgf7",
    "parsedId": "1bklgf7",
    "url": "https://www.reddit.com/r/LangChain/comments/1bklgf7/daily_struggles_with_my_llm_based_chatbot_in/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Daily struggles with my LLM based chatbot in production",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "What are some challenges you face after deploying your LLM based application in production? \n\nMy only goal is to improve the accuracy of my chatbot. It seems like everything boils down to this unless there are any other special usecases you are using the LLMs for. Basically. I try to monitor for all the responses of my chatbot and measure them objectively so I can tweak and improve the accuracy. This seems pretty basic. But, what are some of the other levers that I can pull to improve the accuracy of my RAG based chat application?\n\n&amp;#x200B;\n\nI am also building a tooling for tracing and monitoring the responses with higher cardinality compared to the ones that are in the market. Plan to open source it pretty soon.",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are some challenges you face after deploying your LLM based application in production? &lt;/p&gt;\n\n&lt;p&gt;My only goal is to improve the accuracy of my chatbot. It seems like everything boils down to this unless there are any other special usecases you are using the LLMs for. Basically. I try to monitor for all the responses of my chatbot and measure them objectively so I can tweak and improve the accuracy. This seems pretty basic. But, what are some of the other levers that I can pull to improve the accuracy of my RAG based chat application?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I am also building a tooling for tracing and monitoring the responses with higher cardinality compared to the ones that are in the market. Plan to open source it pretty soon.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1bklgf7/daily_struggles_with_my_llm_based_chatbot_in/",
    "numberOfComments": 15,
    "flair": null,
    "upVotes": 13,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-03-21T23:53:39.000Z",
    "scrapedAt": "2025-08-31T23:58:17.581Z",
    "dataType": "post"
  },
  {
    "id": "t3_1bh6o3e",
    "parsedId": "1bh6o3e",
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1bh6o3e/reverse_engineering_perplexity/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Reverse engineering Perplexity",
    "communityName": "r/LocalLLaMA",
    "parsedCommunityName": "LocalLLaMA",
    "body": "It seems like perplexity basically summarizes the content from the top 5-10 results of google search. If you don’t believe me, search for the exact same thing on google and perplexity and compare the sources, they match 1:1. \n\nBased on this, it seems like perplexity probably runs google search for every search on a headless browser, extracts the content from the top 5-10 results, summarizes it using a LLM and presents the results to the user. What’s game changer is, all of this happens so quickly.\n",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It seems like perplexity basically summarizes the content from the top 5-10 results of google search. If you don’t believe me, search for the exact same thing on google and perplexity and compare the sources, they match 1:1. &lt;/p&gt;\n\n&lt;p&gt;Based on this, it seems like perplexity probably runs google search for every search on a headless browser, extracts the content from the top 5-10 results, summarizes it using a LLM and presents the results to the user. What’s game changer is, all of this happens so quickly.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://v.redd.it/q7wqsbbt7yoc1",
    "numberOfComments": 106,
    "flair": "Discussion",
    "upVotes": 126,
    "upVoteRatio": 0.9,
    "isVideo": true,
    "isAd": false,
    "over18": false,
    "videoUrl": "https://v.redd.it/q7wqsbbt7yoc1/DASH_720.mp4?source=fallback",
    "thumbnailUrl": "https://external-preview.redd.it/bXp3aHI4NnQ3eW9jMSko3KMVeTdNODXfhd9oQqoYzhe8m-mxlBg7qDr13yNj.png?width=140&amp;height=140&amp;crop=140:140,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=41e7faca77a07a3eeca57e27fc13eba810963c21",
    "imageUrls": [
      "https://external-i.redd.it/bXp3aHI4NnQ3eW9jMSko3KMVeTdNODXfhd9oQqoYzhe8m-mxlBg7qDr13yNj.png"
    ],
    "createdAt": "2024-03-17T19:47:32.000Z",
    "scrapedAt": "2025-08-31T23:58:17.637Z",
    "dataType": "post"
  },
  {
    "id": "t3_1be7v0m",
    "parsedId": "1be7v0m",
    "url": "https://www.reddit.com/r/ChatGPT/comments/1be7v0m/i_built_a_chatgpt_rapper/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "I built a ChatGPT Rapper",
    "communityName": "r/ChatGPT",
    "parsedCommunityName": "ChatGPT",
    "body": "Images:\n\thttps://preview.redd.it/4of2eie037oc1.png?auto=webp&amp;s=a11c7ab5d88dc3a8b3532546518b1ac2161c5436\n",
    "html": "Images:\n\thttps://preview.redd.it/4of2eie037oc1.png?auto=webp&amp;s=a11c7ab5d88dc3a8b3532546518b1ac2161c5436\n",
    "link": "https://i.redd.it/4of2eie037oc1.png",
    "numberOfComments": 2,
    "flair": "Funny ",
    "upVotes": 1,
    "upVoteRatio": 0.57,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "https://a.thumbs.redditmedia.com/HCXZBGm1el_L_H2GViBSt0lxkz1nflcq0sKvt2TVt58.jpg",
    "imageUrls": [
      "https://i.redd.it/4of2eie037oc1.png"
    ],
    "createdAt": "2024-03-14T00:32:48.000Z",
    "scrapedAt": "2025-08-31T23:58:17.669Z",
    "dataType": "post"
  },
  {
    "id": "t3_1b6phov",
    "parsedId": "1b6phov",
    "url": "https://www.reddit.com/r/LangChain/comments/1b6phov/update_langtrace_preview_an_opensource_llm/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Update: Langtrace Preview: An opensource LLM monitoring tool - achieving better cardinality compared to Langsmith.",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "This is with regards to: [https://www.reddit.com/r/LangChain/comments/1b4s7cw/building\\_a\\_open\\_source\\_llm\\_monitoring\\_software/](https://www.reddit.com/r/LangChain/comments/1b4s7cw/building_a_open_source_llm_monitoring_software/)  \n\n\nJust wanted to share an update on my open source LLM monitoring tool. I do not have a UI yet, so asked chatGPT to plot the spans of a trace I generated for a langchain example code that uses agents. Below is the screenshot of my tool's trace plotted:\n\nhttps://preview.redd.it/xvqgcukrgemc1.png?width=2980&amp;format=png&amp;auto=webp&amp;s=0eaa0d298e047457520359017123054f65570621\n\n  \nSame output from Langsmith:\n\nhttps://preview.redd.it/lulyrgh6gemc1.png?width=778&amp;format=png&amp;auto=webp&amp;s=db44f54bf8d561ed379a2ea3e1dfe2319ee9ab84\n\n&amp;#x200B;\n\nFeedback/comments/thoughts welcome",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is with regards to: &lt;a href=\"https://www.reddit.com/r/LangChain/comments/1b4s7cw/building_a_open_source_llm_monitoring_software/\"&gt;https://www.reddit.com/r/LangChain/comments/1b4s7cw/building_a_open_source_llm_monitoring_software/&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;Just wanted to share an update on my open source LLM monitoring tool. I do not have a UI yet, so asked chatGPT to plot the spans of a trace I generated for a langchain example code that uses agents. Below is the screenshot of my tool&amp;#39;s trace plotted:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/xvqgcukrgemc1.png?width=2980&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0eaa0d298e047457520359017123054f65570621\"&gt;https://preview.redd.it/xvqgcukrgemc1.png?width=2980&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0eaa0d298e047457520359017123054f65570621&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Same output from Langsmith:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/lulyrgh6gemc1.png?width=778&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=db44f54bf8d561ed379a2ea3e1dfe2319ee9ab84\"&gt;https://preview.redd.it/lulyrgh6gemc1.png?width=778&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=db44f54bf8d561ed379a2ea3e1dfe2319ee9ab84&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Feedback/comments/thoughts welcome&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1b6phov/update_langtrace_preview_an_opensource_llm/",
    "numberOfComments": 12,
    "flair": null,
    "upVotes": 29,
    "upVoteRatio": 0.97,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "https://b.thumbs.redditmedia.com/HaAPBqwuj0vi5UErvwiGWGYZarwWXASKraGcYhfRP1w.jpg",
    "imageUrls": [
      "https://i.redd.it/lulyrgh6gemc1.png",
      "https://i.redd.it/xvqgcukrgemc1.png"
    ],
    "createdAt": "2024-03-04T23:16:58.000Z",
    "scrapedAt": "2025-08-31T23:58:17.698Z",
    "dataType": "post"
  },
  {
    "id": "t3_1b64qb5",
    "parsedId": "1b64qb5",
    "url": "https://www.reddit.com/r/LangChain/comments/1b64qb5/frustrating_problems_with_langchainllms/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Frustrating problems with langchain/LLMs?",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "Starting a thread on the most frustrating problems you’re facing with the use of Langchain or LLMs in your projects",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Starting a thread on the most frustrating problems you’re facing with the use of Langchain or LLMs in your projects&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1b64qb5/frustrating_problems_with_langchainllms/",
    "numberOfComments": 1,
    "flair": "Discussion",
    "upVotes": 2,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-03-04T07:10:40.000Z",
    "scrapedAt": "2025-08-31T23:58:17.734Z",
    "dataType": "post"
  },
  {
    "id": "t3_1b4s7cw",
    "parsedId": "1b4s7cw",
    "url": "https://www.reddit.com/r/LangChain/comments/1b4s7cw/building_a_open_source_llm_monitoring_software/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Building a open source LLM monitoring software",
    "communityName": "r/LangChain",
    "parsedCommunityName": "LangChain",
    "body": "I am building an open source LLM monitoring software. I know there are bunch of other tools out there. But, what are some features you would like to see? I would like to solve for the ones that are not already solved by the other tools that exist today. ",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am building an open source LLM monitoring software. I know there are bunch of other tools out there. But, what are some features you would like to see? I would like to solve for the ones that are not already solved by the other tools that exist today. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/LangChain/comments/1b4s7cw/building_a_open_source_llm_monitoring_software/",
    "numberOfComments": 19,
    "flair": null,
    "upVotes": 12,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-03-02T16:29:54.000Z",
    "scrapedAt": "2025-08-31T23:58:17.764Z",
    "dataType": "post"
  },
  {
    "id": "t3_1b4zv17",
    "parsedId": "1b4zv17",
    "url": "https://www.reddit.com/r/OpenAI/comments/1b4zv17/building_an_open_source_llm_monitoring_software/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Building an open source LLM monitoring software",
    "communityName": "r/OpenAI",
    "parsedCommunityName": "OpenAI",
    "body": "I am building an open source LLM monitoring software. I know there are bunch of other tools out there. But, what are some features you would like to see? I would like to solve for the ones that are not already solved by the other tools that exist today.",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am building an open source LLM monitoring software. I know there are bunch of other tools out there. But, what are some features you would like to see? I would like to solve for the ones that are not already solved by the other tools that exist today.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/OpenAI/comments/1b4zv17/building_an_open_source_llm_monitoring_software/",
    "numberOfComments": 0,
    "flair": "Discussion",
    "upVotes": 4,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-03-02T21:53:21.000Z",
    "scrapedAt": "2025-08-31T23:58:17.806Z",
    "dataType": "post"
  },
  {
    "id": "t3_1b4zmuv",
    "parsedId": "1b4zmuv",
    "url": "https://www.reddit.com/r/SaaS/comments/1b4zmuv/building_an_open_source_llm_monitoring_software/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Building an open source LLM monitoring software",
    "communityName": "r/SaaS",
    "parsedCommunityName": "SaaS",
    "body": "I am building an open source LLM monitoring software. I know there are bunch of other tools out there. But, what are some features you would like to see? I would like to solve for the ones that are not already solved by the other tools that exist today.",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am building an open source LLM monitoring software. I know there are bunch of other tools out there. But, what are some features you would like to see? I would like to solve for the ones that are not already solved by the other tools that exist today.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/SaaS/comments/1b4zmuv/building_an_open_source_llm_monitoring_software/",
    "numberOfComments": 2,
    "flair": null,
    "upVotes": 1,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-03-02T21:43:42.000Z",
    "scrapedAt": "2025-08-31T23:58:17.860Z",
    "dataType": "post"
  },
  {
    "id": "t3_1azx5g1",
    "parsedId": "1azx5g1",
    "url": "https://www.reddit.com/r/SaaS/comments/1azx5g1/what_would_you_build_today_if_you_had_openai/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "What would you build today if you had OpenAI Sora’s APIs?",
    "communityName": "r/SaaS",
    "parsedCommunityName": "SaaS",
    "body": "Just wondering what are you all thinking of building if you had access to the generative video ai Sora’s APIs today.",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just wondering what are you all thinking of building if you had access to the generative video ai Sora’s APIs today.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/SaaS/comments/1azx5g1/what_would_you_build_today_if_you_had_openai/",
    "numberOfComments": 4,
    "flair": null,
    "upVotes": 1,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-02-25T19:54:55.000Z",
    "scrapedAt": "2025-08-31T23:58:17.906Z",
    "dataType": "post"
  },
  {
    "id": "t3_1azdbpp",
    "parsedId": "1azdbpp",
    "url": "https://www.reddit.com/r/AZURE/comments/1azdbpp/anyone_use_azure_openai_ai_search_to_chat_with/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Anyone use azure OpenAI + AI search to chat with documents?",
    "communityName": "r/AZURE",
    "parsedCommunityName": "AZURE",
    "body": "Anyone uses azure OpenAI studio? The developer experience sucks big time so I had to build a UI around it to make it cleaner. But the models are great and I can basically use chatgpt for free. Using it with AI search is a game changer. I can chat with documents for free. ",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone uses azure OpenAI studio? The developer experience sucks big time so I had to build a UI around it to make it cleaner. But the models are great and I can basically use chatgpt for free. Using it with AI search is a game changer. I can chat with documents for free. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/AZURE/comments/1azdbpp/anyone_use_azure_openai_ai_search_to_chat_with/",
    "numberOfComments": 9,
    "flair": "Discussion",
    "upVotes": 4,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-02-25T02:57:53.000Z",
    "scrapedAt": "2025-08-31T23:58:17.949Z",
    "dataType": "post"
  },
  {
    "id": "t3_1azd9nk",
    "parsedId": "1azd9nk",
    "url": "https://www.reddit.com/r/SaaS/comments/1azd9nk/crowdsourcing_problems_you_are_willing_to_pay_to/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Crowdsourcing problems you are willing to pay to solve",
    "communityName": "r/SaaS",
    "parsedCommunityName": "SaaS",
    "body": "Not Crowd souring ideas but crowd sourcing the problems you all face that you are willing to outsource to a solution that you will pay for. Go for it!\n",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not Crowd souring ideas but crowd sourcing the problems you all face that you are willing to outsource to a solution that you will pay for. Go for it!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/SaaS/comments/1azd9nk/crowdsourcing_problems_you_are_willing_to_pay_to/",
    "numberOfComments": 4,
    "flair": null,
    "upVotes": 2,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-02-25T02:54:54.000Z",
    "scrapedAt": "2025-08-31T23:58:18.005Z",
    "dataType": "post"
  },
  {
    "id": "t3_1ay52lj",
    "parsedId": "1ay52lj",
    "url": "https://www.reddit.com/r/SaaS/comments/1ay52lj/chatgpt_on_azure_and_azure_govcloud_without_data/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "ChatGPT on Azure and Azure GovCloud without data leaving your cloud",
    "communityName": "r/SaaS",
    "parsedCommunityName": "SaaS",
    "body": "https://www.fynetune.ai/  \n\n\nIf your organization runs Azure or Azure GovCloud and if you are looking to provide your employees/customers with access to the latest AI models like ChatGPT and Dall E, this software is for you.\n\nThis software can be fully deployed on your Azure cloud environment in less than 5minutes and it uses only the resources on your Azure environment. This way all your data stays within your cloud.\n\nIt also detects PII and logs all the request-response pairs so it can be fully audited for security and compliance. \n\nFeatures: \n\n1. Multi-project support - Separate projects for different teams/departments separated out by namespace but shares the resources to minimize cloud cost\n2. ChatGPT like experience per project with chat histories - Chat with documents by uploading documents to a project - Supports pdf, docx, txt, pptx, csv and markdown\n3. Developer portal with code snippets and API keys per project for building in-house applications using Fynetune and leveraging it's capabilities\n4. RBAC - Teams and multi user support - member and owner roles.\n5. Observability and Auditability\n\n* Track token usage - input and output\n* Track total cost\n* Track all the conversations\n* Automatic PII detection\n\nPlease let me know if you have any feedback. Thanks",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.fynetune.ai/\"&gt;https://www.fynetune.ai/&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;If your organization runs Azure or Azure GovCloud and if you are looking to provide your employees/customers with access to the latest AI models like ChatGPT and Dall E, this software is for you.&lt;/p&gt;\n\n&lt;p&gt;This software can be fully deployed on your Azure cloud environment in less than 5minutes and it uses only the resources on your Azure environment. This way all your data stays within your cloud.&lt;/p&gt;\n\n&lt;p&gt;It also detects PII and logs all the request-response pairs so it can be fully audited for security and compliance. &lt;/p&gt;\n\n&lt;p&gt;Features: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Multi-project support - Separate projects for different teams/departments separated out by namespace but shares the resources to minimize cloud cost&lt;/li&gt;\n&lt;li&gt;ChatGPT like experience per project with chat histories - Chat with documents by uploading documents to a project - Supports pdf, docx, txt, pptx, csv and markdown&lt;/li&gt;\n&lt;li&gt;Developer portal with code snippets and API keys per project for building in-house applications using Fynetune and leveraging it&amp;#39;s capabilities&lt;/li&gt;\n&lt;li&gt;RBAC - Teams and multi user support - member and owner roles.&lt;/li&gt;\n&lt;li&gt;Observability and Auditability&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Track token usage - input and output&lt;/li&gt;\n&lt;li&gt;Track total cost&lt;/li&gt;\n&lt;li&gt;Track all the conversations&lt;/li&gt;\n&lt;li&gt;Automatic PII detection&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Please let me know if you have any feedback. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/SaaS/comments/1ay52lj/chatgpt_on_azure_and_azure_govcloud_without_data/",
    "numberOfComments": 0,
    "flair": null,
    "upVotes": 3,
    "upVoteRatio": 0.8,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-02-23T16:41:39.000Z",
    "scrapedAt": "2025-08-31T23:58:19.417Z",
    "dataType": "post"
  },
  {
    "id": "t3_1ay6oh3",
    "parsedId": "1ay6oh3",
    "url": "https://www.reddit.com/r/AZURE/comments/1ay6oh3/deploy_chatgpt_for_your_teams_on_azure_using/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Deploy ChatGPT for your teams on Azure using Azure's services",
    "communityName": "r/AZURE",
    "parsedCommunityName": "AZURE",
    "body": "[removed]",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/AZURE/comments/1ay6oh3/deploy_chatgpt_for_your_teams_on_azure_using/",
    "numberOfComments": 0,
    "flair": "Discussion",
    "upVotes": 0,
    "upVoteRatio": 0.5,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "default",
    "imageUrls": [],
    "createdAt": "2024-02-23T17:43:18.000Z",
    "scrapedAt": "2025-08-31T23:58:19.522Z",
    "dataType": "post"
  },
  {
    "id": "t3_1ahoaqe",
    "parsedId": "1ahoaqe",
    "url": "https://www.reddit.com/r/SaaS/comments/1ahoaqe/i_never_really_understood_how_seo_experts/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "I never really understood how SEO experts guarantee backlinks",
    "communityName": "r/SaaS",
    "parsedCommunityName": "SaaS",
    "body": "Hey all, I never really understood what SEO experts mean when they say they can “increase backlinks” to my product.\n\nHow do they do it? Do they go and post the link on random websites or do they have blogs that have significant traffic where they create a post about the product? Or do they pay other bloggers to post about the product?\n\nGenuinely curious to understand how they do it",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, I never really understood what SEO experts mean when they say they can “increase backlinks” to my product.&lt;/p&gt;\n\n&lt;p&gt;How do they do it? Do they go and post the link on random websites or do they have blogs that have significant traffic where they create a post about the product? Or do they pay other bloggers to post about the product?&lt;/p&gt;\n\n&lt;p&gt;Genuinely curious to understand how they do it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/SaaS/comments/1ahoaqe/i_never_really_understood_how_seo_experts/",
    "numberOfComments": 10,
    "flair": null,
    "upVotes": 7,
    "upVoteRatio": 0.89,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-02-03T05:07:34.000Z",
    "scrapedAt": "2025-08-31T23:58:19.556Z",
    "dataType": "post"
  },
  {
    "id": "t3_1agfpmc",
    "parsedId": "1agfpmc",
    "url": "https://www.reddit.com/r/SaaS/comments/1agfpmc/whats_a_saas_that_people_are_paying_for_that_can/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "What’s a SaaS that people are paying for that can be done for free?",
    "communityName": "r/SaaS",
    "parsedCommunityName": "SaaS",
    "body": "Wondering what SaaS software can be got for free that people are unaware and paying tons of cash for?",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wondering what SaaS software can be got for free that people are unaware and paying tons of cash for?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/SaaS/comments/1agfpmc/whats_a_saas_that_people_are_paying_for_that_can/",
    "numberOfComments": 29,
    "flair": "B2B SaaS",
    "upVotes": 14,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-02-01T16:59:06.000Z",
    "scrapedAt": "2025-08-31T23:58:19.603Z",
    "dataType": "post"
  },
  {
    "id": "t3_1afp51j",
    "parsedId": "1afp51j",
    "url": "https://www.reddit.com/r/nextjs/comments/1afp51j/i_genuinely_dont_understand_the_issues_off_app/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "I genuinely don’t understand the issues off App Router",
    "communityName": "r/nextjs",
    "parsedCommunityName": "nextjs",
    "body": "I have seen so many devs complain about App Router and its issues. I have been using it for some of my projects and genuinely haven’t faced any issues. \n\nExplain to me like I am 5, what are some challenges you are facing? I am not doubting any of your concerns, I am just trying to learn here.",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have seen so many devs complain about App Router and its issues. I have been using it for some of my projects and genuinely haven’t faced any issues. &lt;/p&gt;\n\n&lt;p&gt;Explain to me like I am 5, what are some challenges you are facing? I am not doubting any of your concerns, I am just trying to learn here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/nextjs/comments/1afp51j/i_genuinely_dont_understand_the_issues_off_app/",
    "numberOfComments": 71,
    "flair": null,
    "upVotes": 88,
    "upVoteRatio": 0.91,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-01-31T18:43:14.000Z",
    "scrapedAt": "2025-08-31T23:58:19.638Z",
    "dataType": "post"
  },
  {
    "id": "t3_1afp2ks",
    "parsedId": "1afp2ks",
    "url": "https://www.reddit.com/r/SaaS/comments/1afp2ks/which_saas_trend_is_obvious_yet_nobody_is/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Which SaaS trend is obvious yet nobody is noticing it?",
    "communityName": "r/SaaS",
    "parsedCommunityName": "SaaS",
    "body": "What are some SaaS trends that are happening in plain sight but nobody is noticing them",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are some SaaS trends that are happening in plain sight but nobody is noticing them&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/SaaS/comments/1afp2ks/which_saas_trend_is_obvious_yet_nobody_is/",
    "numberOfComments": 33,
    "flair": null,
    "upVotes": 28,
    "upVoteRatio": 0.94,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-01-31T18:40:29.000Z",
    "scrapedAt": "2025-08-31T23:58:19.668Z",
    "dataType": "post"
  },
  {
    "id": "t3_1afp1lb",
    "parsedId": "1afp1lb",
    "url": "https://www.reddit.com/r/SaaS/comments/1afp1lb/most_loved_saas_software/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Most loved SaaS software",
    "communityName": "r/SaaS",
    "parsedCommunityName": "SaaS",
    "body": "Crowdsourcing call: What are some of your most loved SaaS software out there and why do you love it the most?",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Crowdsourcing call: What are some of your most loved SaaS software out there and why do you love it the most?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/SaaS/comments/1afp1lb/most_loved_saas_software/",
    "numberOfComments": 47,
    "flair": "B2B SaaS",
    "upVotes": 13,
    "upVoteRatio": 0.93,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-01-31T18:39:20.000Z",
    "scrapedAt": "2025-08-31T23:58:19.710Z",
    "dataType": "post"
  },
  {
    "id": "t3_1aezc9k",
    "parsedId": "1aezc9k",
    "url": "https://www.reddit.com/r/SideProject/comments/1aezc9k/48_hours_to_make_money_on_the_internet/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "48 hours to make money on the internet",
    "communityName": "r/SideProject",
    "parsedCommunityName": "SideProject",
    "body": "Got me thinking deeply. What’s your answer? What are some creative ways to make money on the internet in 48 hours or less.",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Got me thinking deeply. What’s your answer? What are some creative ways to make money on the internet in 48 hours or less.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://i.redd.it/v1iob6mv6nfc1.jpeg",
    "numberOfComments": 49,
    "flair": null,
    "upVotes": 124,
    "upVoteRatio": 0.94,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "https://a.thumbs.redditmedia.com/EvpxSQ7lezkVrUCc2iFe3xmI39ULnYQ-InAMPcJowj0.jpg",
    "imageUrls": [
      "https://i.redd.it/v1iob6mv6nfc1.jpeg"
    ],
    "createdAt": "2024-01-30T21:05:24.000Z",
    "scrapedAt": "2025-08-31T23:58:19.912Z",
    "dataType": "post"
  },
  {
    "id": "t3_1aer9um",
    "parsedId": "1aer9um",
    "url": "https://www.reddit.com/r/SaaS/comments/1aer9um/most_hated_saas_products/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Most hated SaaS products",
    "communityName": "r/SaaS",
    "parsedCommunityName": "SaaS",
    "body": "Crowdsourcing the most hated SaaS products of all time. Submit your favorites",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Crowdsourcing the most hated SaaS products of all time. Submit your favorites&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/SaaS/comments/1aer9um/most_hated_saas_products/",
    "numberOfComments": 141,
    "flair": null,
    "upVotes": 45,
    "upVoteRatio": 0.96,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-01-30T15:39:33.000Z",
    "scrapedAt": "2025-08-31T23:58:19.953Z",
    "dataType": "post"
  },
  {
    "id": "t3_1aeug6d",
    "parsedId": "1aeug6d",
    "url": "https://www.reddit.com/r/indiehackers/comments/1aeug6d/oss_saas_projects_replacing_bloated_expensive_non/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "OSS SaaS projects replacing bloated, expensive non OSS SaaS",
    "communityName": "r/indiehackers",
    "parsedCommunityName": "indiehackers",
    "body": "I have been noticing a new wave of open source saas projects that are replacing bloated and heavily priced non open source alternatives. And these are developed by 1-2 person devs in 2-3 weeks. Notable examples:\n\n- dub.sh\n- novel.sh\n- surge.sh\n- vantage.sh\n\nEtc. What do you all think about this strategy of finding an exiting bloated, expensive saas, building an open source alternative of it and selling a hosted/managed version to monetize it? Steven Tey seems to be doing this very effectively with dub.sh",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been noticing a new wave of open source saas projects that are replacing bloated and heavily priced non open source alternatives. And these are developed by 1-2 person devs in 2-3 weeks. Notable examples:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;dub.sh&lt;/li&gt;\n&lt;li&gt;novel.sh&lt;/li&gt;\n&lt;li&gt;surge.sh&lt;/li&gt;\n&lt;li&gt;vantage.sh&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Etc. What do you all think about this strategy of finding an exiting bloated, expensive saas, building an open source alternative of it and selling a hosted/managed version to monetize it? Steven Tey seems to be doing this very effectively with dub.sh&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/indiehackers/comments/1aeug6d/oss_saas_projects_replacing_bloated_expensive_non/",
    "numberOfComments": 18,
    "flair": null,
    "upVotes": 6,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-01-30T17:48:35.000Z",
    "scrapedAt": "2025-08-31T23:58:20.035Z",
    "dataType": "post"
  },
  {
    "id": "t3_1aezdaw",
    "parsedId": "1aezdaw",
    "url": "https://www.reddit.com/r/SaaS/comments/1aezdaw/48_hours_to_make_money_on_the_internet/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "48 hours to make money on the internet",
    "communityName": "r/SaaS",
    "parsedCommunityName": "SaaS",
    "body": "You have 48 hours to make money on the internet. How would you do it? Be precise. \n(Note: This was a tweet posted by Nikita Bier on X)",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;You have 48 hours to make money on the internet. How would you do it? Be precise. \n(Note: This was a tweet posted by Nikita Bier on X)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/SaaS/comments/1aezdaw/48_hours_to_make_money_on_the_internet/",
    "numberOfComments": 2,
    "flair": null,
    "upVotes": 0,
    "upVoteRatio": 0.5,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-01-30T21:06:40.000Z",
    "scrapedAt": "2025-08-31T23:58:20.071Z",
    "dataType": "post"
  },
  {
    "id": "t3_1aeigj4",
    "parsedId": "1aeigj4",
    "url": "https://www.reddit.com/r/SaaS/comments/1aeigj4/oss_saas_projects_replacing_bloated_expensive_non/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "OSS SaaS projects replacing bloated, expensive non OSS SaaS",
    "communityName": "r/SaaS",
    "parsedCommunityName": "SaaS",
    "body": "I have been noticing a new wave of open source saas projects that are replacing bloated and heavily priced non open source alternatives. And these are developed by 1-2 person devs in 2-3 weeks. Notable examples:\n\n- dub.sh\n- novel.sh\n- surge.sh\n- vantage.sh\n\nEtc. What do you all think about this strategy of finding an exiting bloated, expensive saas, building an open source alternative of it and selling a hosted/managed version to monetize it? Steven Tey seems to be doing this very effectively with dub.sh",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been noticing a new wave of open source saas projects that are replacing bloated and heavily priced non open source alternatives. And these are developed by 1-2 person devs in 2-3 weeks. Notable examples:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;dub.sh&lt;/li&gt;\n&lt;li&gt;novel.sh&lt;/li&gt;\n&lt;li&gt;surge.sh&lt;/li&gt;\n&lt;li&gt;vantage.sh&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Etc. What do you all think about this strategy of finding an exiting bloated, expensive saas, building an open source alternative of it and selling a hosted/managed version to monetize it? Steven Tey seems to be doing this very effectively with dub.sh&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/SaaS/comments/1aeigj4/oss_saas_projects_replacing_bloated_expensive_non/",
    "numberOfComments": 14,
    "flair": "B2B SaaS",
    "upVotes": 8,
    "upVoteRatio": 0.75,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-01-30T07:04:31.000Z",
    "scrapedAt": "2025-08-31T23:58:20.103Z",
    "dataType": "post"
  },
  {
    "id": "t3_1aev7ti",
    "parsedId": "1aev7ti",
    "url": "https://www.reddit.com/r/SaaS/comments/1aev7ti/saas_idea_validation_toolcourse/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "SaaS idea validation tool/course",
    "communityName": "r/SaaS",
    "parsedCommunityName": "SaaS",
    "body": "Are you interested in a SaaS idea validation tool?\n\nFor context, I have been validating SaaS ideas for the past 2-3 years with this simple technique that works really well:\n\n1. Do keyword research and buy a domain\n2. Put together a landing page that explains the product within 3-6 seconds\n3. Add a buy button that redirects to a waitlist link\n4. Market this on reddit and other places on the internet\n5. Run google ads for $50 and track conversions\n\nI am thinking about building this system into a SaaS software itself where you as a user can follow a bunch of steps and get a set of charts and metrics to know whether this idea is worth pursuing.\n\nI think this system can be useful for anyone thinking of a SaaS idea. Will you be interested in something like this? If yes, please DM me, I will share with you the details. ",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are you interested in a SaaS idea validation tool?&lt;/p&gt;\n\n&lt;p&gt;For context, I have been validating SaaS ideas for the past 2-3 years with this simple technique that works really well:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Do keyword research and buy a domain&lt;/li&gt;\n&lt;li&gt;Put together a landing page that explains the product within 3-6 seconds&lt;/li&gt;\n&lt;li&gt;Add a buy button that redirects to a waitlist link&lt;/li&gt;\n&lt;li&gt;Market this on reddit and other places on the internet&lt;/li&gt;\n&lt;li&gt;Run google ads for $50 and track conversions&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I am thinking about building this system into a SaaS software itself where you as a user can follow a bunch of steps and get a set of charts and metrics to know whether this idea is worth pursuing.&lt;/p&gt;\n\n&lt;p&gt;I think this system can be useful for anyone thinking of a SaaS idea. Will you be interested in something like this? If yes, please DM me, I will share with you the details. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/SaaS/comments/1aev7ti/saas_idea_validation_toolcourse/",
    "numberOfComments": 3,
    "flair": null,
    "upVotes": 1,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-01-30T18:19:29.000Z",
    "scrapedAt": "2025-08-31T23:58:20.133Z",
    "dataType": "post"
  },
  {
    "id": "t3_1aeu1y2",
    "parsedId": "1aeu1y2",
    "url": "https://www.reddit.com/r/SaaS/comments/1aeu1y2/build_a_new_skin_for_jira/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Build a new skin for JIRA?",
    "communityName": "r/SaaS",
    "parsedCommunityName": "SaaS",
    "body": "I keep hearing JIRA is the most hated software by many devs. I don’t know if the atlassian folks are hearing this or just choose to ignore it. But idly wondering if it makes sense to use JIRAs APIs to build a new skin for it and charge a fee on top of it. Not even sure if it’s doable. Or maybe manipulate the browser elements directly by building a browser plugin of sorts. \n\nAny thoughts?",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I keep hearing JIRA is the most hated software by many devs. I don’t know if the atlassian folks are hearing this or just choose to ignore it. But idly wondering if it makes sense to use JIRAs APIs to build a new skin for it and charge a fee on top of it. Not even sure if it’s doable. Or maybe manipulate the browser elements directly by building a browser plugin of sorts. &lt;/p&gt;\n\n&lt;p&gt;Any thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/SaaS/comments/1aeu1y2/build_a_new_skin_for_jira/",
    "numberOfComments": 0,
    "flair": null,
    "upVotes": 1,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2024-01-30T17:32:17.000Z",
    "scrapedAt": "2025-08-31T23:58:20.167Z",
    "dataType": "post"
  },
  {
    "id": "t3_1aclh1q",
    "parsedId": "1aclh1q",
    "url": "https://www.reddit.com/r/indiehackers/comments/1aclh1q/this_app_can_help_you_record_explainer_video/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "This app can help you record explainer video demos of your product using Al.",
    "communityName": "r/indiehackers",
    "parsedCommunityName": "indiehackers",
    "body": "So, I have been using a bunch of tools to record explainer video demos of the projects I work on.\nSome people asked me how I did this. I decided to build a product out of it by duct taping together all the products I use behind the scenes. I do think this could be useful for other builders out there with marketing and product launch.\nThis is still at a MVP stage but works decently well with some manual intervention from time to time.\nBut, please do check it out and let me know if you have any feedback. Thanks\n\nhttps://www.videodemoai.com/",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I have been using a bunch of tools to record explainer video demos of the projects I work on.\nSome people asked me how I did this. I decided to build a product out of it by duct taping together all the products I use behind the scenes. I do think this could be useful for other builders out there with marketing and product launch.\nThis is still at a MVP stage but works decently well with some manual intervention from time to time.\nBut, please do check it out and let me know if you have any feedback. Thanks&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.videodemoai.com/\"&gt;https://www.videodemoai.com/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/indiehackers/comments/1aclh1q/this_app_can_help_you_record_explainer_video/",
    "numberOfComments": 2,
    "flair": null,
    "upVotes": 1,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [
      "https://external-i.redd.it/n2pt3W8dFHGn8Om_xLw-F1P8Iy-2vh1HstP__jYFq84.jpg"
    ],
    "createdAt": "2024-01-27T21:26:44.000Z",
    "scrapedAt": "2025-08-31T23:58:20.196Z",
    "dataType": "post"
  },
  {
    "id": "t3_1ac5hvu",
    "parsedId": "1ac5hvu",
    "url": "https://www.reddit.com/r/SaaS/comments/1ac5hvu/this_app_can_help_you_record_explainer_video/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "This app can help you record explainer video demos of your product using AI.",
    "communityName": "r/SaaS",
    "parsedCommunityName": "SaaS",
    "body": "So, I have been using a bunch of tools to record explainer video demos of the projects I work on. Some people asked me how I did this. I decided to build a product out of it by duct taping together all the products I use behind the scenes. I do think this could be useful for other builders out there with marketing and product launch.\n\nThis is still at a MVP stage but works decently well with some manual intervention from time to time. But, please do check it out and let me know if you have any feedback. Thanks\n\n[https://www.videodemoai.com/](https://www.videodemoai.com/)\n\n&amp;#x200B;",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I have been using a bunch of tools to record explainer video demos of the projects I work on. Some people asked me how I did this. I decided to build a product out of it by duct taping together all the products I use behind the scenes. I do think this could be useful for other builders out there with marketing and product launch.&lt;/p&gt;\n\n&lt;p&gt;This is still at a MVP stage but works decently well with some manual intervention from time to time. But, please do check it out and let me know if you have any feedback. Thanks&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.videodemoai.com/\"&gt;https://www.videodemoai.com/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/SaaS/comments/1ac5hvu/this_app_can_help_you_record_explainer_video/",
    "numberOfComments": 0,
    "flair": null,
    "upVotes": 2,
    "upVoteRatio": 0.75,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [
      "https://external-i.redd.it/n2pt3W8dFHGn8Om_xLw-F1P8Iy-2vh1HstP__jYFq84.jpg"
    ],
    "createdAt": "2024-01-27T07:36:59.000Z",
    "scrapedAt": "2025-08-31T23:58:20.234Z",
    "dataType": "post"
  },
  {
    "id": "t3_1ac62in",
    "parsedId": "1ac62in",
    "url": "https://www.reddit.com/r/SideProject/comments/1ac62in/this_app_can_help_you_record_explainer_video/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "This app can help you record explainer video demos of your product using AI.",
    "communityName": "r/SideProject",
    "parsedCommunityName": "SideProject",
    "body": "So, I have been using a bunch of tools to record explainer video demos of the projects I work on. Some people asked me how I did this. I decided to build a product out of it by duct taping together all the products I use behind the scenes. I do think this could be useful for other builders out there with marketing and product launch.\n\nThis is still at a MVP stage but works decently well with some manual intervention from time to time. But, please do check it out and let me know if you have any feedback. Thanks\n\n[https://www.videodemoai.com/](https://www.videodemoai.com/)",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I have been using a bunch of tools to record explainer video demos of the projects I work on. Some people asked me how I did this. I decided to build a product out of it by duct taping together all the products I use behind the scenes. I do think this could be useful for other builders out there with marketing and product launch.&lt;/p&gt;\n\n&lt;p&gt;This is still at a MVP stage but works decently well with some manual intervention from time to time. But, please do check it out and let me know if you have any feedback. Thanks&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.videodemoai.com/\"&gt;https://www.videodemoai.com/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/SideProject/comments/1ac62in/this_app_can_help_you_record_explainer_video/",
    "numberOfComments": 2,
    "flair": null,
    "upVotes": 1,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [
      "https://external-i.redd.it/n2pt3W8dFHGn8Om_xLw-F1P8Iy-2vh1HstP__jYFq84.jpg"
    ],
    "createdAt": "2024-01-27T08:15:24.000Z",
    "scrapedAt": "2025-08-31T23:58:20.274Z",
    "dataType": "post"
  },
  {
    "id": "t3_1ac5cs9",
    "parsedId": "1ac5cs9",
    "url": "https://www.reddit.com/r/InternetIsBeautiful/comments/1ac5cs9/i_made_an_app_that_can_generate_professional/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "I made an app that can generate professional product explainer/demo videos with voiceover for software projects.",
    "communityName": "r/InternetIsBeautiful",
    "parsedCommunityName": "InternetIsBeautiful",
    "body": "Thumbnail: default\n",
    "html": "Thumbnail: default\n",
    "link": "https://www.videodemoai.com",
    "numberOfComments": 0,
    "flair": null,
    "upVotes": 1,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "default",
    "imageUrls": [],
    "createdAt": "2024-01-27T07:27:34.000Z",
    "scrapedAt": "2025-08-31T23:58:20.303Z",
    "dataType": "post"
  },
  {
    "id": "t3_1abbs07",
    "parsedId": "1abbs07",
    "url": "https://www.reddit.com/r/SaaS/comments/1abbs07/not_sure_how_to_market_this/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Not sure how to market this",
    "communityName": "r/SaaS",
    "parsedCommunityName": "SaaS",
    "body": "I have built a documentation software that is super easy to use for any public facing documentation from api docs to general instructional docs.\n\nHere's a link to it: https://a4doks.com\n\nI think this is super useful and it has native markdown support along with ability to style using custom components like cards, accordions and separators.\n\nProblem is, I am an engineer at heart and I have no idea how to market this. Where do I start? I know producthunt is one place where I can launch this.\n\nBut I wanna make sure I have a few users providing me valuable feedback so I can weed out all the bugs and improve it before I launch it on producthunt.",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have built a documentation software that is super easy to use for any public facing documentation from api docs to general instructional docs.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s a link to it: &lt;a href=\"https://a4doks.com\"&gt;https://a4doks.com&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I think this is super useful and it has native markdown support along with ability to style using custom components like cards, accordions and separators.&lt;/p&gt;\n\n&lt;p&gt;Problem is, I am an engineer at heart and I have no idea how to market this. Where do I start? I know producthunt is one place where I can launch this.&lt;/p&gt;\n\n&lt;p&gt;But I wanna make sure I have a few users providing me valuable feedback so I can weed out all the bugs and improve it before I launch it on producthunt.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/SaaS/comments/1abbs07/not_sure_how_to_market_this/",
    "numberOfComments": 4,
    "flair": "Build In Public",
    "upVotes": 1,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [
      "https://external-i.redd.it/RJrF592COLAkS5hES3UQSNvSrs_dT7Jq04NPGUizuEc.jpg"
    ],
    "createdAt": "2024-01-26T06:19:26.000Z",
    "scrapedAt": "2025-08-31T23:58:20.341Z",
    "dataType": "post"
  },
  {
    "id": "t3_1abatg8",
    "parsedId": "1abatg8",
    "url": "https://www.reddit.com/r/indiehackers/comments/1abatg8/not_sure_how_to_market_this/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Not sure how to market this",
    "communityName": "r/indiehackers",
    "parsedCommunityName": "indiehackers",
    "body": "I have built a documentation software that is super easy to use for any public facing documentation from api docs to general instructional docs.\n\nHere’s a link to it: https://a4doks.com\n\nI think this is super useful and it has native markdown support along with ability to style using custom components like cards, accordions and separators.\n\nProblem is, I am an engineer at heart and I have no idea how to market this. Where do I start? I know producthunt is one place where I can launch this. But I wanna make sure I have a few users providing me valuable feedback so I can weed out all the bugs and improve it before I launch it on producthunt.",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have built a documentation software that is super easy to use for any public facing documentation from api docs to general instructional docs.&lt;/p&gt;\n\n&lt;p&gt;Here’s a link to it: &lt;a href=\"https://a4doks.com\"&gt;https://a4doks.com&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I think this is super useful and it has native markdown support along with ability to style using custom components like cards, accordions and separators.&lt;/p&gt;\n\n&lt;p&gt;Problem is, I am an engineer at heart and I have no idea how to market this. Where do I start? I know producthunt is one place where I can launch this. But I wanna make sure I have a few users providing me valuable feedback so I can weed out all the bugs and improve it before I launch it on producthunt.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/indiehackers/comments/1abatg8/not_sure_how_to_market_this/",
    "numberOfComments": 4,
    "flair": null,
    "upVotes": 1,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [
      "https://external-i.redd.it/RJrF592COLAkS5hES3UQSNvSrs_dT7Jq04NPGUizuEc.jpg"
    ],
    "createdAt": "2024-01-26T05:23:21.000Z",
    "scrapedAt": "2025-08-31T23:58:20.392Z",
    "dataType": "post"
  },
  {
    "id": "t3_19cg2k5",
    "parsedId": "19cg2k5",
    "url": "https://www.reddit.com/r/nextjs/comments/19cg2k5/i_built_a_documentation_site_builder/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "I built a documentation site builder",
    "communityName": "r/nextjs",
    "parsedCommunityName": "nextjs",
    "body": "Thumbnail: default\n",
    "html": "Thumbnail: default\n",
    "link": "https://v.redd.it/95jrep8revdc1",
    "numberOfComments": 3,
    "flair": null,
    "upVotes": 12,
    "upVoteRatio": 0.88,
    "isVideo": true,
    "isAd": false,
    "over18": false,
    "videoUrl": "https://v.redd.it/95jrep8revdc1/DASH_1080.mp4?source=fallback",
    "thumbnailUrl": "default",
    "imageUrls": [],
    "createdAt": "2024-01-21T22:41:03.000Z",
    "scrapedAt": "2025-08-31T23:58:20.425Z",
    "dataType": "post"
  },
  {
    "id": "t3_19ceczk",
    "parsedId": "19ceczk",
    "url": "https://www.reddit.com/r/indiehackers/comments/19ceczk/i_built_a_no_code_documentation_site_builder/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "I built a no code documentation site builder",
    "communityName": "r/indiehackers",
    "parsedCommunityName": "indiehackers",
    "body": "I created a documentation site builder that has the following features:\n\n1. Built-in support for markdown and custom components. \n2. Publish and host in minutes.\n\nYou can check it out at [a4doks.com](https://a4doks.com/).\n\nhttps://reddit.com/link/19ceczk/video/ebtlc3qw2vdc1/player",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I created a documentation site builder that has the following features:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Built-in support for markdown and custom components. &lt;/li&gt;\n&lt;li&gt;Publish and host in minutes.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;You can check it out at &lt;a href=\"https://a4doks.com/\"&gt;a4doks.com&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://reddit.com/link/19ceczk/video/ebtlc3qw2vdc1/player\"&gt;https://reddit.com/link/19ceczk/video/ebtlc3qw2vdc1/player&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/indiehackers/comments/19ceczk/i_built_a_no_code_documentation_site_builder/",
    "numberOfComments": 2,
    "flair": null,
    "upVotes": 2,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "https://b.thumbs.redditmedia.com/nVYrb4B-twgGJCXZO5WdE2LylGgjG0Fi5i4BqoLJmrg.jpg",
    "imageUrls": [
      "https://external-i.redd.it/RJrF592COLAkS5hES3UQSNvSrs_dT7Jq04NPGUizuEc.jpg"
    ],
    "createdAt": "2024-01-21T21:29:48.000Z",
    "scrapedAt": "2025-08-31T23:58:20.470Z",
    "dataType": "post"
  },
  {
    "id": "t3_19cf5dp",
    "parsedId": "19cf5dp",
    "url": "https://www.reddit.com/r/SaaS/comments/19cf5dp/i_built_a_documentation_site_builder_using/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "I built a documentation site builder using markdown",
    "communityName": "r/SaaS",
    "parsedCommunityName": "SaaS",
    "body": "Website: [https://www.a4doks.com/](https://www.a4doks.com/)\n\n* Markdown support\n* Custom components\n* Publish and host in one click",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Website: &lt;a href=\"https://www.a4doks.com/\"&gt;https://www.a4doks.com/&lt;/a&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Markdown support&lt;/li&gt;\n&lt;li&gt;Custom components&lt;/li&gt;\n&lt;li&gt;Publish and host in one click&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/SaaS/comments/19cf5dp/i_built_a_documentation_site_builder_using/",
    "numberOfComments": 0,
    "flair": null,
    "upVotes": 0,
    "upVoteRatio": 0.5,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [
      "https://external-i.redd.it/RJrF592COLAkS5hES3UQSNvSrs_dT7Jq04NPGUizuEc.jpg"
    ],
    "createdAt": "2024-01-21T22:01:56.000Z",
    "scrapedAt": "2025-08-31T23:58:20.502Z",
    "dataType": "post"
  },
  {
    "id": "t3_19cf37i",
    "parsedId": "19cf37i",
    "url": "https://www.reddit.com/r/IMadeThis/comments/19cf37i/i_built_a_documentation_site_builder_using/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "I built a documentation site builder using markdown",
    "communityName": "r/IMadeThis",
    "parsedCommunityName": "IMadeThis",
    "body": "&amp;#x200B;\n\nhttps://reddit.com/link/19cf37i/video/a91us9ma8vdc1/player",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://reddit.com/link/19cf37i/video/a91us9ma8vdc1/player\"&gt;https://reddit.com/link/19cf37i/video/a91us9ma8vdc1/player&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/IMadeThis/comments/19cf37i/i_built_a_documentation_site_builder_using/",
    "numberOfComments": 0,
    "flair": null,
    "upVotes": 1,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "https://b.thumbs.redditmedia.com/nVYrb4B-twgGJCXZO5WdE2LylGgjG0Fi5i4BqoLJmrg.jpg",
    "imageUrls": [],
    "createdAt": "2024-01-21T21:59:40.000Z",
    "scrapedAt": "2025-08-31T23:58:20.543Z",
    "dataType": "post"
  },
  {
    "id": "t3_19cegis",
    "parsedId": "19cegis",
    "url": "https://www.reddit.com/r/InternetIsBeautiful/comments/19cegis/build_and_launch_beautiful_documentation_sites/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "Build and launch beautiful documentation sites easily",
    "communityName": "r/InternetIsBeautiful",
    "parsedCommunityName": "InternetIsBeautiful",
    "body": "Thumbnail: default\n",
    "html": "Thumbnail: default\n",
    "link": "https://www.a4doks.com/",
    "numberOfComments": 9,
    "flair": null,
    "upVotes": 0,
    "upVoteRatio": 0.48,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "default",
    "imageUrls": [],
    "createdAt": "2024-01-21T21:33:40.000Z",
    "scrapedAt": "2025-08-31T23:58:20.584Z",
    "dataType": "post"
  },
  {
    "id": "t3_17oem6b",
    "parsedId": "17oem6b",
    "url": "https://www.reddit.com/r/nextjs/comments/17oem6b/i_built_a_documentation_software_that_can_be/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "I built a documentation software that can be written using markdown and styles using shadcn UI components.",
    "communityName": "r/nextjs",
    "parsedCommunityName": "nextjs",
    "body": "Website: [https://a4doks.com](https://a4doks.com)\n\nFeatures:\n- Very easy to get started - just connect your GitHub and clone the starter template\n- You can update and preview it locally using the CLI \n- Publish it and put it behind a custom domain in just a couple of clicks\n\nLooking for some feedback here. Working on making it open source. ",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Website: &lt;a href=\"https://a4doks.com\"&gt;https://a4doks.com&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Features:\n- Very easy to get started - just connect your GitHub and clone the starter template\n- You can update and preview it locally using the CLI \n- Publish it and put it behind a custom domain in just a couple of clicks&lt;/p&gt;\n\n&lt;p&gt;Looking for some feedback here. Working on making it open source. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://v.redd.it/att1trxzujyb1",
    "numberOfComments": 28,
    "flair": "Show /r/nextjs",
    "upVotes": 124,
    "upVoteRatio": 0.95,
    "isVideo": true,
    "isAd": false,
    "over18": false,
    "videoUrl": "https://v.redd.it/att1trxzujyb1/DASH_720.mp4?source=fallback",
    "thumbnailUrl": "https://external-preview.redd.it/NnN3cDN2c3p1anliMbYdyDya3wfc1zC_zt9yXafEEWZytqI9cd5QggJuYTm3.png?width=140&amp;height=88&amp;crop=140:88,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=00e9ec1741efeab464006658299da2fde13b6464",
    "imageUrls": [
      "https://external-i.redd.it/NnN3cDN2c3p1anliMbYdyDya3wfc1zC_zt9yXafEEWZytqI9cd5QggJuYTm3.png"
    ],
    "createdAt": "2023-11-05T15:43:16.000Z",
    "scrapedAt": "2025-08-31T23:58:21.914Z",
    "dataType": "post"
  },
  {
    "id": "t3_17ockgu",
    "parsedId": "17ockgu",
    "url": "https://www.reddit.com/r/indiehackers/comments/17ockgu/i_made_a_documentation_software_that_can_be/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "I made a documentation software that can be written using markdown and shadcn UI components",
    "communityName": "r/indiehackers",
    "parsedCommunityName": "indiehackers",
    "body": "Images:\n\thttps://external-preview.redd.it/emxobHVzN3VjanliMbYdyDya3wfc1zC_zt9yXafEEWZytqI9cd5QggJuYTm3.png?format=pjpg&amp;auto=webp&amp;s=0305c940b8d5fc6edba7d5c7ab3fdda9cb050e3e\n",
    "html": "Images:\n\thttps://external-preview.redd.it/emxobHVzN3VjanliMbYdyDya3wfc1zC_zt9yXafEEWZytqI9cd5QggJuYTm3.png?format=pjpg&amp;auto=webp&amp;s=0305c940b8d5fc6edba7d5c7ab3fdda9cb050e3e\n",
    "link": "https://v.redd.it/ff2t0pbucjyb1",
    "numberOfComments": 10,
    "flair": null,
    "upVotes": 14,
    "upVoteRatio": 0.94,
    "isVideo": true,
    "isAd": false,
    "over18": false,
    "videoUrl": "https://v.redd.it/ff2t0pbucjyb1/DASH_720.mp4?source=fallback",
    "thumbnailUrl": "https://external-preview.redd.it/emxobHVzN3VjanliMbYdyDya3wfc1zC_zt9yXafEEWZytqI9cd5QggJuYTm3.png?width=140&amp;height=88&amp;crop=140:88,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=2954d806c0bd8014d892469f4e153d646eda4bd4",
    "imageUrls": [
      "https://external-i.redd.it/emxobHVzN3VjanliMbYdyDya3wfc1zC_zt9yXafEEWZytqI9cd5QggJuYTm3.png"
    ],
    "createdAt": "2023-11-05T14:01:30.000Z",
    "scrapedAt": "2025-08-31T23:58:21.952Z",
    "dataType": "post"
  },
  {
    "id": "t3_17ofnum",
    "parsedId": "17ofnum",
    "url": "https://www.reddit.com/r/IMadeThis/comments/17ofnum/i_built_a_documentation_software_that_can_be/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "I built a documentation software that can be written using markdown and styles using shadcn UI components.",
    "communityName": "r/IMadeThis",
    "parsedCommunityName": "IMadeThis",
    "body": "&amp;#x200B;\n\nhttps://reddit.com/link/17ofnum/video/dwhdzwdy2kyb1/player\n\nGithub: [https://github.com/a4doks/starter-template](https://github.com/a4doks/starter-template)\n\nWebsite: [https://a4doks.com](https://a4doks.com/)\n\nFeatures:\n\n* Very easy to get started - just connect your GitHub and clone the starter template\n* You can update and preview it locally using the CLI\n* Publish it and put it behind a custom domain in just a couple of clicks\n\nLooking for some feedback here. Working on making it open source.",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://reddit.com/link/17ofnum/video/dwhdzwdy2kyb1/player\"&gt;https://reddit.com/link/17ofnum/video/dwhdzwdy2kyb1/player&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Github: &lt;a href=\"https://github.com/a4doks/starter-template\"&gt;https://github.com/a4doks/starter-template&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Website: &lt;a href=\"https://a4doks.com/\"&gt;https://a4doks.com&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Features:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Very easy to get started - just connect your GitHub and clone the starter template&lt;/li&gt;\n&lt;li&gt;You can update and preview it locally using the CLI&lt;/li&gt;\n&lt;li&gt;Publish it and put it behind a custom domain in just a couple of clicks&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Looking for some feedback here. Working on making it open source.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/IMadeThis/comments/17ofnum/i_built_a_documentation_software_that_can_be/",
    "numberOfComments": 0,
    "flair": null,
    "upVotes": 2,
    "upVoteRatio": 0.75,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "https://b.thumbs.redditmedia.com/a51vUjvj4VqROZY9m51rm7fjbpcrY2I8cQsdOGZbAUU.jpg",
    "imageUrls": [
      "https://external-i.redd.it/Ss-4FJEpEP7laQENYAvTSJ-iedvT4fXQViSS6MPA1YQ.jpg"
    ],
    "createdAt": "2023-11-05T16:32:15.000Z",
    "scrapedAt": "2025-08-31T23:58:21.978Z",
    "dataType": "post"
  },
  {
    "id": "t3_17o0bt5",
    "parsedId": "17o0bt5",
    "url": "https://www.reddit.com/r/SideProject/comments/17o0bt5/i_made_a_documentation_software_that_can_be/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "I made a documentation software that can be written using markdown.",
    "communityName": "r/SideProject",
    "parsedCommunityName": "SideProject",
    "body": "Images:\n\thttps://external-preview.redd.it/-FIUJ8lBS405ds7lyrOm-UPhqUnlbNBlQT7pY4CibhQ.png?format=pjpg&amp;auto=webp&amp;s=4da1ab47d6e75ed23b93ec020e17ec9c3c01bb12\n",
    "html": "Images:\n\thttps://external-preview.redd.it/-FIUJ8lBS405ds7lyrOm-UPhqUnlbNBlQT7pY4CibhQ.png?format=pjpg&amp;auto=webp&amp;s=4da1ab47d6e75ed23b93ec020e17ec9c3c01bb12\n",
    "link": "https://v.redd.it/fe7o881uffyb1",
    "numberOfComments": 4,
    "flair": null,
    "upVotes": 11,
    "upVoteRatio": 0.91,
    "isVideo": true,
    "isAd": false,
    "over18": false,
    "videoUrl": "https://v.redd.it/fe7o881uffyb1/DASH_1080.mp4?source=fallback",
    "thumbnailUrl": "https://b.thumbs.redditmedia.com/t0YHjFD-kAUwOcL2Dj_1TKxto-DcOs-KaoHLziTC7ME.jpg",
    "imageUrls": [
      "https://external-i.redd.it/-FIUJ8lBS405ds7lyrOm-UPhqUnlbNBlQT7pY4CibhQ.png"
    ],
    "createdAt": "2023-11-05T00:51:09.000Z",
    "scrapedAt": "2025-08-31T23:58:22.012Z",
    "dataType": "post"
  },
  {
    "id": "t3_11it3db",
    "parsedId": "11it3db",
    "url": "https://www.reddit.com/r/SmallBusinessCanada/comments/11it3db/app_to_track_etransfer_payments/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "App to track e-transfer payments",
    "communityName": "r/SmallBusinessCanada",
    "parsedCommunityName": "SmallBusinessCanada",
    "body": "I have built an app to track e-transfer payments for streamlining my business. It works like this \n1. If you’re a business accepting payments using e-transfer, you can signup using the email you use for e-transfers \n2. The app tracks your e-transfers and displays it in a nice dashboard with the customer name, amount, date of payment and a field to add tags and edit details.\n\n Is this something that will be useful for you? Happy to share it",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have built an app to track e-transfer payments for streamlining my business. It works like this \n1. If you’re a business accepting payments using e-transfer, you can signup using the email you use for e-transfers \n2. The app tracks your e-transfers and displays it in a nice dashboard with the customer name, amount, date of payment and a field to add tags and edit details.&lt;/p&gt;\n\n&lt;p&gt;Is this something that will be useful for you? Happy to share it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/SmallBusinessCanada/comments/11it3db/app_to_track_etransfer_payments/",
    "numberOfComments": 1,
    "flair": "Book_Keeping",
    "upVotes": 1,
    "upVoteRatio": 0.6,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2023-03-05T09:42:30.000Z",
    "scrapedAt": "2025-08-31T23:58:22.053Z",
    "dataType": "post"
  },
  {
    "id": "t3_yu9ec9",
    "parsedId": "yu9ec9",
    "url": "https://www.reddit.com/r/IMadeThis/comments/yu9ec9/i_made_an_app_that_turns_tweet_threads_into_pdfs/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "I made an app that turns tweet threads into PDFs for sharing as a carousel post on linkedin https://getquill.xyz/",
    "communityName": "r/IMadeThis",
    "parsedCommunityName": "IMadeThis",
    "body": "[https://getquill.xyz/](https://getquill.xyz/)",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://getquill.xyz/\"&gt;https://getquill.xyz/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/IMadeThis/comments/yu9ec9/i_made_an_app_that_turns_tweet_threads_into_pdfs/",
    "numberOfComments": 0,
    "flair": null,
    "upVotes": 2,
    "upVoteRatio": 1,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [],
    "createdAt": "2022-11-13T18:15:05.000Z",
    "scrapedAt": "2025-08-31T23:58:22.083Z",
    "dataType": "post"
  },
  {
    "id": "t3_pp322s",
    "parsedId": "pp322s",
    "url": "https://www.reddit.com/r/FlutterDev/comments/pp322s/ab_testing_flutter_apps/",
    "username": "cryptokaykay",
    "userId": "t2_5n51b0n0",
    "title": "A/B testing flutter apps",
    "communityName": "r/FlutterDev",
    "parsedCommunityName": "FlutterDev",
    "body": "I am building a SaaS app for a/b testing flutter apps. The product works like this:\n\n* you can create two versions(a and b) of a widget(for instance: with different colors or copy text) and upload the widgets to the SaaS tool using a flutter library.\n* now you can use the flutter library to show version\\_a or version\\_b to the user with just a one liner (without having the code for the widgets a and b on the app)\n* you also get a SaaS dashboard where you can also control the weights for versions a and b and you can also see other stats that includes, impressions, conversions and conversion rate.\n\nIf you are interested in trying out the closed beta please sign up here:  \n[https://nanx6niagut.typeform.com/to/lZ2rW0SC](https://nanx6niagut.typeform.com/to/lZ2rW0SC)",
    "html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am building a SaaS app for a/b testing flutter apps. The product works like this:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;you can create two versions(a and b) of a widget(for instance: with different colors or copy text) and upload the widgets to the SaaS tool using a flutter library.&lt;/li&gt;\n&lt;li&gt;now you can use the flutter library to show version_a or version_b to the user with just a one liner (without having the code for the widgets a and b on the app)&lt;/li&gt;\n&lt;li&gt;you also get a SaaS dashboard where you can also control the weights for versions a and b and you can also see other stats that includes, impressions, conversions and conversion rate.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If you are interested in trying out the closed beta please sign up here:&lt;br/&gt;\n&lt;a href=\"https://nanx6niagut.typeform.com/to/lZ2rW0SC\"&gt;https://nanx6niagut.typeform.com/to/lZ2rW0SC&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
    "link": "https://www.reddit.com/r/FlutterDev/comments/pp322s/ab_testing_flutter_apps/",
    "numberOfComments": 0,
    "flair": "3rd Party Service",
    "upVotes": 0,
    "upVoteRatio": 0.5,
    "isVideo": false,
    "isAd": false,
    "over18": false,
    "thumbnailUrl": "self",
    "imageUrls": [
      "https://external-i.redd.it/HGAVZJucaNgf8nMFOwy3wrE8LN_YGodbh0om8Stu-LE.jpg"
    ],
    "createdAt": "2021-09-16T00:57:51.000Z",
    "scrapedAt": "2025-08-31T23:58:22.114Z",
    "dataType": "post"
  }
]